{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "from pymoo.operators.sampling.rnd import BinaryRandomSampling\n",
    "from pymoo.operators.mutation.bitflip import BitflipMutation\n",
    "from pymoo.operators.crossover.hux import HUX\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import itertools \n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "display_pca = False\n",
    "N_NEIGHBOURS = 5\n",
    "RANDOM_SEED = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_splits(path):\n",
    "\ttry:\n",
    "\t\tdf = pd.read_csv(path, delimiter=', ', engine='python')\n",
    "\t\tx = df.drop(columns='Class')\n",
    "\t\ty = df['Class']\n",
    "\texcept KeyError:\n",
    "\t\tdf = pd.read_csv(path, delimiter=',')\n",
    "\t\tx = df.drop(columns='Class')\n",
    "\t\ty = df['Class']\n",
    "\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\tx = np.array(x)\n",
    "\ty = label_encoder.fit_transform(y)\n",
    "\t\n",
    "\ttrain_split = StratifiedShuffleSplit(\n",
    "\t\tn_splits=31,\n",
    "\t\ttest_size=0.5,\n",
    "\t)\n",
    "\n",
    "\tsplits = []\n",
    "\n",
    "\tfor train_idx, temp_idx in train_split.split(x, y):\n",
    "\n",
    "\t\ttest_split = StratifiedShuffleSplit(\n",
    "\t\t\tn_splits=1,\n",
    "\t\t\ttest_size=0.5\n",
    "\t\t)\n",
    "\n",
    "\t\tx_temp, y_temp = x[temp_idx], y[temp_idx]\n",
    "\n",
    "\t\ttest_idx, validation_idx = next(test_split.split(x_temp, y_temp))\n",
    "\n",
    "\t\tvalidation_idx = temp_idx[validation_idx]\n",
    "\t\ttest_idx = temp_idx[test_idx]\n",
    "\n",
    "\t\tsplits.append((train_idx, validation_idx, test_idx))\n",
    "\t\n",
    "\treturn x, y, splits\n",
    "\n",
    "def over_sample(x, y):\n",
    "\t\n",
    "\tcounts = pd.DataFrame(y).value_counts()\n",
    "\n",
    "\tif counts[0] < counts[1]:\n",
    "\t\tminority_class_indicies = np.where(y == 1)\n",
    "\telse:\n",
    "\t\tminority_class_indicies = np.where(y == 0)\n",
    "\n",
    "\tover_sampled_x = np.concatenate((x, x[minority_class_indicies]), axis=0)\n",
    "\tover_sampled_y = np.concatenate((y, y[minority_class_indicies]), axis=0)\n",
    "\n",
    "\treturn over_sampled_x, over_sampled_y\n",
    "\n",
    "class BiasedBinarySampling(Sampling):\n",
    "\tdef __init__(self, labels, major_prob, minor_prob):\n",
    "\t\t\n",
    "\t\tself.labels = labels\n",
    "\t\tcounts = pd.DataFrame(labels).value_counts()\n",
    "\t\tif counts[0] > counts[1]:\n",
    "\t\t\tself.c0_thresh = major_prob\n",
    "\t\t\tself.c1_thresh = minor_prob\n",
    "\t\telse:\n",
    "\t\t\tself.c0_thresh = minor_prob\n",
    "\t\t\tself.c1_thresh = major_prob\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef _do(self, problem, n_samples, **kwargs):\n",
    "\n",
    "\t\trands = np.random.random((n_samples, problem.n_var))\n",
    "\t\tinit_pops = np.zeros((n_samples, problem.n_var), dtype=bool)\n",
    "\t\tfor idx, label in enumerate(self.labels):\n",
    "\t\t\tif label == 0:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c0_thresh).astype(bool)\n",
    "\t\t\tif label == 1:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c1_thresh).astype(bool)\n",
    "\n",
    "\n",
    "\t\treturn init_pops\n",
    "\n",
    "class InheritedSampling(Sampling):\n",
    "\tdef __init__(self, pareto_front, mutation_prob, num_rows_inherited):\n",
    "\t\t\n",
    "\t\tself.parent = pareto_front\n",
    "\t\tself.thresh = mutation_prob\n",
    "\t\tself.inherit_thresh = num_rows_inherited\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef _do(self, problem, n_samples, **kwargs):\n",
    "\n",
    "\t\tinit_pops = np.zeros((n_samples, problem.n_var), dtype=bool)\n",
    "\t\trands = np.random.random((n_samples, problem.n_var))\n",
    "\t\tfor i in range(init_pops.shape[0]):\n",
    "\t\t\tfor j in range(init_pops.shape[1]):\n",
    "\n",
    "\t\t\t\tif i < self.inherit_thresh:\n",
    "\t\t\t\t\tif rands[i, j] < self.thresh:\n",
    "\t\t\t\t\t\tinit_pops[i, j] = 0 if self.parent[i, j] == 1 else 1\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tinit_pops[i, j] = self.parent[i, j]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tinit_pops[i, j] = 0 if rands[i, j] < 0.5 else 1\n",
    "\n",
    "\t\treturn init_pops\n",
    "\n",
    "class GenericOptimizer(Problem):\n",
    "\tpopulation_size = 100\n",
    "\tn_neighbours = 5\n",
    "\tsequential = False\n",
    "\tdef __init__(self, X_train, y_train, X_val, y_val, objectives, exec_mode):\n",
    "\t\t\n",
    "\t\tself.exec_mode = exec_mode\n",
    "\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\n",
    "\t\tself.X_val = X_val\n",
    "\t\tself.y_val = y_val\n",
    "\n",
    "\t\tself.training_data = X_train\n",
    "\t\tself.n_instances = X_train.shape[0]\n",
    "\t\t\n",
    "\t\tself.objectives = objectives\n",
    "\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tn_var=self.n_instances,\n",
    "\t\t\tn_obj=len(objectives),               \n",
    "\t\t\tn_constr=0,            \n",
    "\t\t\txl=0,                  \n",
    "\t\t\txu=1,                  \n",
    "\t\t\ttype_var=np.bool_,     \n",
    "\t\t)\n",
    "\n",
    "\tdef _evaluate(self, x, out, *args, **kwargs):\n",
    "\t\t\n",
    "\t\tif self.exec_mode == \"sequential\":\n",
    "\t\t\tmetrics = []\n",
    "\t\t\tfor objective in self.objectives:\n",
    "\t\t\t\tmetrics.append(self.eval_objective((objective, x)))\n",
    "\t\telse:\n",
    "\t\t\tmetrics = Parallel(n_jobs=-1)(delayed(self.eval_objective)((objective, x)) for objective in self.objectives)\n",
    "\t\t\n",
    "\t\tout[\"F\"] = np.column_stack(metrics)\n",
    "\n",
    "\tdef eval_objective(self, pack):\n",
    "\t\tobjective, x = pack\n",
    "\t\t\t\n",
    "\t\tif \"calculate_num_examples\" in repr(objective):\n",
    "\t\t\treturn GenericOptimizer.calculate_num_examples(x)\n",
    "\n",
    "\t\telif \"calculate_IR\" in repr(objective):\n",
    "\t\t\tvals = []\n",
    "\t\t\tfor instance in x:\n",
    "\t\t\t\tvals.append(GenericOptimizer.calculate_IR(self.y_train[instance]))\n",
    "\t\t\treturn vals\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tvals = []\n",
    "\t\t\tfor instance in x:\n",
    "\t\t\t\tvals.append(objective(\n",
    "\t\t\t\t\tself.X_train[instance],\n",
    "\t\t\t\t\tself.y_train[instance],\n",
    "\t\t\t\t\tself.X_val,\n",
    "\t\t\t\t\tself.y_val,\n",
    "\t\t\t\t\tGenericOptimizer.n_neighbours\n",
    "\t\t\t\t))\n",
    "\t\t\treturn vals\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_IR(cls, y):\n",
    "\t\tdf = pd.DataFrame(y).value_counts()\n",
    "\t\treturn (df[1]/df[0]) if df.min() == 0 else (df[0]/df[1])\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef filter_by_class(cls, x, y, label):\n",
    "\t\tindices = np.where(y==label)\n",
    "\t\treturn x[indices], y[indices]\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tacc = accuracy_score(y_val, y_pred)\n",
    "\t\t\treturn 1-acc\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 0)\n",
    "\t\terr = cls.calculate_overall_error(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn err\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 1)\n",
    "\t\terr = cls.calculate_overall_error(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn err\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tf1 = f1_score(y_val, y_pred)\n",
    "\t\t\treturn 1-f1\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 0)\n",
    "\t\tinv_f1 = cls.calculate_overall_inverse_f1(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_f1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 1)\n",
    "\t\tinv_f1 = cls.calculate_overall_inverse_f1(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_f1\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_inverse_precision(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tprec = precision_score(y_val, y_pred)\n",
    "\t\t\treturn 1-prec\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_inverse_precision(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 0)\n",
    "\t\tinv_prec = cls.calculate_overall_inverse_precision(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_prec\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_precision(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 1)\n",
    "\t\tinv_prec = cls.calculate_overall_inverse_precision(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_prec\n",
    "\t\t\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_inverse_recall(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\trecall = recall_score(y_val, y_pred)\n",
    "\t\t\treturn 1-recall\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_inverse_recall(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 0)\n",
    "\t\tinv_recall = cls.calculate_overall_inverse_recall(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_recall\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_recall(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 1)\n",
    "\t\tinv_recall = cls.calculate_overall_inverse_recall(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_recall\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_num_examples(cls, instances):\n",
    "\t\treturn np.sum(instances, axis=1)\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_optimal_instance(cls, x_train, y_train, x_val, y_val, result, n):\n",
    "\n",
    "\t\tfronts = NonDominatedSorting().do(result.F, only_non_dominated_front=True)\n",
    "\t\t_, pareto_indicies = np.unique(result.F[fronts], axis=0, return_index=True)\n",
    "\n",
    "\t\tbest_instance_idx = 0\n",
    "\t\tbest_acc = 0\n",
    "\t\tbest_instance = None\n",
    "\t\tfor idx, instance in enumerate(result.X[pareto_indicies]):\n",
    "\t\t\tx_filtered, y_filtered = x_train[instance], y_train[instance]\n",
    "\t\t\tif x_filtered.shape[0] < n: \n",
    "\t\t\t\tacc = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tknn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\t\tknn.fit(x_filtered, y_filtered)\n",
    "\t\t\t\ty_pred = knn.predict(x_val)\n",
    "\t\t\t\tacc = accuracy_score(y_val, y_pred)\n",
    "\t\t\t\n",
    "\t\t\t\tif acc > best_acc:\n",
    "\t\t\t\t\tbest_acc = acc\n",
    "\t\t\t\t\tbest_instance_idx = idx\n",
    "\t\t\t\t\tbest_instance = instance\n",
    "\t\t\t\t\n",
    "\t\treturn best_instance_idx, x_train[best_instance], y_train[best_instance]\n",
    "\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3720 executions\n"
     ]
    }
   ],
   "source": [
    "def execute(config):\n",
    "\t\n",
    "\tif f\"run_{config['Experiment index']}.pickle\" in os.listdir(f\"Experiments_2\"):\n",
    "\t\treturn \n",
    "\t\n",
    "\ttrain_idx = config[\"train_idx\"]\n",
    "\tvalidation_idx = config[\"validation_idx\"]\n",
    "\ttest_idx = config[\"test_idx\"]\n",
    "\t\n",
    "\tx_train, y_train = config[\"x\"][train_idx], config[\"y\"][train_idx]\n",
    "\tx_validation, y_validation = config[\"x\"][validation_idx], config[\"y\"][validation_idx]\n",
    "\tx_test, y_test = config[\"x\"][test_idx], config[\"y\"][test_idx]\n",
    "\t\n",
    "\tif config[\"over_sample\"]:\n",
    "\t\tx_train, y_train = over_sample(x_train, y_train)\n",
    "\n",
    "\tobjectives = config[\"objectives_list\"]\n",
    "\n",
    "\tproblem = GenericOptimizer(\n",
    "\t\tx_train, \n",
    "\t\ty_train, \n",
    "\t\tx_validation, \n",
    "\t\ty_validation,\n",
    "\t\tobjectives,\n",
    "\t\t\"parallel\" if config[\"thread_evaluations\"] else \"sequential\"\n",
    "\t)\n",
    "\n",
    "\tinitial_population = BinaryRandomSampling() if config[\"sampling\"] == \"Rand\" else BiasedBinarySampling(y_train, 0.5, 0.7)\n",
    "\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\tsampling=initial_population, \n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True)\n",
    "\t\n",
    "\tresult = minimize(\n",
    "\t\tproblem, \n",
    "\t\talgorithm, \n",
    "\t\t('n_gen', GenericOptimizer.population_size)\n",
    "\t)\n",
    "\n",
    "\tsave_var = {\n",
    "\t\t\"Result\": result,\n",
    "\t\t\"Over Sample\": config[\"over_sample\"],\n",
    "\t\t\"Dataset\": folder,\n",
    "\t\t\"Init Pop\": config[\"sampling\"],\n",
    "\t\t\"Objectives\": objectives\n",
    "\t}\n",
    "\n",
    "\twith open(f\"Experiments_2/run_{config['Experiment index']}.pickle\", 'wb') as fh:\n",
    "\t\tpickle.dump(save_var, fh, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\treturn (config, result)\n",
    "\n",
    "\n",
    "configs = []\n",
    "from generic_optimizer import GenericOptimizer\n",
    "evaluation_schemes = [\n",
    "\t[GenericOptimizer.calculate_overall_error, GenericOptimizer.calculate_num_examples],\n",
    "\t[GenericOptimizer.calculate_overall_error, GenericOptimizer.calculate_overall_inverse_f1, GenericOptimizer.calculate_num_examples],\n",
    "\t[GenericOptimizer.calculate_class0_error, GenericOptimizer.calculate_class1_error],\n",
    "]\n",
    "\n",
    "sampling_methods = [\n",
    "\t\"Rand\",\n",
    "\t\"Bias\"\n",
    "]\n",
    "config_idx = 0\n",
    "for sampling_method in sampling_methods:\n",
    "\tfor objectives in evaluation_schemes:\n",
    "\t\tfor do_over_sample in [True, False]:\n",
    "\t\t\tfor folder in os.listdir('Datasets'):\n",
    "\t\t\t\tx, y, splits = prepare_splits(os.path.join('Datasets', folder, f\"{folder}.csv\"))\n",
    "\t\t\t\tfor train_idx, test_idx, validation_idx in splits: # 31 splits for Wilcoxon rank-sum\n",
    "\t\t\t\t\tconfig = {\n",
    "\t\t\t\t\t\t\"Experiment index\": config_idx,\n",
    "\t\t\t\t\t\t\"Dataset\": folder,\n",
    "\t\t\t\t\t\t\"x\": x, \"y\": y,\n",
    "\t\t\t\t\t\t\"train_idx\": train_idx,\n",
    "\t\t\t\t\t\t\"validation_idx\": validation_idx,\n",
    "\t\t\t\t\t\t\"test_idx\": test_idx,\n",
    "\t\t\t\t\t\t\"thread_evaluations\": False,\n",
    "\t\t\t\t\t\t\"over_sample\": do_over_sample,\n",
    "\t\t\t\t\t\t\"objectives_list\": objectives,\n",
    "\t\t\t\t\t\t\"sampling\": sampling_method,\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t\tconfig_idx += 1\n",
    "\t\t\t\t\tconfigs.append(config)\n",
    "\n",
    "print(f\"Created {len(configs)} executions\")\n",
    "with open(\"experiment_start_data_2025_3_5.pickle\", 'wb') as fh:\n",
    "\tpickle.dump(configs[:2], fh, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiment_start_data_2025_3_5.pickle\", 'rb') as fh:\n",
    "\tconfigs = pickle.load(fh)\n",
    "\n",
    "output = Parallel(n_jobs=-1)(delayed(execute)((config)) for config in configs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
