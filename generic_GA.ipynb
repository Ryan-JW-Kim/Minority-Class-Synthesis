{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.core.problem import Problem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.operators.crossover.hux import HUX\n",
    "from pymoo.operators.mutation.bitflip import BitflipMutation\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "from pymoo.operators.sampling.rnd import BinaryRandomSampling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from utils import *\n",
    "\n",
    "display_pca = False\n",
    "N_NEIGHBOURS = 5\n",
    "RANDOM_SEED = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasedBinarySampling(Sampling):\n",
    "\tdef __init__(self, labels, major_prob, minor_prob):\n",
    "\t\t\n",
    "\t\tself.labels = labels\n",
    "\t\tcounts = pd.DataFrame(labels).value_counts()\n",
    "\t\tif counts[0] > counts[1]:\n",
    "\t\t\tself.c0_thresh = major_prob\n",
    "\t\t\tself.c1_thresh = minor_prob\n",
    "\t\telse:\n",
    "\t\t\tself.c0_thresh = minor_prob\n",
    "\t\t\tself.c1_thresh = major_prob\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef _do(self, problem, n_samples, **kwargs):\n",
    "\n",
    "\t\trands = np.random.random((n_samples, problem.n_var))\n",
    "\t\tinit_pops = np.zeros((n_samples, problem.n_var), dtype=bool)\n",
    "\t\tfor idx, label in enumerate(self.labels):\n",
    "\t\t\tif label == 0:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c0_thresh).astype(bool)\n",
    "\t\t\tif label == 1:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c1_thresh).astype(bool)\n",
    "\n",
    "\n",
    "\t\treturn init_pops\n",
    "\n",
    "class InheritedSampling(Sampling):\n",
    "\tdef __init__(self, pareto_front, mutation_prob, num_rows_inherited):\n",
    "\t\t\n",
    "\t\tself.parent = pareto_front\n",
    "\t\tself.thresh = mutation_prob\n",
    "\t\tself.inherit_thresh = num_rows_inherited\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef _do(self, problem, n_samples, **kwargs):\n",
    "\n",
    "\t\tinit_pops = np.zeros((n_samples, problem.n_var), dtype=bool)\n",
    "\t\trands = np.random.random((n_samples, problem.n_var))\n",
    "\t\tfor i in range(init_pops.shape[0]):\n",
    "\t\t\tfor j in range(init_pops.shape[1]):\n",
    "\n",
    "\t\t\t\tif i < self.inherit_thresh:\n",
    "\t\t\t\t\tif rands[i, j] < self.thresh:\n",
    "\t\t\t\t\t\tinit_pops[i, j] = 0 if self.parent[i, j] == 1 else 1\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tinit_pops[i, j] = self.parent[i, j]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tinit_pops[i, j] = 0 if rands[i, j] < 0.5 else 1\n",
    "\n",
    "\t\treturn init_pops\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11560693641618502\n"
     ]
    }
   ],
   "source": [
    "class GenericOptimizer(Problem):\n",
    "\tpopulation_size = 100\n",
    "\tn_neighbours = 5\n",
    "\tsequential = False\n",
    "\tdef __init__(self, X_train, y_train, X_val, y_val, objectives, exec_mode):\n",
    "\t\t\n",
    "\t\tself.exec_mode = exec_mode\n",
    "\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\n",
    "\t\tself.X_val = X_val\n",
    "\t\tself.y_val = y_val\n",
    "\n",
    "\t\tself.training_data = X_train\n",
    "\t\tself.n_instances = X_train.shape[0]\n",
    "\t\t\n",
    "\t\tself.objectives = objectives\n",
    "\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tn_var=self.n_instances,\n",
    "\t\t\tn_obj=len(objectives),               \n",
    "\t\t\tn_constr=0,            \n",
    "\t\t\txl=0,                  \n",
    "\t\t\txu=1,                  \n",
    "\t\t\ttype_var=np.bool_,     \n",
    "\t\t)\n",
    "\n",
    "\tdef _evaluate(self, x, out, *args, **kwargs):\n",
    "\t\t\n",
    "\t\tif self.exec_mode == \"sequential\":\n",
    "\t\t\tmetrics = []\n",
    "\t\t\tfor objective in self.objectives:\n",
    "\t\t\t\tmetrics.append(self.eval_objective((objective, x)))\n",
    "\t\telse:\n",
    "\t\t\tmetrics = Parallel(n_jobs=-1)(delayed(self.eval_objective)((objective, x)) for objective in self.objectives)\n",
    "\t\t\n",
    "\t\tout[\"F\"] = np.column_stack(metrics)\n",
    "\n",
    "\tdef eval_objective(self, pack):\n",
    "\t\tobjective, x = pack\n",
    "\t\t\t\n",
    "\t\tif \"calculate_num_examples\" in repr(objective):\n",
    "\t\t\treturn GenericOptimizer.calculate_num_examples(x)\n",
    "\n",
    "\t\telif \"calculate_IR\" in repr(objective):\n",
    "\t\t\tvals = []\n",
    "\t\t\tfor instance in x:\n",
    "\t\t\t\tvals.append(GenericOptimizer.calculate_IR(self.y_train[instance]))\n",
    "\t\t\treturn vals\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tvals = []\n",
    "\t\t\tfor instance in x:\n",
    "\t\t\t\tvals.append(objective(\n",
    "\t\t\t\t\tself.X_train[instance],\n",
    "\t\t\t\t\tself.y_train[instance],\n",
    "\t\t\t\t\tself.X_val,\n",
    "\t\t\t\t\tself.y_val,\n",
    "\t\t\t\t\tGenericOptimizer.n_neighbours\n",
    "\t\t\t\t))\n",
    "\t\t\treturn vals\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_IR(cls, y):\n",
    "\t\tdf = pd.DataFrame(y).value_counts()\n",
    "\t\treturn (df[1]/df[0]) if df.min() == 0 else (df[0]/df[1])\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef filter_by_class(cls, x, y, label):\n",
    "\t\tindices = np.where(y_train==label)\n",
    "\t\treturn x[indices], y[indices]\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tacc = accuracy_score(y_val, y_pred)\n",
    "\t\t\treturn 1-acc\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 0)\n",
    "\t\terr = cls.calculate_overall_error(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn err\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 1)\n",
    "\t\terr = cls.calculate_overall_error(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn err\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tf1 = f1_score(y_val, y_pred)\n",
    "\t\t\treturn 1-f1\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 0)\n",
    "\t\tinv_f1 = cls.calculate_overall_inverse_f1(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_f1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 1)\n",
    "\t\tinv_f1 = cls.calculate_overall_inverse_f1(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_f1\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_inverse_precision(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tprec = precision_score(y_val, y_pred)\n",
    "\t\t\treturn 1-prec\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_inverse_precision(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 0)\n",
    "\t\tinv_prec = cls.calculate_overall_inverse_precision(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_prec\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_precision(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 1)\n",
    "\t\tinv_prec = cls.calculate_overall_inverse_precision(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_prec\n",
    "\t\t\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_inverse_recall(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\trecall = recall_score(y_val, y_pred)\n",
    "\t\t\treturn 1-recall\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_inverse_recall(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 0)\n",
    "\t\tinv_recall = cls.calculate_overall_inverse_recall(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_recall\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_recall(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 1)\n",
    "\t\tinv_recall = cls.calculate_overall_inverse_recall(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_recall\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_num_examples(cls, instances):\n",
    "\t\treturn np.sum(instances, axis=1)\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_optimal_instance(cls, x_train, y_train, x_val, y_val, result, n):\n",
    "\n",
    "\t\tfronts = NonDominatedSorting().do(result.F, only_non_dominated_front=True)\n",
    "\t\t_, pareto_indicies = np.unique(result.F[fronts], axis=0, return_index=True)\n",
    "\n",
    "\t\tbest_instance_idx = 0\n",
    "\t\tbest_acc = 0\n",
    "\t\tbest_instance = None\n",
    "\t\tfor idx, instance in enumerate(result.X[pareto_indicies]):\n",
    "\t\t\tx_filtered, y_filtered = x_train[instance], y_train[instance]\n",
    "\t\t\tif x_filtered.shape[0] < n: \n",
    "\t\t\t\tacc = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tknn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\t\tknn.fit(x_filtered, y_filtered)\n",
    "\t\t\t\ty_pred = knn.predict(x_val)\n",
    "\t\t\t\tacc = accuracy_score(y_val, y_pred)\n",
    "\t\t\t\n",
    "\t\t\t\tif acc > best_acc:\n",
    "\t\t\t\t\tbest_acc = acc\n",
    "\t\t\t\t\tbest_instance_idx = idx\n",
    "\t\t\t\t\tbest_instance = instance\n",
    "\t\t\t\t\n",
    "\t\treturn best_instance_idx, x_train[best_instance], y_train[best_instance]\n",
    "\n",
    "for folder in os.listdir('Datasets'):\n",
    "\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(\n",
    "\t\tos.path.join('Datasets', folder, f\"{folder}.csv\"), \n",
    "\t\tfolder\n",
    "\t)\n",
    "\t\n",
    "\tobjectives = [\n",
    "\t\tGenericOptimizer.calculate_overall_error,\n",
    "\t\t# GenericOptimizer.calculate_num_examples,\n",
    "\t\tGenericOptimizer.calculate_overall_inverse_f1\n",
    "\t]\n",
    "\n",
    "\tproblem = GenericOptimizer(\n",
    "\t\tX_train, \n",
    "\t\ty_train, \n",
    "\t\tX_val, \n",
    "\t\ty_val,\n",
    "\t\tobjectives,\n",
    "\t\t\"sequential\"\n",
    "\t)\n",
    "\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\tsampling=BinaryRandomSampling(), \n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True)\n",
    "\t\n",
    "\tresult = minimize(\n",
    "\t\tproblem, \n",
    "\t\talgorithm, \n",
    "\t\t('n_gen', GenericOptimizer.population_size), \n",
    "\t\t# verbose=True\n",
    "\t)\n",
    "\n",
    "\tbest_instance_idx, x_train_best_instance, y_train_best_instance = GenericOptimizer.calculate_optimal_instance(X_train, y_train, X_val, y_val, result, GenericOptimizer.n_neighbours)\n",
    "\n",
    "\tprint(GenericOptimizer.calculate_overall_error(x_train_best_instance, y_train_best_instance, X_test, y_test, GenericOptimizer.n_neighbours))\n",
    "\tbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_optimized_metrics(data):\n",
    "\truns, run = data\n",
    "\t\n",
    "\tsegments = run.split(\"__\")\n",
    "\n",
    "\tdata_option = segments[0]\n",
    "\tinit_pop = segments[1]\n",
    "\toptimization = segments[2]\n",
    "\tdataset = segments[3].replace(\".pickle\", \"\")\n",
    "\t\n",
    "\theader = [\n",
    "\t\t\"Baseline Test Accuracy\",\n",
    "\t\t\"Baseline IR\",\n",
    "\t\t\"Optimized Test Accuracy\",\n",
    "\t\t\"Optimized IR\",\n",
    "\t\t\"Reduction Rate %\",\n",
    "\t]\n",
    "\tvalues = []\n",
    "\tfor save_var in runs[run]:\n",
    "\n",
    "\t\tX_train, X_val, X_test, y_train, y_val, y_test = save_var['Data']\n",
    "\t\tcounts, _, _, baseline_testAcc = assess_baseline_metrics(X_train, y_train, X_test, y_test)\n",
    "\t\tbaseline_IR = max(counts) / min(counts)\n",
    "\n",
    "\t\t_, _, x_filtered, y_filtered = select_optimal_instance(X_train, y_train, X_val, y_val, save_var['Result'])\n",
    "\t\tcounts = pd.DataFrame(y_filtered).value_counts()\n",
    "\t\toptimized_IR = max(counts) / min(counts)\n",
    "\n",
    "\t\toptimization_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\t\toptimization_knn.fit(x_filtered, y_filtered)\n",
    "\n",
    "\t\ty_pred = optimization_knn.predict(X_test)\n",
    "\t\ttest_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\t\treduction_rate = (X_train.shape[0] - x_filtered.shape[0]) / X_train.shape[0]*100\n",
    "\t\t\n",
    "\t\tvalues.append([\n",
    "\t\t\tbaseline_testAcc,\n",
    "\t\t\tbaseline_IR,\n",
    "\t\t\ttest_acc,\n",
    "\t\t\toptimized_IR,\n",
    "\t\t\treduction_rate\n",
    "\t\t])\n",
    "\t\n",
    "\taverages = pd.DataFrame(values, columns=header).mean(numeric_only=True)\n",
    "\t\n",
    "\trow = [\n",
    "\t\tdataset,\n",
    "\t\tdata_option,\n",
    "\t\tinit_pop,\n",
    "\t\toptimization,\n",
    "\t\taverages['Baseline Test Accuracy'],\n",
    "\t\taverages['Baseline IR'],\n",
    "\t\taverages['Optimized Test Accuracy'],\n",
    "\t\taverages['Optimized IR'],\n",
    "\t\taverages['Reduction Rate %'],\n",
    "\t\taverages['Optimized Test Accuracy'] - averages['Baseline Test Accuracy']\n",
    "\t]\n",
    "\n",
    "\treturn row\n",
    "\n",
    "header = [\n",
    "\t\"Dataset\",\n",
    "\t\"Over Sample?\",\n",
    "\t\"Biased Initialization?\",\n",
    "\t\"Optimization\",\n",
    "\t\"Baseline Test Accuracy\",\n",
    "\t\"Baseline IR\",\n",
    "\t\"Optimized Test Accuracy\",\n",
    "\t\"Optimized IR\",\n",
    "\t\"Reduction Rate %\",\n",
    "\t\"Optimized Test Acc Diff\"\n",
    "]\n",
    "\n",
    "# for run in runs:\n",
    "# \trows = [calculate_average_optimized_metrics((runs, run))]\n",
    "\t\n",
    "rows = Parallel(n_jobs=-1)(delayed(calculate_average_optimized_metrics)((runs, run)) for run in runs)\n",
    "table = pd.DataFrame(rows, columns=header)\n",
    "table.to_csv(\"final_results_FIXED.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 74/400 [3:17:01<14:27:59, 159.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m _, pareto_indicies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(result\u001b[38;5;241m.\u001b[39mF[fronts], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m min_indicies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(result\u001b[38;5;241m.\u001b[39mF[pareto_indicies], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m result_final \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mInstanceSelectionProblem_2_Obj_MinMaxAcc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mInheritedSampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmin_indicies\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rows_inherited\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmin_indicies\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m save_var \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     37\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28miter\u001b[39m,\n\u001b[0;32m     38\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_option,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m: (X_train, X_val, X_test, y_train, y_val, y_test)\n\u001b[0;32m     44\u001b[0m }\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n",
      "Cell \u001b[1;32mIn[5], line 275\u001b[0m, in \u001b[0;36mexecute_optimization\u001b[1;34m(X_train, y_train, X_val, y_val, problem_defn, sampler, pop_size)\u001b[0m\n\u001b[0;32m    266\u001b[0m problem \u001b[38;5;241m=\u001b[39m problem_defn(X_train, y_train, X_val, y_val)\n\u001b[0;32m    268\u001b[0m algorithm \u001b[38;5;241m=\u001b[39m NSGA2(\n\u001b[0;32m    269\u001b[0m \tpop_size\u001b[38;5;241m=\u001b[39mpop_size, \n\u001b[0;32m    270\u001b[0m \tsampling\u001b[38;5;241m=\u001b[39msampler, \n\u001b[0;32m    271\u001b[0m \tcrossover\u001b[38;5;241m=\u001b[39mHUX(), \n\u001b[0;32m    272\u001b[0m \tmutation\u001b[38;5;241m=\u001b[39mBitflipMutation(), \n\u001b[0;32m    273\u001b[0m \teliminate_duplicates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_gen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRANDOM_SEED\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymoo\\optimize.py:67\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(problem, algorithm, termination, copy_algorithm, copy_termination, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m     algorithm\u001b[38;5;241m.\u001b[39msetup(problem, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# actually execute the algorithm\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# store the deep copied algorithm in the result object\u001b[39;00m\n\u001b[0;32m     70\u001b[0m res\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m=\u001b[39m algorithm\n",
      "File \u001b[1;32mc:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymoo\\core\\algorithm.py:138\u001b[0m, in \u001b[0;36mAlgorithm.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_next():\n\u001b[1;32m--> 138\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[1;32mc:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymoo\\core\\algorithm.py:158\u001b[0m, in \u001b[0;36mAlgorithm.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# call the advance with them after evaluation\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m infills \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfills\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(infills\u001b[38;5;241m=\u001b[39minfills)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# if the algorithm does not follow the infill-advance scheme just call advance\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymoo\\core\\evaluator.py:69\u001b[0m, in \u001b[0;36mEvaluator.eval\u001b[1;34m(self, problem, pop, skip_already_evaluated, evaluate_values_of, count_evals, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# evaluate the solutions (if there are any)\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(I) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# do the actual evaluation - call the sub-function to set the corresponding values to the population\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop\u001b[49m\u001b[43m[\u001b[49m\u001b[43mI\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_values_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# update the function evaluation counter\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count_evals:\n",
      "File \u001b[1;32mc:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymoo\\core\\evaluator.py:90\u001b[0m, in \u001b[0;36mEvaluator._eval\u001b[1;34m(self, problem, pop, evaluate_values_of, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m X \u001b[38;5;241m=\u001b[39m pop\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# call the problem to evaluate the solutions\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_values_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate_values_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_as_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# for each of the attributes set it to the problem\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymoo\\core\\problem.py:257\u001b[0m, in \u001b[0;36mProblem.evaluate\u001b[1;34m(self, X, return_values_of, return_as_dictionary, *args, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     only_single_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, np\u001b[38;5;241m.\u001b[39mndarray))\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# this is where the actual evaluation takes place\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m _out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_values_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m out \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _out\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    261\u001b[0m \n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m# copy it to a numpy array (it might be one of jax at this point)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymoo\\core\\problem.py:299\u001b[0m, in \u001b[0;36mProblem.do\u001b[1;34m(self, X, return_values_of, *args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_elementwise(X, out, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# finally format the output dictionary\u001b[39;00m\n\u001b[0;32m    302\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_dict(out, \u001b[38;5;28mlen\u001b[39m(X), return_values_of)\n",
      "File \u001b[1;32mc:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymoo\\core\\problem.py:307\u001b[0m, in \u001b[0;36mProblem._evaluate_vectorized\u001b[1;34m(self, X, out, *args, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate_vectorized\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, out, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 173\u001b[0m, in \u001b[0;36mInstanceSelectionProblem_2_Obj_MinMaxAcc._evaluate\u001b[1;34m(self, x, out, *args, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, out, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 173\u001b[0m \tobjectives \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \tf1 \u001b[38;5;241m=\u001b[39m [obj[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m objectives] \u001b[38;5;66;03m# Class 0 error\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \tf2 \u001b[38;5;241m=\u001b[39m [obj[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m objectives] \u001b[38;5;66;03m# Class 1 error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# with tqdm(total=1200) as pbar:\n",
    "count = 0\n",
    "with tqdm(total=400) as pbar:\n",
    "\tfor iter in range(10):\n",
    "\t\tfor data_option in ['over_sample', 'regular_sample']:\n",
    "\t\t\tfor init_pop in ['rand', 'bias']:\n",
    "\t\t\t\t\tfor folder in os.listdir('Datasets'):\n",
    "\t\t\t\t\t\tpbar.update(1)\n",
    "\t\t\t\t\t\toptimization = \"MultiStep\"\n",
    "\t\t\t\t\t\tsave_name = f\"Experiments//{iter}__{data_option}__{init_pop}__{optimization}__{folder}.pickle\"\n",
    "\t\t\t\t\t\t# print(save_name)\n",
    "\t\t\t\t\t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(\n",
    "\t\t\t\t\t\t\tos.path.join('Datasets', folder, f\"{folder}.csv\"), \n",
    "\t\t\t\t\t\t\tfolder, \n",
    "\t\t\t\t\t\t\tover_sample=True if data_option == \"over_sample\" else False\n",
    "\t\t\t\t\t\t)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tinitial_population = BinaryRandomSampling() if init_pop == \"rand\" else BiasedBinarySampling(y_train, 0.5, 0.7)\n",
    "\t\t\t\t\t\tresult = execute_optimization(\n",
    "\t\t\t\t\t\t\tX_train, y_train, X_val, y_val, \n",
    "\t\t\t\t\t\t\tInstanceSelectionProblem_3_Obj, \n",
    "\t\t\t\t\t\t\tinitial_population,\n",
    "\t\t\t\t\t\t\tpop_size=100\n",
    "\t\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\t\tfronts = NonDominatedSorting().do(result.F, only_non_dominated_front=True)\n",
    "\t\t\t\t\t\t_, pareto_indicies = np.unique(result.F[fronts], axis=0, return_index=True)\n",
    "\n",
    "\t\t\t\t\t\tmin_indicies = np.argmin(result.F[pareto_indicies], axis=0)\n",
    "\t\t\t\t\t\tresult_final = execute_optimization(\n",
    "\t\t\t\t\t\t\tX_train, y_train, X_val, y_val, \n",
    "\t\t\t\t\t\t\tInstanceSelectionProblem_2_Obj_MinMaxAcc, \n",
    "\t\t\t\t\t\t\tInheritedSampling(result.X[min_indicies], mutation_prob=0.0, num_rows_inherited=len(min_indicies))\n",
    "\t\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\t\tsave_var = {\n",
    "\t\t\t\t\t\t\t\"iter\": iter,\n",
    "\t\t\t\t\t\t\t\"Sampler\": data_option,\n",
    "\t\t\t\t\t\t\t\"Population\": init_pop,\n",
    "\t\t\t\t\t\t\t\"Optimization\": optimization,\n",
    "\t\t\t\t\t\t\t\"Dataset\": folder,\n",
    "\t\t\t\t\t\t\t\"Result\": result_final,\n",
    "\t\t\t\t\t\t\t\"Data\": (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "\t\t\t\t\t\t}\n",
    "\n",
    "\t\t\t\t\t\twith open(save_name, \"wb\") as fh:\n",
    "\t\t\t\t\t\t\tpickle.dump(save_var, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\tcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def execute_multi_step(folder):\n",
    "\n",
    "\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(\n",
    "\t\tos.path.join('Datasets', folder, f\"{folder}.csv\"), \n",
    "\t\tfolder, \n",
    "\t\tover_sample=False\n",
    "\t)\n",
    "\n",
    "\tresult = execute_optimization(\n",
    "\t\tX_train, y_train, X_val, y_val, \n",
    "\t\tInstanceSelectionProblem_3_Obj, \n",
    "\t\tBinaryRandomSampling()\n",
    "\t)\n",
    "\tfronts = NonDominatedSorting().do(result.F, only_non_dominated_front=True)\n",
    "\t_, pareto_indicies = np.unique(result.F[fronts], axis=0, return_index=True)\n",
    "\t_, _, x_filtered, y_filtered = select_optimal_instance(X_train, y_train, X_val, y_val, result)\n",
    "\n",
    "\toptimization_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\toptimization_knn.fit(x_filtered, y_filtered)\n",
    "\ty_pred = optimization_knn.predict(X_test)\n",
    "\tr1_test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\tmin_indicies = np.argmin(result.F[pareto_indicies], axis=0)\n",
    "\tresult_final = execute_optimization(\n",
    "\t\tX_train, y_train, X_val, y_val, \n",
    "\t\tInstanceSelectionProblem_2_Obj_MinMaxAcc, \n",
    "\t\tInheritedSampling(result.X[min_indicies], mutation_prob=0.0, num_rows_inherited=len(min_indicies))\n",
    "\t)\n",
    "\t_, _, x_filtered, y_filtered = select_optimal_instance(X_train, y_train, X_val, y_val, result_final)\n",
    "\n",
    "\toptimization_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\toptimization_knn.fit(x_filtered, y_filtered)\n",
    "\ty_pred = optimization_knn.predict(X_test)\n",
    "\tr2_test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\trow = [\n",
    "\t\tdataset,\n",
    "\t\tdata_option,\n",
    "\t\tinit_pop,\n",
    "\t\t\"MultiStep\",\n",
    "\t\taverages['Baseline Test Accuracy'],\n",
    "\t\taverages['Baseline IR'],\n",
    "\t\taverages['Optimized Test Accuracy'],\n",
    "\t\taverages['Optimized IR'],\n",
    "\t\taverages['Reduction Rate %'],\n",
    "\t\taverages['Optimized Test Accuracy'] - averages['Baseline Test Accuracy']\n",
    "\t]\n",
    "\n",
    "\treturn row\n",
    "\n",
    "names = ['australia-3Obj-Biased-regular-Sample', 'Round 2', 'MinMaj cold start']\n",
    "for folder in os.listdir('Datasets'):\n",
    "\tdo_parallel(folder)\n",
    "\t# results = Parallel(n_jobs=-1)(delayed(do_parallel)(folder) for _ in range(10))\n",
    "\t# pd.DataFrame(results, columns=names).to_csv(\"save_1.csv\", index=False)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_parallel(folder):\n",
    "\n",
    "\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(\n",
    "\t\tos.path.join('Datasets', folder, f\"{folder}.csv\"), \n",
    "\t\tfolder, \n",
    "\t\tover_sample=False\n",
    "\t)\n",
    "\t\n",
    "\n",
    "\n",
    "\tresult = execute_optimization(\n",
    "\t\tX_train, y_train, X_val, y_val, \n",
    "\t\tInstanceSelectionProblem_2_Obj, \n",
    "\t\tBiasedBinarySampling(y_train, 0.5, 0.7)\n",
    "\t)\n",
    "\tfronts = NonDominatedSorting().do(result.F, only_non_dominated_front=True)\n",
    "\t_, pareto_indicies = np.unique(result.F[fronts], axis=0, return_index=True)\n",
    "\tbest_acc_1, best_instance_idx, x_filtered, y_filtered = select_optimal_instance(X_train, y_train, X_val, y_val, result)\n",
    "\tprint(f\"Round 1: {best_acc_1}\")\n",
    "\n",
    "\toptimization_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\toptimization_knn.fit(x_filtered, y_filtered)\n",
    "\ty_pred = optimization_knn.predict(X_test)\n",
    "\tr1_test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\tmin_indicies = np.argmin(result.F[fronts], axis=0)\n",
    "\n",
    "\n",
    "\tresult_final = execute_optimization(\n",
    "\t\tX_train, y_train, X_val, y_val, \n",
    "\t\tInstanceSelectionProblem_2_Obj_MinMaxAcc, \n",
    "\t\tInheritedSampling(result.X[min_indicies], mutation_prob=0.0, num_rows_inherited=len(min_indicies))\n",
    "\t)\n",
    "\tfronts = NonDominatedSorting().do(result_final.F, only_non_dominated_front=True)\n",
    "\t_, pareto_indicies = np.unique(result_final.F[fronts], axis=0, return_index=True)\n",
    "\tbest_acc_2, best_instance_idx, x_filtered, y_filtered = select_optimal_instance(X_train, y_train, X_val, y_val, result_final)\n",
    "\tprint(f\"Round 2: {best_acc_2}\")\t\n",
    "\n",
    "\n",
    "\n",
    "\toptimization_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\toptimization_knn.fit(x_filtered, y_filtered)\n",
    "\ty_pred = optimization_knn.predict(X_test)\n",
    "\tr2_test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\tresult = execute_optimization(\n",
    "\t\tX_train, y_train, X_val, y_val, \n",
    "\t\tInstanceSelectionProblem_2_Obj_MinMaxAcc, \n",
    "\t\tBinaryRandomSampling(),\n",
    "\t\tpop_size=200\n",
    "\t)\n",
    "\tfronts = NonDominatedSorting().do(result.F, only_non_dominated_front=True)\n",
    "\t_, pareto_indicies = np.unique(result.F[fronts], axis=0, return_index=True)\n",
    "\tbest_acc_3, best_instance_idx, x_filtered, y_filtered = select_optimal_instance(X_train, y_train, X_val, y_val, result)\n",
    "\tprint(f\"Cold start MinMajAcc: {best_acc_3}\\n\")\n",
    "\n",
    "\toptimization_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\toptimization_knn.fit(x_filtered, y_filtered)\n",
    "\ty_pred = optimization_knn.predict(X_test)\n",
    "\tr3_test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\treturn [r1_test_acc, r2_test_acc, r3_test_acc]\n",
    "\n",
    "names = ['australia-3Obj-Biased-regular-Sample', 'Round 2', 'MinMaj cold start']\n",
    "for folder in os.listdir('Datasets'):\n",
    "\tresults = Parallel(n_jobs=-1)(delayed(do_parallel)(folder) for _ in range(10))\n",
    "\tpd.DataFrame(results, columns=names).to_csv(\"save_2.csv\", index=False)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
