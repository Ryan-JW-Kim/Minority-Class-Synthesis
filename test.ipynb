{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from execution_schemes import *\n",
    "from main import *\n",
    "\n",
    "from src import *\n",
    "datasets = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "from pymoo.operators.sampling.rnd import BinaryRandomSampling\n",
    "from pymoo.operators.crossover.hux import HUX\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.indicators.hv import Hypervolume\n",
    "from pymoo.core.mutation import Mutation\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def prepare_splits(x, y):\n",
    "\ttrain_split = StratifiedShuffleSplit(\n",
    "\t\tn_splits=31, \n",
    "\t\ttest_size=0.5\n",
    "\t)\n",
    "\tsplits = []\n",
    "\tfor train_idx, temp_idx in train_split.split(x, y):\n",
    "\t\ttest_split = StratifiedShuffleSplit(\n",
    "\t\t\tn_splits=1, \n",
    "\t\t\ttest_size=0.5\n",
    "\t\t)\n",
    "\t\ttest_idx, validation_idx = next(test_split.split(x[temp_idx], y[temp_idx]))\n",
    "\n",
    "\t\tvalidation_idx = temp_idx[validation_idx]\n",
    "\t\ttest_idx = temp_idx[test_idx]\n",
    "\t\t\n",
    "\t\tsplits.append((train_idx, validation_idx, test_idx))\n",
    "\treturn splits\n",
    "\n",
    "def create_preprocessor_pipeline(variables):\n",
    "\t\n",
    "\ttype_mappings = {}\n",
    "\tfor variable_idx, variable_name in enumerate(variables['name']):\n",
    "\t\tvariable_type = variables['type'][variable_idx]\n",
    "\t\tif variable_type not in type_mappings:\n",
    "\t\t\ttype_mappings[variable_type] = []\n",
    "\n",
    "\t\tif variables['role'][variable_idx] == 'Feature':\n",
    "\t\t\ttype_mappings[variable_type].append(variable_name)\n",
    "\n",
    "\tcategorical_transformer = Pipeline(steps=[\n",
    "\t\t('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "\t\t('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "\t])\n",
    "\tnumerical_transformer = Pipeline(steps=[\n",
    "\t\t('imputer', SimpleImputer(strategy='mean')),\n",
    "\t\t('scaler', StandardScaler())\n",
    "\t])\n",
    "\n",
    "\tnumerical_features = []\n",
    "\tif 'Continuous' in type_mappings:\n",
    "\t\tfor feature in type_mappings['Continuous']:\n",
    "\t\t\tnumerical_features.append(feature)\n",
    "\tif 'Integer' in type_mappings:\n",
    "\t\tfor feature in type_mappings['Integer']:\n",
    "\t\t\tnumerical_features.append(feature)\n",
    "\t\t\t\n",
    "\ttransformer_steps = []\n",
    "\tif numerical_features != []:\n",
    "\t\ttransformer_steps.append(\n",
    "\t\t\t('num', numerical_transformer, numerical_features)\n",
    "\t\t)\n",
    "\tif 'Categorical' in type_mappings:\n",
    "\t\ttransformer_steps.append(\n",
    "\t\t\t('cat', categorical_transformer, type_mappings['Categorical'])\n",
    "\t\t)\n",
    "\tpreprocessor = ColumnTransformer(\n",
    "\t\ttransformers=transformer_steps\n",
    "\t)\n",
    "\tpipeline = Pipeline(steps=[\n",
    "\t\t('preprocessor', preprocessor)\n",
    "\t])\n",
    "\t\n",
    "\treturn pipeline\n",
    "\n",
    "def over_sample(x, y):\n",
    "\tcounts = pd.DataFrame(y).value_counts()\n",
    "\tminority_class_label = counts.index[np.argmin(counts)][0]\n",
    "\tminority_class_indicies = np.where(y == minority_class_label)[0]\n",
    "\tover_sampled_x = np.concatenate((x, x[minority_class_indicies]), axis=0)\n",
    "\tover_sampled_y = np.concatenate((y, y[minority_class_indicies]), axis=0)\n",
    "\treturn over_sampled_x, over_sampled_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericOptimizer(Problem):\n",
    "\tpopulation_size = 100\n",
    "\tn_neighbours = 5\n",
    "\tsequential = False\n",
    "\tdef __init__(self, X_train, y_train, X_val, y_val, objectives, exec_mode):\n",
    "\t\tself.mutation_history = {}\n",
    "\t\tself.generation_number = 0\n",
    "\n",
    "\t\tself.exec_mode = exec_mode\n",
    "\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\n",
    "\t\tself.X_val = X_val\n",
    "\t\tself.y_val = y_val\n",
    "\n",
    "\t\tself.training_data = X_train\n",
    "\t\tself.n_instances = X_train.shape[0]\n",
    "\t\t\n",
    "\t\tself.objectives = objectives\n",
    "\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tn_var=self.n_instances,\n",
    "\t\t\tn_obj=len(objectives),               \n",
    "\t\t\tn_constr=0,            \n",
    "\t\t\txl=0,                  \n",
    "\t\t\txu=1,                  \n",
    "\t\t\ttype_var=np.bool_,     \n",
    "\t\t)\n",
    "\n",
    "\tdef _evaluate(self, x, out, *args, **kwargs):\n",
    "\t\t\n",
    "\t\tif self.exec_mode == \"sequential\":\n",
    "\t\t\tmetrics = []\n",
    "\t\t\tfor objective in self.objectives:\n",
    "\t\t\t\tmetrics.append(self.eval_objective((objective, x)))\n",
    "\t\telse:\n",
    "\t\t\tmetrics = Parallel(n_jobs=-1)(delayed(self.eval_objective)((objective, x)) for objective in self.objectives)\n",
    "\t\t\n",
    "\t\tself.generation_number += 1\n",
    "\n",
    "\t\tout[\"F\"] = np.column_stack(metrics)\n",
    "\n",
    "\tdef eval_objective(self, pack):\n",
    "\t\tobjective, x = pack\n",
    "\t\t\t\n",
    "\t\tif \"calculate_num_examples\" in repr(objective):\n",
    "\t\t\treturn GenericOptimizer.calculate_num_examples(x)\n",
    "\n",
    "\t\telif \"calculate_IR\" in repr(objective):\n",
    "\t\t\tvals = []\n",
    "\t\t\tfor instance in x:\n",
    "\t\t\t\tvals.append(GenericOptimizer.calculate_IR(self.y_train[instance]))\n",
    "\t\t\treturn vals\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tvals = []\n",
    "\t\t\tfor instance in x:\n",
    "\t\t\t\tvals.append(objective(\n",
    "\t\t\t\t\tself.X_train[instance],\n",
    "\t\t\t\t\tself.y_train[instance],\n",
    "\t\t\t\t\tself.X_val,\n",
    "\t\t\t\t\tself.y_val,\n",
    "\t\t\t\t\tGenericOptimizer.n_neighbours\n",
    "\t\t\t\t))\n",
    "\t\t\treturn vals\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_IR(cls, y):\n",
    "\t\tdf = pd.DataFrame(y).value_counts()\n",
    "\t\treturn (df[1]/df[0]) if df.min() == 0 else (df[0]/df[1])\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef filter_by_class(cls, x, y, label):\n",
    "\t\tindices = np.where(y==label)\n",
    "\t\treturn x[indices], y[indices]\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tacc = accuracy_score(y_val, y_pred)\n",
    "\t\t\treturn 1-acc\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 0)\n",
    "\t\terr = cls.calculate_overall_error(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn err\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 1)\n",
    "\t\terr = cls.calculate_overall_error(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn err\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tf1 = f1_score(y_val, y_pred)\n",
    "\t\t\treturn 1-f1\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 0)\n",
    "\t\tinv_f1 = cls.calculate_overall_inverse_f1(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_f1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 1)\n",
    "\t\tinv_f1 = cls.calculate_overall_inverse_f1(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_f1\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_inverse_precision(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tprec = precision_score(y_val, y_pred)\n",
    "\t\t\treturn 1-prec\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_inverse_precision(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 0)\n",
    "\t\tinv_prec = cls.calculate_overall_inverse_precision(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_prec\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_inverse_precision(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 1)\n",
    "\t\tinv_prec = cls.calculate_overall_inverse_precision(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_prec\n",
    "\t\t\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_inverse_recall(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\trecall = recall_score(y_val, y_pred)\n",
    "\t\t\treturn 1-recall\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_inverse_recall(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 0)\n",
    "\t\tinv_recall = cls.calculate_overall_inverse_recall(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_recall\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_inverse_recall(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_train, class0_y_train = cls.filter_by_class(x_train, y_train, 1)\n",
    "\t\tinv_recall = cls.calculate_overall_inverse_recall(\n",
    "\t\t\tclass0_x_train,\n",
    "\t\t\tclass0_y_train,\n",
    "\t\t\tx_val,\n",
    "\t\t\ty_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_recall\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_num_examples(cls, instances):\n",
    "\t\treturn np.sum(instances, axis=1)\n",
    "\n",
    "\t@classmethod\n",
    "\tdef quantify_performance(cls, population, objectives, x_train, y_train, x_validation, y_validation, x_test, y_test):\n",
    "\t\tpass\n",
    "\n",
    "\t@classmethod\n",
    "\tdef unbound_eval_objectives(cls, objective, instances, x_train, y_train, x_validation, y_validation):\n",
    "\t\tif \"calculate_num_examples\" in repr(objective):\n",
    "\t\t\treturn GenericOptimizer.calculate_num_examples(instances)\n",
    "\n",
    "\t\telif \"calculate_IR\" in repr(objective):\n",
    "\t\t\tvals = []\n",
    "\t\t\tfor instance in instances:\n",
    "\t\t\t\tvals.append(GenericOptimizer.calculate_IR(y_train[instance]))\n",
    "\t\t\treturn vals\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tvals = []\n",
    "\t\t\tfor instance in instances:\n",
    "\t\t\t\tvals.append(objective(\n",
    "\t\t\t\t\tx_train[instance],\n",
    "\t\t\t\t\ty_train[instance],\n",
    "\t\t\t\t\tx_validation,\n",
    "\t\t\t\t\ty_validation,\n",
    "\t\t\t\t\tGenericOptimizer.n_neighbours\n",
    "\t\t\t\t))\n",
    "\t\t\treturn vals\n",
    "\t\t\n",
    "\t@classmethod\n",
    "\tdef calculate_optimal_instance(cls, x_train, y_train, x_val, y_val, metrics, population, n):\n",
    "\n",
    "\t\tfronts = NonDominatedSorting().do(metrics, only_non_dominated_front=True)\n",
    "\t\t_, pareto_indicies = np.unique(metrics[fronts], axis=0, return_index=True)\n",
    "\n",
    "\t\tbest_acc = 0\n",
    "\t\tbest_instance = None\n",
    "\t\tfor idx, instance in enumerate(population[pareto_indicies]):\n",
    "\t\t\tx_filtered, y_filtered = x_train[instance], y_train[instance]\n",
    "\t\t\tif x_filtered.shape[0] < n: \n",
    "\t\t\t\tacc = 0\n",
    "\t\t\telse:\n",
    "\t\t\t\tknn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\t\tknn.fit(x_filtered, y_filtered)\n",
    "\t\t\t\ty_pred = knn.predict(x_val)\n",
    "\t\t\t\tacc = accuracy_score(y_val, y_pred)\n",
    "\t\t\t\n",
    "\t\t\t\tif acc > best_acc:\n",
    "\t\t\t\t\tbest_acc = acc\n",
    "\t\t\t\t\tbest_instance = instance\n",
    "\t\t\t\t\n",
    "\t\treturn pareto_indicies, x_train[best_instance], y_train[best_instance]\n",
    "\t  \n",
    "class BiasedBinarySampling(Sampling):\n",
    "\tdef __init__(self, labels, major_prob, minor_prob):\n",
    "\t\t\n",
    "\t\tself.labels = labels\n",
    "\t\tcounts = pd.DataFrame(labels).value_counts()\n",
    "\t\tif counts[0] > counts[1]:\n",
    "\t\t\tself.c0_thresh = major_prob\n",
    "\t\t\tself.c1_thresh = minor_prob\n",
    "\t\telse:\n",
    "\t\t\tself.c0_thresh = minor_prob\n",
    "\t\t\tself.c1_thresh = major_prob\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef _do(self, problem, n_samples, **kwargs):\n",
    "\n",
    "\t\trands = np.random.random((n_samples, problem.n_var))\n",
    "\t\tinit_pops = np.zeros((n_samples, problem.n_var), dtype=bool)\n",
    "\t\tfor idx, label in enumerate(self.labels):\n",
    "\t\t\tif label == 0:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c0_thresh).astype(bool)\n",
    "\t\t\tif label == 1:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c1_thresh).astype(bool)\n",
    "\n",
    "\n",
    "\t\treturn init_pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overSample_randPop_execute(package):\n",
    "\tx, y, train_idx, validation_idx, test_idx, objectives, run_name = package\n",
    "\tx_train, y_train = x[train_idx], y[train_idx]\n",
    "\tx_validation, y_validation = x[validation_idx], y[validation_idx]\n",
    "\tx_train, y_train = over_sample(\n",
    "\t\tx_train, \n",
    "\t\ty_train\n",
    "\t)\n",
    "\tproblem = GenericOptimizer(\n",
    "\t\tx_train, \n",
    "\t\ty_train, \n",
    "\t\tx_validation, \n",
    "\t\ty_validation,\n",
    "\t\tobjectives,\n",
    "\t\t\"Sequential\"\n",
    "\t)\t# BiasedBinarySampling(y_train, 0.5, 0.7)\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\tsampling=BinaryRandomSampling(), \n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True,\n",
    "\t)\n",
    "\tresult = minimize(\n",
    "\t\tproblem, \n",
    "\t\talgorithm, \n",
    "\t\t('n_gen', GenericOptimizer.population_size),\n",
    "\t\tsave_history=True\n",
    "\t)\n",
    "\tpackage = {\n",
    "\t\t\"name\": run_name,\n",
    "\t\t\"train\": train_idx,\n",
    "\t\t\"validation\": validation_idx,\n",
    "\t\t\"test\": test_idx,\n",
    "\t\t\"result\": result\n",
    "\t}\n",
    "\treturn package\n",
    "\n",
    "def regularSample_randPop_execute(package):\n",
    "\tx, y, train_idx, validation_idx, test_idx, objectives, run_name = package\n",
    "\tx_train, y_train = x[train_idx], y[train_idx]\n",
    "\tx_validation, y_validation = x[validation_idx], y[validation_idx]\n",
    "\tproblem = GenericOptimizer(\n",
    "\t\tx_train, \n",
    "\t\ty_train, \n",
    "\t\tx_validation, \n",
    "\t\ty_validation,\n",
    "\t\tobjectives,\n",
    "\t\t\"Sequential\"\n",
    "\t)\t# BiasedBinarySampling(y_train, 0.5, 0.7)\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\tsampling=BinaryRandomSampling(), \n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True,\n",
    "\t)\n",
    "\tresult = minimize(\n",
    "\t\tproblem, \n",
    "\t\talgorithm, \n",
    "\t\t('n_gen', GenericOptimizer.population_size),\n",
    "\t\tsave_history=True\n",
    "\t)\n",
    "\tpackage = {\n",
    "\t\t\"name\": run_name,\n",
    "\t\t\"train\": train_idx,\n",
    "\t\t\"validation\": validation_idx,\n",
    "\t\t\"test\": test_idx,\n",
    "\t\t\"result\": result\n",
    "\t}\n",
    "\treturn package\n",
    "\n",
    "def overSample_biasPop_execute(package):\n",
    "\tx, y, train_idx, validation_idx, test_idx, objectives, run_name = package\n",
    "\tx_train, y_train = x[train_idx], y[train_idx]\n",
    "\tx_validation, y_validation = x[validation_idx], y[validation_idx]\n",
    "\tx_train, y_train = over_sample(\n",
    "\t\tx_train, \n",
    "\t\ty_train\n",
    "\t)\n",
    "\tproblem = GenericOptimizer(\n",
    "\t\tx_train, \n",
    "\t\ty_train, \n",
    "\t\tx_validation, \n",
    "\t\ty_validation,\n",
    "\t\tobjectives,\n",
    "\t\t\"Sequential\"\n",
    "\t)\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\tsampling=BiasedBinarySampling(y_train, 0.5, 0.7), \n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True,\n",
    "\t)\n",
    "\tresult = minimize(\n",
    "\t\tproblem, \n",
    "\t\talgorithm, \n",
    "\t\t('n_gen', GenericOptimizer.population_size),\n",
    "\t\tsave_history=True\n",
    "\t)\n",
    "\tpackage = {\n",
    "\t\t\"name\": run_name,\n",
    "\t\t\"train\": train_idx,\n",
    "\t\t\"validation\": validation_idx,\n",
    "\t\t\"test\": test_idx,\n",
    "\t\t\"result\": result\n",
    "\t}\n",
    "\treturn package\n",
    "\n",
    "def regularSample_biasPop_execute(package):\n",
    "\tx, y, train_idx, validation_idx, test_idx, objectives, run_name = package\n",
    "\tx_train, y_train = x[train_idx], y[train_idx]\n",
    "\tx_validation, y_validation = x[validation_idx], y[validation_idx]\n",
    "\tproblem = GenericOptimizer(\n",
    "\t\tx_train, \n",
    "\t\ty_train, \n",
    "\t\tx_validation, \n",
    "\t\ty_validation,\n",
    "\t\tobjectives,\n",
    "\t\t\"Sequential\"\n",
    "\t)\t# BiasedBinarySampling(y_train, 0.5, 0.7)\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\tsampling=BiasedBinarySampling(y_train, 0.5, 0.7), \n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True,\n",
    "\t)\n",
    "\tresult = minimize(\n",
    "\t\tproblem, \n",
    "\t\talgorithm, \n",
    "\t\t('n_gen', GenericOptimizer.population_size),\n",
    "\t\tsave_history=True\n",
    "\t)\n",
    "\tpackage = {\n",
    "\t\t\"name\": run_name,\n",
    "\t\t\"train\": train_idx,\n",
    "\t\t\"validation\": validation_idx,\n",
    "\t\t\"test\": test_idx,\n",
    "\t\t\"result\": result\n",
    "\t}\n",
    "\treturn package\n",
    "\n",
    "objectives_sets = evaluation_schemes = [\n",
    "\t[GenericOptimizer.calculate_overall_error, GenericOptimizer.calculate_num_examples],\n",
    "\t[GenericOptimizer.calculate_overall_error, GenericOptimizer.calculate_overall_inverse_f1, GenericOptimizer.calculate_num_examples],\n",
    "\t[GenericOptimizer.calculate_class0_error, GenericOptimizer.calculate_class1_error],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Code\\3_13_venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "for dataset, name in datasets:\n",
    "\t\n",
    "\traw_X, y = dataset.data.features, dataset.data.targets\n",
    "\tpipeline = create_preprocessor_pipeline(dataset.variables)\n",
    "\tpipeline.fit(raw_X, y)\n",
    "\tX = pipeline.transform(raw_X)\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\ty = label_encoder.fit_transform(y)\n",
    "\n",
    "\t# =======================================================================\n",
    "\t# =======================================================================\n",
    "\t# =======================================================================\n",
    "\n",
    "\tpackages = []\n",
    "\tfor c, (train_idx, validation_idx, test_idx) in enumerate(prepare_splits(X, y)):\n",
    "\t\tfor objectives in objectives_sets:\n",
    "\t\t\tobjectives_names = [re.search(r'\\.([a-zA-Z_][a-zA-Z0-9_]*)\\s', str(objective_name)).group(1) for objective_name in objectives]\n",
    "\t\t\tobjectives_names = '_'.join(objectives_names)\t\t\t\n",
    "\t\t\tpackages.append((X, y, train_idx, validation_idx, test_idx, objectives, f\"{c}_{name} {objectives_names} overSample_randPop\"))\n",
    "\n",
    "\tresults = Parallel(n_jobs=-1)(delayed(overSample_randPop_execute)(package) for package in packages)\n",
    "\tfor result in results:\n",
    "\t\twith open(os.path.join(\"results\", f\"{result['name']}.pickle\"), 'wb') as fh:\n",
    "\t\t\tpickle.dump(result, fh)\t\n",
    "\t\n",
    "\t# =======================================================================\n",
    "\t# =======================================================================\n",
    "\t# =======================================================================\n",
    "\t\n",
    "\tpackages = []\n",
    "\tfor c, (train_idx, validation_idx, test_idx) in enumerate(prepare_splits(X, y)):\n",
    "\t\tfor objectives in objectives_sets:\n",
    "\t\t\tobjectives_names = [re.search(r'\\.([a-zA-Z_][a-zA-Z0-9_]*)\\s', str(objective_name)).group(1) for objective_name in objectives]\n",
    "\t\t\tobjectives_names = '_'.join(objectives_names)\t\t\t\n",
    "\t\t\tpackages.append((X, y, train_idx, validation_idx, test_idx, objectives, f\"{c}_{name} {objectives_names} overSample_randPop\"))\n",
    "\n",
    "\tresults = Parallel(n_jobs=-1)(delayed(overSample_randPop_execute)(package) for package in packages)\n",
    "\tfor result in results:\n",
    "\t\twith open(os.path.join(\"results\", f\"{result['name']}.pickle\"), 'wb') as fh:\n",
    "\t\t\tpickle.dump(result, fh)\t\n",
    "\n",
    "\t# =======================================================================\n",
    "\t# =======================================================================\n",
    "\t# =======================================================================\n",
    "\t\n",
    "\tpackages = []\n",
    "\tfor c, (train_idx, validation_idx, test_idx) in enumerate(prepare_splits(X, y)):\n",
    "\t\tfor objectives in objectives_sets:\n",
    "\t\t\tobjectives_names = [re.search(r'\\.([a-zA-Z_][a-zA-Z0-9_]*)\\s', str(objective_name)).group(1) for objective_name in objectives]\n",
    "\t\t\tobjectives_names = '_'.join(objectives_names)\t\t\t\n",
    "\t\t\tpackages.append((X, y, train_idx, validation_idx, test_idx, objectives, f\"{c}_{name} {objectives_names} overSample_randPop\"))\n",
    "\n",
    "\tresults = Parallel(n_jobs=-1)(delayed(overSample_randPop_execute)(package) for package in packages)\n",
    "\tfor result in results:\n",
    "\t\twith open(os.path.join(\"results\", f\"{result['name']}.pickle\"), 'wb') as fh:\n",
    "\t\t\tpickle.dump(result, fh)\t\n",
    "\n",
    "\t# =======================================================================\n",
    "\t# =======================================================================\n",
    "\t# =======================================================================\n",
    "\n",
    "\tpackages = []\n",
    "\tfor c, (train_idx, validation_idx, test_idx) in enumerate(prepare_splits(X, y)):\n",
    "\t\tfor objectives in objectives_sets:\n",
    "\t\t\tobjectives_names = [re.search(r'\\.([a-zA-Z_][a-zA-Z0-9_]*)\\s', str(objective_name)).group(1) for objective_name in objectives]\n",
    "\t\t\tobjectives_names = '_'.join(objectives_names)\t\t\t\n",
    "\t\t\tpackages.append((X, y, train_idx, validation_idx, test_idx, objectives, f\"{c}_{name} {objectives_names} overSample_randPop\"))\n",
    "\n",
    "\tresults = Parallel(n_jobs=-1)(delayed(overSample_randPop_execute)(package) for package in packages)\n",
    "\tfor result in results:\n",
    "\t\twith open(os.path.join(\"results\", f\"{result['name']}.pickle\"), 'wb') as fh:\n",
    "\t\t\tpickle.dump(result, fh)\t\n",
    "\tbreak"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3_13_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
