{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27640ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "from pymoo.operators.sampling.rnd import BinaryRandomSampling\n",
    "from pymoo.operators.crossover.hux import HUX\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.indicators.hv import Hypervolume\n",
    "from pymoo.core.mutation import Mutation\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5061f3f9",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0add49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_UCI_datasets():\n",
    "\tdatasets = [\n",
    "\t\t(fetch_ucirepo(id=52), \"ionosphere\"),\n",
    "\t\t(fetch_ucirepo(id=43), \"haberman\"),\n",
    "\t\t(fetch_ucirepo(id=53), \"iris0\"),\n",
    "\t\t(fetch_ucirepo(id=42), \"glass1\"),\n",
    "\t\t(fetch_ucirepo(id=143), \"australia\"),\n",
    "\t\t(fetch_ucirepo(id=277), \"thoracic\"),\n",
    "\t\t(fetch_ucirepo(id=50), \"segment0\"),\n",
    "\t\t# (fetch_ucirepo(id=149), \"vehicle0\"),\n",
    "\t\t(fetch_ucirepo(id=109), \"wine\"),\n",
    "\t\t# (fetch_ucirepo(id=39), \"ecoli\"),\n",
    "\t\t(fetch_ucirepo(id=225), \"ILPD\"),\n",
    "\t\t(fetch_ucirepo(id=45), \"heart_disease\"),\n",
    "\t\t(fetch_ucirepo(id=17), \"wisconsin\"),\n",
    "\t\t# (fetch_ucirepo(id=73), \"mushroom\"),\n",
    "\t\t(fetch_ucirepo(id=94), \"spambase\"),\n",
    "\t\t(fetch_ucirepo(id=161), \"mammographic\"),\n",
    "\t\t# (fetch_ucirepo(id=12), \"balance\"),\n",
    "\t\t(fetch_ucirepo(id=110), \"yeast1\"),\n",
    "\t\t(fetch_ucirepo(id=451), \"coimbra\"),\n",
    "\t\t(fetch_ucirepo(id=244), \"fertility\")\n",
    "\t]\n",
    "\n",
    "\treturn datasets\n",
    "\n",
    "def load_KEEL_dataset(path):\n",
    "\twith open(path, 'r') as fh:\n",
    "\t\tlines = fh.readlines()\n",
    "\t\n",
    "\trelation_name = ''\n",
    "\tattributes = []\n",
    "\tattribute_types = {}\n",
    "\tdata_lines = []\n",
    "\tin_data_section = False\n",
    "\n",
    "\tfor line in lines:\n",
    "\t\tline = line.strip()\n",
    "\t\tif line.startswith('@relation'):\n",
    "\t\t\trelation_name = line.split()[1]\n",
    "\t\telif line.startswith('@attribute'):\n",
    "\t\t\t# Match attribute lines with types and optional ranges or enumerations\n",
    "\t\t\tmatch = re.match(r'@attribute\\s+(\\w+)\\s+(\\w+)(?:\\s+\\[.*?\\])?', line)\n",
    "\t\t\tif match:\n",
    "\t\t\t\tattr_name, attr_type = match.groups()\n",
    "\t\t\t\tattributes.append(attr_name)\n",
    "\t\t\t\tattribute_types[attr_name] = attr_type\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Match attribute lines with enumerated types\n",
    "\t\t\t\tmatch_enum = re.match(r'@attribute\\s+(\\w+)\\s+\\{.*?\\}', line)\n",
    "\t\t\t\tif match_enum:\n",
    "\t\t\t\t\tattr_name = match_enum.group(1)\n",
    "\t\t\t\t\tattributes.append(attr_name)\n",
    "\t\t\t\t\tattribute_types[attr_name] = 'categorical'\n",
    "\t\telif line.startswith('@data'):\n",
    "\t\t\tin_data_section = True\n",
    "\t\telif in_data_section:\n",
    "\t\t\tif line and not line.startswith('@'):\n",
    "\t\t\t\tdata_lines.append(line)\n",
    "\n",
    "\t# Create DataFrame from data lines\n",
    "\tdata_str = '\\n'.join(data_lines)\n",
    "\tdf = pd.read_csv(StringIO(data_str), header=None, names=attributes)\n",
    "\n",
    "\treturn df, attribute_types\n",
    "\t# attributes = []\n",
    "\t# attribute_types = {}\n",
    "\n",
    "\t# for line in data_text.split(\"\\n\"):\n",
    "\t# \tif line.startswith(\"@attribute\"):\n",
    "\t# \t\tparts = re.match(r'@attribute (\\w+) (real|\\{.*\\})', line)\n",
    "\t# \t\tif parts:\n",
    "\t# \t\t\tattr_name = parts.group(1)\n",
    "\t# \t\t\tattr_type = parts.group(2)\n",
    "\t# \t\t\tattributes.append(attr_name)\n",
    "\t# \t\t\tattribute_types[attr_name] = attr_type\n",
    "\n",
    "\t# # Extract data section\n",
    "\t# data_section = data_text.split(\"@data\")[1].strip()\n",
    "\n",
    "\t# # Convert data section to DataFrame\n",
    "\t# df = pd.read_csv(StringIO(data_section), header=None, names=attributes)\n",
    "\n",
    "\t# return df, attribute_types\n",
    "\n",
    "class GenericOptimizer(Problem):\n",
    "\tpopulation_size = 100\n",
    "\tn_neighbours = 5\n",
    "\tsequential = False\n",
    "\tdef __init__(self, X_train, y_train, X_val, y_val, objectives, exec_mode):\n",
    "\t\tself.mutation_history = {}\n",
    "\t\tself.generation_number = 0\n",
    "\n",
    "\t\tself.exec_mode = exec_mode\n",
    "\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\n",
    "\t\tself.X_val = X_val\n",
    "\t\tself.y_val = y_val\n",
    "\n",
    "\t\tself.training_data = X_train\n",
    "\t\tself.n_instances = X_train.shape[0]\n",
    "\t\t\n",
    "\t\tself.objectives = objectives\n",
    "\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tn_var=self.n_instances,\n",
    "\t\t\tn_obj=len(objectives),               \n",
    "\t\t\tn_constr=0,            \n",
    "\t\t\txl=0,                  \n",
    "\t\t\txu=1,                  \n",
    "\t\t\ttype_var=np.bool_,     \n",
    "\t\t)\n",
    "\n",
    "\tdef _evaluate(self, x, out, *args, **kwargs):\n",
    "\t\t\n",
    "\t\tif self.exec_mode == \"sequential\":\n",
    "\t\t\tmetrics = []\n",
    "\t\t\tfor objective in self.objectives:\n",
    "\t\t\t\tmetrics.append(self.eval_objective((objective, x)))\n",
    "\t\telse:\n",
    "\t\t\tmetrics = Parallel(n_jobs=-1)(delayed(self.eval_objective)((objective, x)) for objective in self.objectives)\n",
    "\t\t\n",
    "\t\tself.generation_number += 1\n",
    "\n",
    "\t\tout[\"F\"] = np.column_stack(metrics)\n",
    "\n",
    "\tdef eval_objective(self, pack):\n",
    "\t\tobjective, x = pack\n",
    "\t\t\t\n",
    "\t\tif \"calculate_num_examples\" in repr(objective):\n",
    "\t\t\treturn GenericOptimizer.calculate_num_examples(x)\n",
    "\n",
    "\t\telif \"calculate_IR\" in repr(objective):\n",
    "\t\t\tvals = []\n",
    "\t\t\tfor instance in x:\n",
    "\t\t\t\tvals.append(GenericOptimizer.calculate_IR(self.y_train[instance]))\n",
    "\t\t\treturn vals\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tvals = []\n",
    "\t\t\tfor instance in x:\n",
    "\t\t\t\tvals.append(objective(\n",
    "\t\t\t\t\tself.X_train[instance],\n",
    "\t\t\t\t\tself.y_train[instance],\n",
    "\t\t\t\t\tself.X_val,\n",
    "\t\t\t\t\tself.y_val,\n",
    "\t\t\t\t\tGenericOptimizer.n_neighbours\n",
    "\t\t\t\t))\n",
    "\t\t\treturn vals\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_IR(cls, y):\n",
    "\t\tdf = pd.DataFrame(y).value_counts()\n",
    "\t\treturn (df[1]/df[0]) if df.min() == 0 else (df[0]/df[1])\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef filter_by_class(cls, x, y, label):\n",
    "\t\tindices = np.where(y==label)\n",
    "\t\treturn x[indices], y[indices]\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tacc = accuracy_score(y_val, y_pred)\n",
    "\t\t\treturn 1-acc\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_val, class0_y_val = cls.filter_by_class(x_val, y_val, 0)\n",
    "\t\terr = cls.calculate_overall_error(\n",
    "\t\t\tx_train,\n",
    "\t\t\ty_train,\n",
    "\t\t\tclass0_x_val,\n",
    "\t\t\tclass0_y_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn err\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass1_x_val, class1_y_val = cls.filter_by_class(x_val, y_val, 1)\n",
    "\t\terr = cls.calculate_overall_error(\n",
    "\t\t\tx_train,\n",
    "\t\t\ty_train,\n",
    "\t\t\tclass1_x_val,\n",
    "\t\t\tclass1_y_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn err\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\t\tcounts = pd.DataFrame(y_train).value_counts()\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tf1 = f1_score(y_val, y_pred, average='binary')\n",
    "\t\t\treturn 1-f1\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_val, class0_y_val = cls.filter_by_class(x_val, y_val, 0)\n",
    "\t\tinv_f1 = cls.calculate_overall_inverse_f1(\n",
    "\t\t\tx_train,\n",
    "\t\t\ty_train,\n",
    "\t\t\tclass0_x_val,\n",
    "\t\t\tclass0_y_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_f1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass1_x_val, class1_y_val = cls.filter_by_class(x_val, y_val, 1)\n",
    "\t\tinv_f1 = cls.calculate_overall_inverse_f1(\n",
    "\t\t\tx_train,\n",
    "\t\t\ty_train,\n",
    "\t\t\tclass1_x_val,\n",
    "\t\t\tclass1_y_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_f1\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_num_examples(cls, instances):\n",
    "\t\treturn np.sum(instances, axis=1)\n",
    "\n",
    "class BiasedBinarySampling(Sampling):\n",
    "\tdef __init__(self, labels, major_prob, minor_prob):\n",
    "\t\t\n",
    "\t\tself.labels = labels\n",
    "\t\tcounts = pd.DataFrame(labels).value_counts()\n",
    "\t\tif counts[0] > counts[1]:\n",
    "\t\t\tself.c0_thresh = major_prob\n",
    "\t\t\tself.c1_thresh = minor_prob\n",
    "\t\telse:\n",
    "\t\t\tself.c0_thresh = minor_prob\n",
    "\t\t\tself.c1_thresh = major_prob\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef _do(self, problem, n_samples, **kwargs):\n",
    "\n",
    "\t\trands = np.random.random((n_samples, problem.n_var))\n",
    "\t\tinit_pops = np.zeros((n_samples, problem.n_var), dtype=bool)\n",
    "\t\tfor idx, label in enumerate(self.labels):\n",
    "\t\t\tif label == 0:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c0_thresh).astype(bool)\n",
    "\t\t\tif label == 1:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c1_thresh).astype(bool)\n",
    "\n",
    "\n",
    "\t\treturn init_pops\n",
    "\t\n",
    "class BitflipMutation(Mutation):\n",
    "\n",
    "\tdef _do(self, problem, X, **kwargs):\n",
    "\t\t\n",
    "\t\tprob_var = self.get_prob_var(problem, size=(len(X), 1))\n",
    "\t\tXp = np.copy(X)\n",
    "\t\tflip = np.random.random(X.shape) < prob_var\n",
    "\t\tXp[flip] = ~X[flip]\n",
    "\t\t\n",
    "\t\ttotal_number_of_genes = X.shape[0] * X.shape[1]\n",
    "\t\tgenes_effected = np.sum(X ^ Xp)\n",
    "\n",
    "\t\tif problem.generation_number not in problem.mutation_history:\n",
    "\t\t\tproblem.mutation_history[problem.generation_number] = []\n",
    "\t\t\n",
    "\t\tproblem.mutation_history[problem.generation_number].append(genes_effected/total_number_of_genes)\n",
    "\n",
    "\t\treturn Xp\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, x_train, y_train):\n",
    "\t\tself.x_train = x_train\n",
    "\t\tself.y_train = y_train\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.x_train.shape[0]\n",
    "\tdef __getitem__(self, ind):\n",
    "\t\tx = self.x_train[ind]\n",
    "\t\ty = self.y_train[ind]\n",
    "\t\treturn x, y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\tdef __init__(self, input_dim):\n",
    "\t\tsuper(MLP, self).__init__()\n",
    "\t\tself.linear1 = nn.Linear(input_dim, input_dim//2)\n",
    "\t\tself.relu1 = nn.ReLU()\n",
    "\t\tself.linear2 = nn.Linear(input_dim//2, input_dim//3)\n",
    "\t\tself.relu2 = nn.ReLU()\n",
    "\t\tself.linear3 = nn.Linear(input_dim//3, input_dim)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.linear1(x)\n",
    "\t\tx = self.relu1(x)\n",
    "\t\tx = self.linear2(x)\n",
    "\t\tx = self.relu2(x)\n",
    "\t\tx = self.linear3(x)\n",
    "\t\treturn x\n",
    "\t\n",
    "class CustomMutation(Mutation):\n",
    "\tcurr_MLP = None\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\tnum_synthetic_examples = 500000\n",
    "\ttrain_epochs = 50\n",
    "\tbatch_size = 215\n",
    "\tprimary_objective = GenericOptimizer.calculate_overall_error\n",
    "\t# secondary_objectives = [\n",
    "\t# \t[GenericOptimizer.calculate_num_examples],\n",
    "\t# \t[GenericOptimizer.calculate_class0_error],\n",
    "\t# \t[GenericOptimizer.calculate_class0_inverse_f1],\n",
    "\t# \t[GenericOptimizer.calculate_class0_inverse_precision],\n",
    "\t# \t[GenericOptimizer.calculate_class0_inverse_recall],\n",
    "\t# \t[GenericOptimizer.calculate_class1_error],\n",
    "\t# \t[GenericOptimizer.calculate_class1_inverse_f1],\n",
    "\t# \t[GenericOptimizer.calculate_class1_inverse_precision],\n",
    "\t# \t[GenericOptimizer.calculate_class1_inverse_recall],\n",
    "\t# \t[GenericOptimizer.calculate_overall_inverse_f1],\n",
    "\t# \t[GenericOptimizer.calculate_overall_inverse_precision],\n",
    "\t# \t[GenericOptimizer.calculate_overall_inverse_recall],\n",
    "\t# \t[GenericOptimizer.calculate_class0_inverse_precision, GenericOptimizer.calculate_class1_inverse_precision],\n",
    "\t# \t[GenericOptimizer.calculate_class0_inverse_recall, GenericOptimizer.calculate_class1_inverse_recall],\n",
    "\t# \t[GenericOptimizer.calculate_class0_inverse_f1, GenericOptimizer.calculate_class1_inverse_f1],\n",
    "\t# \t[GenericOptimizer.calculate_class0_error, GenericOptimizer.calculate_class1_error],\n",
    "\t# ]\n",
    "\n",
    "\tdef __init__(self, x_train, y_train, x_validation, y_validation, prediction_threshold=0.5):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.prediction_thresh = prediction_threshold\n",
    "\t\tsynthesized_x, synthesized_y = CustomMutation.create_training_data(x_train, y_train, x_validation, y_validation)\n",
    "\t\tself.model = CustomMutation.train_mutation(synthesized_x, synthesized_y)\n",
    "\n",
    "\tdef _do(self, problem, X, **kwargs):\n",
    "\n",
    "\t\tint_x = np.array(X, dtype=np.float32)\n",
    "\t\tdataset = CustomDataset(int_x, int_x)\n",
    "\t\tloader = DataLoader(dataset, batch_size=X.shape[0], shuffle=False)\n",
    "\n",
    "\t\tself.model.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor data, _ in loader:\n",
    "\t\t\t\tdata = data.to(CustomMutation.device)\n",
    "\t\t\t\toutputs = self.model(data)\n",
    "\t\t\t\tpredictions = (outputs > self.prediction_thresh).bool()\n",
    "\n",
    "\t\tprediction = np.array(predictions)\n",
    "\n",
    "\t\ttotal_number_of_genes = X.shape[0] * X.shape[1]\n",
    "\t\tgenes_effected = np.sum(X ^ prediction)\n",
    "\n",
    "\t\tif problem.generation_number not in problem.mutation_history:\n",
    "\t\t\tproblem.mutation_history[problem.generation_number] = []\n",
    "\t\t\n",
    "\t\tproblem.mutation_history[problem.generation_number].append(genes_effected/total_number_of_genes)\n",
    "\t\treturn prediction\n",
    "\n",
    "\t@classmethod\n",
    "\tdef train_mutation(cls, x_train, y_train):\n",
    "\t\ttrain_set = CustomDataset(x_train, y_train)\n",
    "\t\tinput_dim = x_train.shape[1]\n",
    "\t\tbatch_size = cls.batch_size\n",
    "\t\ttrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\t\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\t\t \n",
    "\t\tmodel = MLP(input_dim).to(device)\n",
    "\t\toptimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
    "\t\tcriterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\t\tmodel.train()\n",
    "\t\tfor epoch in range(cls.train_epochs):\n",
    "\t\t\tlosses = []\n",
    "\t\t\tfor batch_num, input_data in enumerate(train_loader):\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\tx, y = input_data\n",
    "\t\t\t\tx, y = x.to(device).float(), y.to(device)\n",
    "\n",
    "\t\t\t\toutput = model(x)\n",
    "\t\t\t\tloss = criterion(output, y)\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\tlosses.append(loss.item())\n",
    "\t\t\t\toptimizer.step()\n",
    "\n",
    "\t\treturn model\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef create_training_data(cls, x_train, y_train, x_validation, y_validation):\n",
    "\t\t\n",
    "\t\tsynthesizing_splits = StratifiedShuffleSplit(\n",
    "\t\t\tn_splits=len(cls.secondary_objectives), # create a split for each secondary objective\n",
    "\t\t\ttest_size=0.5, # Half the validation set is randomly excluded\n",
    "\t\t)\t\n",
    "\t\tpackages = []\n",
    "\t\tfor idx, (sub_validation_idx, _) in enumerate(synthesizing_splits.split(x_validation, y_validation)):\n",
    "\t\t\tpackages.append((\n",
    "\t\t\t\tcls.secondary_objectives[idx],\n",
    "\t\t\t\tx_train,\n",
    "\t\t\t\ty_train,\n",
    "\t\t\t\tx_validation[sub_validation_idx],\n",
    "\t\t\t\ty_validation[sub_validation_idx]\n",
    "\t\t\t))\n",
    "\n",
    "\t\t# Execute optimization and extract the final populations\n",
    "\t\tpopulations = Parallel(n_jobs=-1)(delayed(cls.execute_training_data_gen)(package) for package in packages)\n",
    "\t\t\n",
    "\t\t# Aggregate all populations into single list containing every unique instance\n",
    "\t\tall_instances = []\n",
    "\t\tfor population in populations:\n",
    "\t\t\tfor individual in population.pop:\n",
    "\t\t\t\tall_instances.append(list(individual.X))\n",
    "\t\t\t\t\n",
    "\t\tall_instances = np.array(all_instances)\n",
    "\n",
    "\t\t# Create synthetic examples by adding randin noise to each instance. Repeat until threshold is reached.\n",
    "\t\tsynthetic_x, synthetic_y = [], []\n",
    "\t\twhile len(synthetic_x) < cls.num_synthetic_examples:\n",
    "\t\t\t\n",
    "\t\t\tfor y_true in all_instances:\n",
    "\t\t\t\tx_noised = []\n",
    "\t\t\t\tfor idx, probability in enumerate(np.random.uniform(0.1, 1.0, y_true.shape[0])):\n",
    "\t\t\t\t\tif probability < 0.85:\n",
    "\t\t\t\t\t\tx_noised.append(y_true[idx])                \n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tx_noised.append(0 if y_true[idx] == 1 else 1)\n",
    "\n",
    "\t\t\t\tsynthetic_x.append(np.array(x_noised, dtype=np.float32))\n",
    "\t\t\t\tsynthetic_y.append(np.array(y_true, dtype=np.float32))\n",
    "\n",
    "\t\treturn np.array(synthetic_x), np.array(synthetic_y)\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef execute_training_data_gen(cls, package):\n",
    "\n",
    "\t\tobjectives, x_train, y_train, x_validation, y_validation = package\n",
    "\t\t\n",
    "\t\tobjectives.append(cls.primary_objective)\n",
    "\n",
    "\t\tproblem = GenericOptimizer(\n",
    "\t\t\tx_train, \n",
    "\t\t\ty_train, \n",
    "\t\t\tx_validation, \n",
    "\t\t\ty_validation,\n",
    "\t\t\tobjectives,\n",
    "\t\t\t\"Sequential\"\n",
    "\t\t)\n",
    "\n",
    "\t\talgorithm = NSGA2(\n",
    "\t\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\t\tsampling=BinaryRandomSampling(), \n",
    "\t\t\tcrossover=HUX(), \n",
    "\t\t\tmutation=BitflipMutation(), \n",
    "\t\t\teliminate_duplicates=True\n",
    "\t\t)\n",
    "\t\tresult = minimize(\n",
    "\t\t\tproblem, \n",
    "\t\t\talgorithm, \n",
    "\t\t\t('n_gen', GenericOptimizer.population_size)\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\treturn result\n",
    "\n",
    "def prepare_splits(x, y):\n",
    "\ttrain_split = StratifiedShuffleSplit(\n",
    "\t\tn_splits=31, \n",
    "\t\ttest_size=0.5\n",
    "\t)\n",
    "\tsplits = []\n",
    "\tfor train_idx, temp_idx in train_split.split(x, y):\n",
    "\t\ttest_split = StratifiedShuffleSplit(\n",
    "\t\t\tn_splits=1, \n",
    "\t\t\ttest_size=0.5\n",
    "\t\t)\n",
    "\t\ttest_idx, validation_idx = next(test_split.split(x[temp_idx], y[temp_idx]))\n",
    "\n",
    "\t\tvalidation_idx = temp_idx[validation_idx]\n",
    "\t\ttest_idx = temp_idx[test_idx]\n",
    "\t\t\n",
    "\t\tsplits.append((train_idx, validation_idx, test_idx))\n",
    "\treturn splits\n",
    "\n",
    "def create_UCI_preprocessor_pipeline(variables):\n",
    "\t\n",
    "\ttype_mappings = {}\n",
    "\tfor variable_idx, variable_name in enumerate(variables['name']):\n",
    "\t\tvariable_type = variables['type'][variable_idx]\n",
    "\t\tif variable_type not in type_mappings:\n",
    "\t\t\ttype_mappings[variable_type] = []\n",
    "\n",
    "\t\tif variables['role'][variable_idx] == 'Feature':\n",
    "\t\t\ttype_mappings[variable_type].append(variable_name)\n",
    "\n",
    "\tcategorical_transformer = Pipeline(steps=[\n",
    "\t\t('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "\t\t('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "\t])\n",
    "\tnumerical_transformer = Pipeline(steps=[\n",
    "\t\t('imputer', SimpleImputer(strategy='mean')),\n",
    "\t\t('scaler', StandardScaler())\n",
    "\t])\n",
    "\n",
    "\tnumerical_features = []\n",
    "\tif 'Continuous' in type_mappings:\n",
    "\t\tfor feature in type_mappings['Continuous']:\n",
    "\t\t\tnumerical_features.append(feature)\n",
    "\tif 'Integer' in type_mappings:\n",
    "\t\tfor feature in type_mappings['Integer']:\n",
    "\t\t\tnumerical_features.append(feature)\n",
    "\t\t\t\n",
    "\ttransformer_steps = []\n",
    "\tif numerical_features != []:\n",
    "\t\ttransformer_steps.append(\n",
    "\t\t\t('num', numerical_transformer, numerical_features)\n",
    "\t\t)\n",
    "\tif 'Categorical' in type_mappings:\n",
    "\t\ttransformer_steps.append(\n",
    "\t\t\t('cat', categorical_transformer, type_mappings['Categorical'])\n",
    "\t\t)\n",
    "\tpreprocessor = ColumnTransformer(\n",
    "\t\ttransformers=transformer_steps\n",
    "\t)\n",
    "\tpipeline = Pipeline(steps=[\n",
    "\t\t('preprocessor', preprocessor)\n",
    "\t])\n",
    "\t\n",
    "\treturn pipeline\n",
    "\n",
    "\ttype_mappings = {}\n",
    "\tcategorical_features = []\n",
    "\tnumerical_features = []\n",
    "\n",
    "\tfor column in attributes:\n",
    "\t\tif column != \"Class\" and attributes[column] != 'categorical':\n",
    "\t\t\tnumerical_features.append(column)\n",
    "\t\telif column != \"Class\" and attributes[column] == 'categorical':\n",
    "\t\t\tcategorical_features.append(column)\n",
    "\ty = dataset['Class']\t\n",
    "\tX = dataset.drop(columns=['Class'], inplace=True)\n",
    "\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\ty = label_encoder.fit_transform(y)\n",
    "\n",
    "\tcategorical_transformer = Pipeline(steps=[\n",
    "\t\t('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "\t\t('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "\t])\n",
    "\tnumerical_transformer = Pipeline(steps=[\n",
    "\t\t('imputer', SimpleImputer(strategy='mean')),\n",
    "\t\t('scaler', StandardScaler())\n",
    "\t])\n",
    "\n",
    "\tnumerical_features = []\n",
    "\tif 'Continuous' in type_mappings:\n",
    "\t\tfor feature in type_mappings['Continuous']:\n",
    "\t\t\tnumerical_features.append(feature)\n",
    "\tif 'Integer' in type_mappings:\n",
    "\t\tfor feature in type_mappings['Integer']:\n",
    "\t\t\tnumerical_features.append(feature)\n",
    "\t\t\t\n",
    "\ttransformer_steps = []\n",
    "\tif numerical_features != []:\n",
    "\t\ttransformer_steps.append(\n",
    "\t\t\t('num', numerical_transformer, numerical_features)\n",
    "\t\t)\n",
    "\tif 'Categorical' in type_mappings:\n",
    "\t\ttransformer_steps.append(\n",
    "\t\t\t('cat', categorical_transformer, categorical_features)\n",
    "\t\t)\n",
    "\tpreprocessor = ColumnTransformer(\n",
    "\t\ttransformers=transformer_steps\n",
    "\t)\n",
    "\tpipeline = Pipeline(steps=[\n",
    "\t\t('preprocessor', preprocessor)\n",
    "\t])\n",
    "\n",
    "\treturn pipeline\n",
    "\n",
    "def create_KEEL_preprocessor_pipeline(attributes):\n",
    "\ttype_mappings = {}\n",
    "\tcategorical_features = []\n",
    "\tnumerical_features = []\n",
    "\n",
    "\tfor column in attributes:\n",
    "\t\tif column != \"Class\" and attributes[column] != 'categorical':\n",
    "\t\t\tnumerical_features.append(column)\n",
    "\t\telif column != \"Class\" and attributes[column] == 'categorical':\n",
    "\t\t\tcategorical_features.append(column)\n",
    "\n",
    "\tcategorical_transformer = Pipeline(steps=[\n",
    "\t\t('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "\t\t('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "\t])\n",
    "\tnumerical_transformer = Pipeline(steps=[\n",
    "\t\t('imputer', SimpleImputer(strategy='mean')),\n",
    "\t\t('scaler', StandardScaler())\n",
    "\t])\n",
    "\t\t\t\n",
    "\ttransformer_steps = []\n",
    "\tif numerical_features != []:\n",
    "\t\ttransformer_steps.append(\n",
    "\t\t\t('num', numerical_transformer, numerical_features)\n",
    "\t\t)\n",
    "\tif 'Categorical' in type_mappings:\n",
    "\t\ttransformer_steps.append(\n",
    "\t\t\t('cat', categorical_transformer, categorical_features)\n",
    "\t\t)\n",
    "\tpreprocessor = ColumnTransformer(\n",
    "\t\ttransformers=transformer_steps\n",
    "\t)\n",
    "\tpipeline = Pipeline(steps=[\n",
    "\t\t('preprocessor', preprocessor)\n",
    "\t])\n",
    "\n",
    "\treturn pipeline\n",
    "\n",
    "def over_sample(x, y):\n",
    "\tcounts = pd.DataFrame(y).value_counts()\n",
    "\tminority_class_label = counts.index[np.argmin(counts)][0]\n",
    "\tminority_class_indicies = np.where(y == minority_class_label)[0]\n",
    "\t# y = y.reshape(-1, 1)\n",
    "\tover_sampled_x = np.concatenate((x, x[minority_class_indicies]), axis=0)\n",
    "\tover_sampled_y = np.concatenate((y, y[minority_class_indicies]), axis=0)\n",
    "\t# over_sampled_y = over_sampled_y.reshape(-1)    \n",
    "\treturn over_sampled_x, over_sampled_y\n",
    "\n",
    "def parallel_error(instance, x_train, y_train, x_compare, y_compare):\n",
    "\n",
    "\tx_filtered, y_filtered = x_train[instance], y_train[instance]\n",
    "\tif x_filtered.shape[0] < GenericOptimizer.n_neighbours: \n",
    "\t\terror = 1\n",
    "\telse:\n",
    "\t\tknn = KNeighborsClassifier(n_neighbors=GenericOptimizer.n_neighbours)\n",
    "\t\tknn.fit(x_filtered, y_filtered)\n",
    "\t\ty_pred = knn.predict(x_compare)\n",
    "\t\terror = 1 - accuracy_score(y_compare, y_pred)\n",
    "\treturn error\n",
    "\n",
    "def calculate_metrics(x_train, y_train, x_validation, y_validation, x_test, y_test, result):\n",
    "\tbaseline_validation_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train, y_train,\n",
    "\t\tx_validation, y_validation,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\tbaseline_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train, y_train,\n",
    "\t\tx_test, y_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\n",
    "\tvalidation_F = Parallel(n_jobs=-1)(delayed(parallel_error)(instance, x_train, y_train, x_validation, y_validation) for instance in result.X)\n",
    "\n",
    "\tideal_validation = result.X[np.argmin(validation_F)]\n",
    "\tvalidation_inclusions = np.sum(ideal_validation)\n",
    "\toptimized_validation_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_validation],\n",
    "\t\ty_train[ideal_validation],\n",
    "\t\tx_validation,\n",
    "\t\ty_validation,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\toptimized_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_validation],\n",
    "\t\ty_train[ideal_validation],\n",
    "\t\tx_test,\n",
    "\t\ty_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\n",
    "\ttest_F = Parallel(n_jobs=-1)(delayed(parallel_error)(instance, x_train, y_train, x_test, y_test) for instance in result.X)\n",
    "\tideal_test = result.X[np.argmin(test_F)]\n",
    "\ttest_inclusions = np.sum(ideal_test)\n",
    "\n",
    "\n",
    "\tideal_optimized_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_test],\n",
    "\t\ty_train[ideal_test],\n",
    "\t\tx_test,\n",
    "\t\ty_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\treturn validation_inclusions, test_inclusions, baseline_validation_err, baseline_test_err, optimized_validation_err, optimized_test_err, ideal_optimized_test_err\n",
    "\n",
    "def evaluate_results():\n",
    "\tdatasets = load_datasets()\n",
    "\tsave_path = \"results\"\n",
    "\n",
    "\titeration_mappings = {}\n",
    "\tfor file in os.listdir(\"results\"):\n",
    "\t\texecution_name = \"_\".join(file.replace(\".pickle\", \"\").split(\"_\")[1:])\n",
    "\t\tif execution_name not in iteration_mappings:\n",
    "\t\t\titeration_mappings[execution_name] = []\n",
    "\t\titeration_mappings[execution_name].append(file)\n",
    "\n",
    "\t#####################################################################################################################\n",
    "\t#                                                                                                                   #\n",
    "\t#####################################################################################################################\n",
    "\n",
    "\n",
    "\trows = []\n",
    "\tfor execution_name in iteration_mappings:\n",
    "\n",
    "\t\toptimized_validation_acc = []\n",
    "\t\toptimized_test_acc = []\n",
    "\t\toptimized_ideal_test_acc = []\n",
    "\n",
    "\t\tbaseline_test_acc = []\n",
    "\t\tbaseline_validaion_acc = []\n",
    "\n",
    "\t\tvalidation_inclusions = []\n",
    "\t\ttest_inclusions = []\n",
    "\t\tcurr_dataset = execution_name.split(\" \")[0].strip()\n",
    "\t\tfor dataset, name in datasets:\n",
    "\t\t\tif name == curr_dataset:\n",
    "\t\t\t\traw_X, y = dataset.data.features, dataset.data.targets\n",
    "\t\t\t\tpipeline = create_preprocessor_pipeline(dataset.variables)\n",
    "\t\t\t\tpipeline.fit(raw_X, y)\n",
    "\t\t\t\tX = pipeline.transform(raw_X)\n",
    "\t\t\t\tlabel_encoder = LabelEncoder()\n",
    "\t\t\t\ty = label_encoder.fit_transform(y)\n",
    "\t\t\t\tbreak\n",
    "\t\t\n",
    "\t\tfor filename in iteration_mappings[execution_name]:\n",
    "\t\t\twith open(os.path.join(save_path, filename), 'rb') as fh:\n",
    "\t\t\t\tresult_dict = pickle.load(fh)\n",
    "\n",
    "\t\t\ttrain_idx = result_dict['train']\n",
    "\t\t\tvalidation_idx = result_dict['validation']\n",
    "\t\t\ttest_idx = result_dict['test']\n",
    "\t\t\tresult = result_dict['result']\n",
    "\t\t\trun_name = result_dict['name']\n",
    "\n",
    "\t\t\tx_train, y_train = X[train_idx], y[train_idx]\n",
    "\t\t\tx_validation, y_validation = X[validation_idx], y[validation_idx]\n",
    "\t\t\tx_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "\t\t\tif \"overSample\" in run_name:\n",
    "\t\t\t\tx_train, y_train = over_sample(\n",
    "\t\t\t\t\tx_train, \n",
    "\t\t\t\t\ty_train\n",
    "\t\t\t\t)\n",
    "\t\t\t\n",
    "\t\t\tnum_validation, num_test, baseline_validation_err, baseline_test_err, optimized_validation_err, optimized_test_err, ideal_optimized_test_err = calculate_metrics(\n",
    "\t\t\t\tx_train, \n",
    "\t\t\t\ty_train, \n",
    "\t\t\t\tx_validation, \n",
    "\t\t\t\ty_validation, \n",
    "\t\t\t\tx_test, \n",
    "\t\t\t\ty_test, \n",
    "\t\t\t\tresult\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\tvalidation_inclusions.append(num_validation)\n",
    "\t\t\ttest_inclusions.append(num_test)\n",
    "\n",
    "\t\t\tbaseline_validaion_acc.append(1-baseline_validation_err)\n",
    "\t\t\tbaseline_test_acc.append(1-baseline_test_err)\n",
    "\t\t\toptimized_validation_acc.append(1-optimized_validation_err)\n",
    "\t\t\toptimized_test_acc.append(1-optimized_test_err)\n",
    "\t\t\toptimized_ideal_test_acc.append(1-ideal_optimized_test_err)\n",
    "\n",
    "\t\tval_pval = ranksums(baseline_validaion_acc, optimized_validation_acc).pvalue\n",
    "\t\ttest_pval = ranksums(baseline_test_acc, optimized_test_acc).pvalue\n",
    "\t\tideal_test_pval = ranksums(baseline_test_acc, optimized_ideal_test_acc).pvalue\n",
    "\t\t\n",
    "\t\trow = {\n",
    "\t\t\t\"Dataset\": curr_dataset,\n",
    "\t\t\t\"Sampling\": \"over sampling\" if \"overSample\" in execution_name else \"regular sampling\",\n",
    "\t\t\t\"Population\": \"random population\" if \"randPop\" in execution_name else \"biased population\",\n",
    "\t\t\t\"Total Size\": X.shape[0],\n",
    "\t\t\t\"Optimized Validation Size\": validation_inclusions,\n",
    "\t\t\t\"Optimized Test Size\": test_inclusions,\n",
    "\t\t\t\"Validation Baseline Acc\": baseline_validaion_acc,\n",
    "\t\t\t\"Test Baseline Acc\": baseline_test_acc,\n",
    "\t\t\t\"Optimized Validation Acc\": optimized_validation_acc,\n",
    "\t\t\t\"Optimized Test Acc\": optimized_test_acc,\n",
    "\t\t\t\"Ideal Test Acc\": optimized_ideal_test_acc,\n",
    "\t\t\t\"Validation P-value\": val_pval,\n",
    "\t\t\t\"Test P-value\": test_pval,\n",
    "\t\t\t\"Ideal Test P-value\": ideal_test_pval\n",
    "\t\t}\n",
    "\t\trows.append(row)\n",
    "\t\t\t\n",
    "\t#####################################################################################################################\n",
    "\t#                                                                                                                   #\n",
    "\t#####################################################################################################################\n",
    "\n",
    "\n",
    "\tfor dataset, name in datasets:\n",
    "\t\t\n",
    "\t\traw_X, y = dataset.data.features, dataset.data.targets\n",
    "\t\tpipeline = create_preprocessor_pipeline(dataset.variables)\n",
    "\t\tpipeline.fit(raw_X, y)\n",
    "\t\tX = pipeline.transform(raw_X)\n",
    "\t\tlabel_encoder = LabelEncoder()\n",
    "\t\ty = label_encoder.fit_transform(y)\n",
    "\n",
    "\t\tprint(name)\n",
    "\t\tprint(pd.DataFrame(y).value_counts())\n",
    "\t\tprint(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf1e3dc",
   "metadata": {},
   "source": [
    "# Create data packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25cfb4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives_sets = [\n",
    "\t# [GenericOptimizer.calculate_overall_error, GenericOptimizer.calculate_num_examples],\n",
    "\t# [GenericOptimizer.calculate_overall_error, GenericOptimizer.calculate_overall_inverse_f1, GenericOptimizer.calculate_num_examples],\n",
    "\t# [GenericOptimizer.calculate_class0_error, GenericOptimizer.calculate_class1_error],\n",
    "\t[GenericOptimizer.calculate_overall_error]\n",
    "]\n",
    "\n",
    "packages = []\n",
    "for dat_file in Path('datasets').rglob('*.dat'):\n",
    "\n",
    "\tname = str(dat_file.name).replace(\".dat\", \"\")\n",
    "\tdataset, attributes = load_KEEL_dataset(dat_file)\n",
    "\n",
    "\ty = dataset['Class']\t\n",
    "\traw_X = dataset.drop(columns=['Class'])\n",
    "\t\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\ty = label_encoder.fit_transform(y)\n",
    "\n",
    "\tpipeline = create_KEEL_preprocessor_pipeline(attributes)\n",
    "\n",
    "\tpipeline.fit(raw_X, y)\n",
    "\tX = pipeline.transform(raw_X)\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\ty = label_encoder.fit_transform(y)\n",
    "\n",
    "\tfor c, (train_idx, validation_idx, test_idx) in enumerate(prepare_splits(X, y)):\n",
    "\t\tfor objectives in objectives_sets:\n",
    "\t\t\n",
    "\t\t\tpackages.append((X, y, train_idx, validation_idx, test_idx, objectives, f\"{c}_{name}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae308fc",
   "metadata": {},
   "source": [
    "# Executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0687be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(package):\n",
    "\tx, y, train_idx, validation_idx, test_idx, objectives, dataset_name = package\n",
    "\tobjectives_names = [re.search(r'\\.([a-zA-Z_][a-zA-Z0-9_]*)\\s', str(objective_name)).group(1) for objective_name in objectives]\n",
    "\tobjectives_names = '_'.join(objectives_names)\t\t\n",
    "\tx_train, y_train = x[train_idx], y[train_idx]\n",
    "\tx_validation, y_validation = x[validation_idx], y[validation_idx]\n",
    "\t# x_train, y_train = over_sample( # <------ SAMPLING\n",
    "\t# \tx_train, \n",
    "\t# \ty_train\n",
    "\t# )\n",
    "\tproblem = GenericOptimizer(\n",
    "\t\tx_train, \n",
    "\t\ty_train, \n",
    "\t\tx_validation, \n",
    "\t\ty_validation,\n",
    "\t\tobjectives,\n",
    "\t\t\"sequential\"\n",
    "\t)\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\tsampling=BinaryRandomSampling(), # <----- POPULATION\n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True,\n",
    "\t)\n",
    "\tresult = minimize(\n",
    "\t\tproblem, \n",
    "\t\talgorithm, \n",
    "\t\t('n_gen', GenericOptimizer.population_size),\n",
    "\t\tsave_history=False\n",
    "\t)\n",
    "\tpackage = {\n",
    "\t\t\"file\": f\"{dataset_name} regSample randPop {objectives_names}.pickle\",\n",
    "\t\t\"train\": train_idx,\n",
    "\t\t\"validation\": validation_idx,\n",
    "\t\t\"test\": test_idx,\n",
    "\t\t\"result\": result\n",
    "\t}\n",
    "\treturn package\n",
    "\n",
    "for result in Parallel(n_jobs=-1)(delayed(func)(package) for package in packages):\n",
    "\twith open(os.path.join(\"results\", result['file']), 'wb') as fh:\n",
    "\t\tpickle.dump(result, fh)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a8448f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(package):\n",
    "\tx, y, train_idx, validation_idx, test_idx, objectives, dataset_name = package\n",
    "\tobjectives_names = [re.search(r'\\.([a-zA-Z_][a-zA-Z0-9_]*)\\s', str(objective_name)).group(1) for objective_name in objectives]\n",
    "\tobjectives_names = '_'.join(objectives_names)\t\t\n",
    "\tx_train, y_train = x[train_idx], y[train_idx]\n",
    "\tx_validation, y_validation = x[validation_idx], y[validation_idx]\n",
    "\tx_train, y_train = over_sample( # <------ SAMPLING\n",
    "\t\tx_train, \n",
    "\t\ty_train\n",
    "\t)\n",
    "\tproblem = GenericOptimizer(\n",
    "\t\tx_train, \n",
    "\t\ty_train, \n",
    "\t\tx_validation, \n",
    "\t\ty_validation,\n",
    "\t\tobjectives,\n",
    "\t\t\"sequential\"\n",
    "\t)\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\tsampling=BinaryRandomSampling(), # <----- POPULATION\n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True,\n",
    "\t)\n",
    "\tresult = minimize(\n",
    "\t\tproblem, \n",
    "\t\talgorithm, \n",
    "\t\t('n_gen', GenericOptimizer.population_size),\n",
    "\t\tsave_history=False\n",
    "\t)\n",
    "\tpackage = {\n",
    "\t\t\"file\": f\"{dataset_name} overSample randPop {objectives_names}.pickle\",\n",
    "\t\t\"train\": train_idx,\n",
    "\t\t\"validation\": validation_idx,\n",
    "\t\t\"test\": test_idx,\n",
    "\t\t\"result\": result\n",
    "\t}\n",
    "\treturn package\n",
    "\n",
    "for result in Parallel(n_jobs=-1)(delayed(func)(package) for package in packages):\n",
    "\twith open(os.path.join(\"results\", result['file']), 'wb') as fh:\n",
    "\t\tpickle.dump(result, fh)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9a1077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(package):\n",
    "\tx, y, train_idx, validation_idx, test_idx, objectives, dataset_name = package\n",
    "\tobjectives_names = [re.search(r'\\.([a-zA-Z_][a-zA-Z0-9_]*)\\s', str(objective_name)).group(1) for objective_name in objectives]\n",
    "\tobjectives_names = '_'.join(objectives_names)\t\t\n",
    "\tx_train, y_train = x[train_idx], y[train_idx]\n",
    "\tx_validation, y_validation = x[validation_idx], y[validation_idx]\n",
    "\t# x_train, y_train = over_sample( # <------ SAMPLING\n",
    "\t# \tx_train, \n",
    "\t# \ty_train\n",
    "\t# )\n",
    "\tproblem = GenericOptimizer(\n",
    "\t\tx_train, \n",
    "\t\ty_train, \n",
    "\t\tx_validation, \n",
    "\t\ty_validation,\n",
    "\t\tobjectives,\n",
    "\t\t\"sequential\"\n",
    "\t)\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\tsampling=BiasedBinarySampling(y_train, 0.4, 0.7), # <----- POPULATION\n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True,\n",
    "\t)\n",
    "\tresult = minimize(\n",
    "\t\tproblem, \n",
    "\t\talgorithm, \n",
    "\t\t('n_gen', GenericOptimizer.population_size),\n",
    "\t\tsave_history=False\n",
    "\t)\n",
    "\tpackage = {\n",
    "\t\t\"file\": f\"{dataset_name} regSample biasPop {objectives_names}.pickle\",\n",
    "\t\t\"train\": train_idx,\n",
    "\t\t\"validation\": validation_idx,\n",
    "\t\t\"test\": test_idx,\n",
    "\t\t\"result\": result\n",
    "\t}\n",
    "\treturn package\n",
    "\n",
    "for result in Parallel(n_jobs=-1)(delayed(func)(package) for package in packages):\n",
    "\twith open(os.path.join(\"results\", result['file']), 'wb') as fh:\n",
    "\t\tpickle.dump(result, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb10e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(package):\n",
    "\tx, y, train_idx, validation_idx, test_idx, objectives, dataset_name = package\n",
    "\tobjectives_names = [re.search(r'\\.([a-zA-Z_][a-zA-Z0-9_]*)\\s', str(objective_name)).group(1) for objective_name in objectives]\n",
    "\tobjectives_names = '_'.join(objectives_names)\t\t\n",
    "\tx_train, y_train = x[train_idx], y[train_idx]\n",
    "\tx_validation, y_validation = x[validation_idx], y[validation_idx]\n",
    "\tx_train, y_train = over_sample( # <------ SAMPLING\n",
    "\t\tx_train, \n",
    "\t\ty_train\n",
    "\t)\n",
    "\tproblem = GenericOptimizer(\n",
    "\t\tx_train, \n",
    "\t\ty_train, \n",
    "\t\tx_validation, \n",
    "\t\ty_validation,\n",
    "\t\tobjectives,\n",
    "\t\t\"sequential\"\n",
    "\t)\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\tsampling=BiasedBinarySampling(y_train, 0.4, 0.7), # <----- POPULATION\n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True,\n",
    "\t)\n",
    "\tresult = minimize(\n",
    "\t\tproblem, \n",
    "\t\talgorithm, \n",
    "\t\t('n_gen', GenericOptimizer.population_size),\n",
    "\t\tsave_history=False\n",
    "\t)\n",
    "\tpackage = {\n",
    "\t\t\"file\": f\"{dataset_name} overSample biasPop {objectives_names}.pickle\",\n",
    "\t\t\"train\": train_idx,\n",
    "\t\t\"validation\": validation_idx,\n",
    "\t\t\"test\": test_idx,\n",
    "\t\t\"result\": result\n",
    "\t}\n",
    "\treturn package\n",
    "\n",
    "for result in Parallel(n_jobs=-1)(delayed(func)(package) for package in packages):\n",
    "\twith open(os.path.join(\"results\", result['file']), 'wb') as fh:\n",
    "\t\tpickle.dump(result, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a28e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(package):\n",
    "\tx, y, train_idx, validation_idx, test_idx, objectives, dataset_name = package\n",
    "\tobjectives_names = [re.search(r'\\.([a-zA-Z_][a-zA-Z0-9_]*)\\s', str(objective_name)).group(1) for objective_name in objectives]\n",
    "\tobjectives_names = '_'.join(objectives_names)\t\t\n",
    "\tx_train, y_train = x[train_idx], y[train_idx]\n",
    "\tx_validation, y_validation = x[validation_idx], y[validation_idx]\n",
    "\t# x_train, y_train = over_sample( # <------ SAMPLING\n",
    "\t# \tx_train, \n",
    "\t# \ty_train\n",
    "\t# )\n",
    "\tproblem = GenericOptimizer(\n",
    "\t\tx_train, \n",
    "\t\ty_train, \n",
    "\t\tx_validation, \n",
    "\t\ty_validation,\n",
    "\t\tobjectives,\n",
    "\t\t\"sequential\"\n",
    "\t)\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\tsampling=BinaryRandomSampling(), # <----- POPULATION\n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True,\n",
    "\t)\n",
    "\tresult = minimize(\n",
    "\t\tproblem, \n",
    "\t\talgorithm, \n",
    "\t\t('n_gen', GenericOptimizer.population_size),\n",
    "\t\tsave_history=False\n",
    "\t)\n",
    "\tpackage = {\n",
    "\t\t\"file\": f\"{dataset_name} regSample randPop {objectives_names}.pickle\",\n",
    "\t\t\"train\": train_idx,\n",
    "\t\t\"validation\": validation_idx,\n",
    "\t\t\"test\": test_idx,\n",
    "\t\t\"result\": result\n",
    "\t}\n",
    "\treturn package\n",
    "\n",
    "for result in Parallel(n_jobs=-1)(delayed(func)(package) for package in packages):\n",
    "\twith open(os.path.join(\"results\", result['file']), 'wb') as fh:\n",
    "\t\tpickle.dump(result, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b5981",
   "metadata": {},
   "source": [
    "# Calculate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82fb0c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for dat_file in Path('datasets').rglob('*.dat'):\n",
    "\n",
    "\tname = str(dat_file.name).replace(\".dat\", \"\")\n",
    "\tdataset, attributes = load_KEEL_dataset(dat_file)\n",
    "\n",
    "\ty = dataset['Class']\t\n",
    "\traw_X = dataset.drop(columns=['Class'])\n",
    "\t\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\ty = label_encoder.fit_transform(y)\n",
    "\n",
    "\tpipeline = create_KEEL_preprocessor_pipeline(attributes)\n",
    "\n",
    "\tpipeline.fit(raw_X, y)\n",
    "\tX = pipeline.transform(raw_X)\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\ty = label_encoder.fit_transform(y)\n",
    "\n",
    "\tdatasets[name] = (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dbd466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abalone9-18\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BiasedBinarySampling' object has no attribute 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[165], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m x, y \u001b[38;5;241m=\u001b[39m datasets[name]\n\u001b[0;32m      5\u001b[0m init_pop \u001b[38;5;241m=\u001b[39m BiasedBinarySampling(y, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.7\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minit_pop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BiasedBinarySampling' object has no attribute 'X'"
     ]
    }
   ],
   "source": [
    "for name in datasets:\n",
    "\tprint(name)\n",
    "\n",
    "\tx, y = datasets[name]\n",
    "\n",
    "\tfor c, (train_idx, validation_idx, test_idx) in enumerate(prepare_splits(X, y)):\n",
    "\t\t\n",
    "\t\tinit_pop = BiasedBinarySampling(y, 0.4, 0.7)\n",
    "\t\t\n",
    "\t\tproblem = GenericOptimizer(\n",
    "\t\t\tx_train, \n",
    "\t\t\ty_train, \n",
    "\t\t\tx_validation, \n",
    "\t\t\ty_validation,\n",
    "\t\t\tobjectives,\n",
    "\t\t\t\"sequential\"\n",
    "\t\t)\n",
    "\t\talgorithm = NSGA2(\n",
    "\t\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\t\tsampling=BinaryRandomSampling(), # <----- POPULATION\n",
    "\t\t\tcrossover=HUX(), \n",
    "\t\t\tmutation=BitflipMutation(), \n",
    "\t\t\teliminate_duplicates=True,\n",
    "\t\t)\n",
    "\t\tresult = minimize(\n",
    "\t\t\tproblem, \n",
    "\t\t\talgorithm, \n",
    "\t\t\t('n_gen', GenericOptimizer.population_size),\n",
    "\t\t\tsave_history=False\n",
    "\t\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6dafec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abalone9-18\n",
      "16.404761904761905\n",
      "\n",
      "\n",
      "ecoli-0-1-3-7_vs_2-6\n",
      "39.142857142857146\n",
      "\n",
      "\n",
      "ecoli4\n",
      "15.8\n",
      "\n",
      "\n",
      "glass2\n",
      "11.588235294117647\n",
      "\n",
      "\n",
      "glass5\n",
      "22.77777777777778\n",
      "\n",
      "\n",
      "haberman\n",
      "2.7777777777777777\n",
      "\n",
      "\n",
      "new-thyroid1\n",
      "5.142857142857143\n",
      "\n",
      "\n",
      "pima\n",
      "1.8656716417910448\n",
      "\n",
      "\n",
      "vehicle0\n",
      "3.251256281407035\n",
      "\n",
      "\n",
      "vehicle1\n",
      "2.8986175115207375\n",
      "\n",
      "\n",
      "winequality-red-8_vs_6-7\n",
      "46.5\n",
      "\n",
      "\n",
      "winequality-white-3-9_vs_5\n",
      "58.28\n",
      "\n",
      "\n",
      "wisconsin\n",
      "1.8577405857740585\n",
      "\n",
      "\n",
      "yeast-1_vs_7\n",
      "14.3\n",
      "\n",
      "\n",
      "yeast1\n",
      "2.4592074592074593\n",
      "\n",
      "\n",
      "yeast3\n",
      "8.104294478527608\n",
      "\n",
      "\n",
      "yeast4\n",
      "28.098039215686274\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in datasets:\n",
    "\tprint(name)\n",
    "\n",
    "\tx, y = datasets[name]\n",
    "\tprint(GenericOptimizer.calculate_IR(y))\n",
    "\tprint(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "290cee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_name_to_config = {}\n",
    "file_to_config = {}\n",
    "for file in os.listdir(\"results\"):\n",
    "\tsegments = file.split(\"_\")\n",
    "\t\n",
    "\texecution_name = \"_\".join(segments[1:]).replace(\".pickle\", \"\")\n",
    "\n",
    "\tif execution_name not in execution_name_to_config:\n",
    "\t\texecution_name_to_config[execution_name] = []\n",
    "\n",
    "\texecution_name_to_config[execution_name].append(file)\n",
    "\t\n",
    "\tname = file.replace(\".pickle\", \"\")\n",
    "\tsegments = name.split(\" \")\n",
    "\n",
    "\tfile_to_config[file] = {\n",
    "\t\t\"Dataset\": \"_\".join(segments[0].split(\"_\")[1:]),\n",
    "\t\t\"Sampling\": segments[1],\n",
    "\t\t\"Population\": segments[2],\n",
    "\t\t\"Objectives\": segments[3],\n",
    "\t\t\"Split Num\": int(segments[0].split(\"_\")[0])\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a643e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_files = {}\n",
    "for execution_name in execution_name_to_config:\n",
    "\tfor config_file in execution_name_to_config[execution_name]:\n",
    "\t\twith open(f\"results/{config_file}\", 'rb') as fh:\n",
    "\t\t\tresult_dict = pickle.load(fh)\n",
    "\t\tloaded_files[config_file] = result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ea5af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_rows = []\n",
    "comparable_rows = []\n",
    "file_to_results = {}\n",
    "for execution_name in execution_name_to_config:\n",
    "    \n",
    "\toptimized_validation_acc = []\n",
    "\toptimized_test_acc = []\n",
    "\toptimized_ideal_test_acc = []\n",
    "\n",
    "\tbaseline_test_acc = []\n",
    "\tbaseline_validaion_acc = []\n",
    "\n",
    "\tconfig_names = []\n",
    "\tvalidation_inclusions = []\n",
    "\ttest_inclusions = []\n",
    "\n",
    "\tfor config_file in execution_name_to_config[execution_name]:\n",
    "\n",
    "\t\tif file_to_config[config_file]['Dataset'] not in datasets:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tresult_dict = loaded_files[config_file]\n",
    "\n",
    "\t\ttrain_idx = result_dict['train']\n",
    "\t\tvalidation_idx = result_dict['validation']\n",
    "\t\ttest_idx = result_dict['test']\n",
    "\t\tresult = result_dict['result']\n",
    "\n",
    "\t\tX, y = datasets[file_to_config[config_file]['Dataset']]\n",
    "\n",
    "\t\tx_train, y_train = X[train_idx], y[train_idx]\n",
    "\t\tx_validation, y_validation = X[validation_idx], y[validation_idx]\n",
    "\t\tx_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "\t\tif file_to_config[config_file]['Sampling'] == \"overSample\":\n",
    "\t\t\tx_train, y_train = over_sample(\n",
    "\t\t\t\tx_train, \n",
    "\t\t\t\ty_train\n",
    "\t\t\t)\n",
    "\t\t\t\n",
    "\t\tnum_validation, num_test, baseline_validation_err, baseline_test_err, optimized_validation_err, optimized_test_err, ideal_optimized_test_err = calculate_metrics(\n",
    "\t\t\tx_train, \n",
    "\t\t\ty_train, \n",
    "\t\t\tx_validation, \n",
    "\t\t\ty_validation, \n",
    "\t\t\tx_test, \n",
    "\t\t\ty_test, \n",
    "\t\t\tresult\n",
    "\t\t)\n",
    "\n",
    "\t\tconfig_names.append(config_file)\n",
    "\n",
    "\t\tvalidation_inclusions.append(num_validation)\n",
    "\t\ttest_inclusions.append(num_test)\n",
    "\n",
    "\t\tbaseline_validaion_acc.append(1-baseline_validation_err)\n",
    "\t\tbaseline_test_acc.append(1-baseline_test_err)\n",
    "\t\toptimized_validation_acc.append(1-optimized_validation_err)\n",
    "\t\toptimized_test_acc.append(1-optimized_test_err)\n",
    "\t\toptimized_ideal_test_acc.append(1-ideal_optimized_test_err)\n",
    "\n",
    "\tif file_to_config[config_file]['Dataset'] not in datasets:\n",
    "\t\tcontinue\n",
    "\t\t\n",
    "\tval_pval = ranksums(baseline_validaion_acc, optimized_validation_acc).pvalue\n",
    "\ttest_pval = ranksums(baseline_test_acc, optimized_test_acc).pvalue\n",
    "\tideal_test_pval = ranksums(baseline_test_acc, optimized_ideal_test_acc).pvalue\n",
    "\n",
    "\treport_rows.append({\n",
    "\t\t\"Dataset\": file_to_config[config_file]['Dataset'],\n",
    "\t\t\"Sampling\": \"over sampling\" if \"overSample\" in execution_name else \"regular sampling\",\n",
    "\t\t\"Population\": \"random population\" if \"randPop\" in execution_name else \"biased population\",\n",
    "\t\t\"Optimization\": file_to_config[config_file]['Objectives'],\n",
    "\n",
    "\t\t\"Total Size\": X.shape[0],\n",
    "\t\t\"Optimized Validation Size\": np.mean(validation_inclusions),\n",
    "\t\t\"Optimized Test Size\": np.mean(test_inclusions),\n",
    "\t\t\n",
    "\t\t\"Validation Baseline Acc\": np.mean(baseline_validaion_acc),\n",
    "\t\t\"Test Baseline Acc\": np.mean(baseline_test_acc),\n",
    "\t\t\n",
    "\t\t\"Optimized Validation Acc\": np.mean(optimized_validation_acc),\n",
    "\t\t\"Optimized Test Acc\": np.mean(optimized_test_acc),\n",
    "\t\t\"Ideal Test Acc\": np.mean(optimized_ideal_test_acc),\n",
    "\t\t\n",
    "\t\t\"Validation Diff\": np.mean(np.subtract(optimized_validation_acc, baseline_validaion_acc)),\n",
    "\t\t\"Test Diff\": np.mean(np.subtract(optimized_test_acc, baseline_test_acc)),\n",
    "\t\t\"Ideal Test Diff\": np.mean(np.subtract(optimized_ideal_test_acc, baseline_test_acc)),\n",
    "\t\t\n",
    "\t\t\"Validation P-value\": val_pval,\n",
    "\t\t\"Test P-value\": test_pval,\n",
    "\t\t\"Ideal Test P-value\": ideal_test_pval\n",
    "\t})\n",
    "\n",
    "\tcomparable_rows.append({\n",
    "\t\t\"Dataset\": file_to_config[config_file]['Dataset'],\n",
    "\t\t\"Configs\": config_names,\n",
    "\t\t\"Sampling\": \"over sampling\" if \"overSample\" in execution_name else \"regular sampling\",\n",
    "\t\t\"Population\": \"random population\" if \"randPop\" in execution_name else \"biased population\",\n",
    "\t\t\"Optimization\": file_to_config[config_file]['Objectives'],\n",
    "\n",
    "\t\t\"Total Size\": X.shape[0],\n",
    "\t\t\"Optimized Validation Size\": validation_inclusions,\n",
    "\t\t\"Optimized Test Size\": test_inclusions,\n",
    "\t\t\n",
    "\t\t\"Validation Baseline Acc\": baseline_validaion_acc,\n",
    "\t\t\"Test Baseline Acc\": baseline_test_acc,\n",
    "\t\t\n",
    "\t\t\"Optimized Validation Acc\": optimized_validation_acc,\n",
    "\t\t\"Optimized Test Acc\": optimized_test_acc,\n",
    "\t\t\"Ideal Test Acc\": optimized_ideal_test_acc,\n",
    "\t\t\n",
    "\t\t\"Validation Diff\": np.subtract(optimized_validation_acc, baseline_validaion_acc),\n",
    "\t\t\"Test Diff\": np.subtract(optimized_test_acc, baseline_test_acc),\n",
    "\t\t\"Ideal Test Diff\": np.subtract(optimized_ideal_test_acc, baseline_test_acc),\n",
    "\t\t\n",
    "\t\t\"Validation P-value\": val_pval,\n",
    "\t\t\"Test P-value\": test_pval,\n",
    "\t\t\"Ideal Test P-value\": ideal_test_pval\n",
    "\t})\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c3ced3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Sampling</th>\n",
       "      <th>Population</th>\n",
       "      <th>Optimization</th>\n",
       "      <th>Total Size</th>\n",
       "      <th>Optimized Validation Size</th>\n",
       "      <th>Optimized Test Size</th>\n",
       "      <th>Validation Baseline Acc</th>\n",
       "      <th>Test Baseline Acc</th>\n",
       "      <th>Optimized Validation Acc</th>\n",
       "      <th>Optimized Test Acc</th>\n",
       "      <th>Ideal Test Acc</th>\n",
       "      <th>Validation Diff</th>\n",
       "      <th>Test Diff</th>\n",
       "      <th>Ideal Test Diff</th>\n",
       "      <th>Validation P-value</th>\n",
       "      <th>Test P-value</th>\n",
       "      <th>Ideal Test P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone9-18</td>\n",
       "      <td>over sampling</td>\n",
       "      <td>biased population</td>\n",
       "      <td>calculate_class0_error_calculate_class1_error</td>\n",
       "      <td>731</td>\n",
       "      <td>168.935484</td>\n",
       "      <td>169.645161</td>\n",
       "      <td>0.949233</td>\n",
       "      <td>0.948881</td>\n",
       "      <td>0.976027</td>\n",
       "      <td>0.946765</td>\n",
       "      <td>0.959281</td>\n",
       "      <td>0.026794</td>\n",
       "      <td>-0.002115</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.967156e-11</td>\n",
       "      <td>0.352793</td>\n",
       "      <td>0.001733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abalone9-18</td>\n",
       "      <td>over sampling</td>\n",
       "      <td>biased population</td>\n",
       "      <td>calculate_overall_error_calculate_num_examples</td>\n",
       "      <td>731</td>\n",
       "      <td>27.903226</td>\n",
       "      <td>13.322581</td>\n",
       "      <td>0.949233</td>\n",
       "      <td>0.948881</td>\n",
       "      <td>0.978495</td>\n",
       "      <td>0.937952</td>\n",
       "      <td>0.955050</td>\n",
       "      <td>0.029261</td>\n",
       "      <td>-0.010929</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>1.544705e-11</td>\n",
       "      <td>0.017347</td>\n",
       "      <td>0.072651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abalone9-18</td>\n",
       "      <td>over sampling</td>\n",
       "      <td>biased population</td>\n",
       "      <td>calculate_overall_error_calculate_overall_inve...</td>\n",
       "      <td>731</td>\n",
       "      <td>32.225806</td>\n",
       "      <td>13.290323</td>\n",
       "      <td>0.949233</td>\n",
       "      <td>0.948881</td>\n",
       "      <td>0.981315</td>\n",
       "      <td>0.936894</td>\n",
       "      <td>0.953816</td>\n",
       "      <td>0.032082</td>\n",
       "      <td>-0.011987</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>1.401846e-11</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.145080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abalone9-18</td>\n",
       "      <td>over sampling</td>\n",
       "      <td>random population</td>\n",
       "      <td>calculate_class0_error_calculate_class1_error</td>\n",
       "      <td>731</td>\n",
       "      <td>191.516129</td>\n",
       "      <td>192.741935</td>\n",
       "      <td>0.949233</td>\n",
       "      <td>0.948881</td>\n",
       "      <td>0.973206</td>\n",
       "      <td>0.947647</td>\n",
       "      <td>0.959633</td>\n",
       "      <td>0.023973</td>\n",
       "      <td>-0.001234</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>3.030386e-11</td>\n",
       "      <td>0.622189</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone9-18</td>\n",
       "      <td>over sampling</td>\n",
       "      <td>random population</td>\n",
       "      <td>calculate_overall_error_calculate_num_examples</td>\n",
       "      <td>731</td>\n",
       "      <td>23.806452</td>\n",
       "      <td>13.451613</td>\n",
       "      <td>0.949233</td>\n",
       "      <td>0.948881</td>\n",
       "      <td>0.978495</td>\n",
       "      <td>0.936718</td>\n",
       "      <td>0.953464</td>\n",
       "      <td>0.029261</td>\n",
       "      <td>-0.012163</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>1.544705e-11</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.169858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>regular sampling</td>\n",
       "      <td>biased population</td>\n",
       "      <td>calculate_overall_error_calculate_overall_inve...</td>\n",
       "      <td>1484</td>\n",
       "      <td>46.032258</td>\n",
       "      <td>34.387097</td>\n",
       "      <td>0.964177</td>\n",
       "      <td>0.967133</td>\n",
       "      <td>0.987045</td>\n",
       "      <td>0.958351</td>\n",
       "      <td>0.965655</td>\n",
       "      <td>0.022868</td>\n",
       "      <td>-0.008782</td>\n",
       "      <td>-0.001478</td>\n",
       "      <td>1.335353e-11</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.563790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>regular sampling</td>\n",
       "      <td>random population</td>\n",
       "      <td>calculate_class0_error_calculate_class1_error</td>\n",
       "      <td>1484</td>\n",
       "      <td>367.806452</td>\n",
       "      <td>367.225806</td>\n",
       "      <td>0.964177</td>\n",
       "      <td>0.967133</td>\n",
       "      <td>0.981045</td>\n",
       "      <td>0.966785</td>\n",
       "      <td>0.971394</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>1.401846e-11</td>\n",
       "      <td>0.871382</td>\n",
       "      <td>0.000657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>regular sampling</td>\n",
       "      <td>random population</td>\n",
       "      <td>calculate_overall_error</td>\n",
       "      <td>1484</td>\n",
       "      <td>368.064516</td>\n",
       "      <td>369.709677</td>\n",
       "      <td>0.964786</td>\n",
       "      <td>0.966959</td>\n",
       "      <td>0.980350</td>\n",
       "      <td>0.967133</td>\n",
       "      <td>0.972176</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>1.471579e-11</td>\n",
       "      <td>0.549614</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>regular sampling</td>\n",
       "      <td>random population</td>\n",
       "      <td>calculate_overall_error_calculate_num_examples</td>\n",
       "      <td>1484</td>\n",
       "      <td>49.387097</td>\n",
       "      <td>44.451613</td>\n",
       "      <td>0.964177</td>\n",
       "      <td>0.967133</td>\n",
       "      <td>0.984262</td>\n",
       "      <td>0.962438</td>\n",
       "      <td>0.965829</td>\n",
       "      <td>0.020085</td>\n",
       "      <td>-0.004695</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>1.335353e-11</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.485872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>regular sampling</td>\n",
       "      <td>random population</td>\n",
       "      <td>calculate_overall_error_calculate_overall_inve...</td>\n",
       "      <td>1484</td>\n",
       "      <td>60.419355</td>\n",
       "      <td>52.645161</td>\n",
       "      <td>0.964177</td>\n",
       "      <td>0.967133</td>\n",
       "      <td>0.985045</td>\n",
       "      <td>0.961742</td>\n",
       "      <td>0.967220</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>-0.005391</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>1.335353e-11</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.597536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dataset          Sampling         Population  \\\n",
       "0    abalone9-18     over sampling  biased population   \n",
       "1    abalone9-18     over sampling  biased population   \n",
       "2    abalone9-18     over sampling  biased population   \n",
       "3    abalone9-18     over sampling  random population   \n",
       "4    abalone9-18     over sampling  random population   \n",
       "..           ...               ...                ...   \n",
       "216       yeast4  regular sampling  biased population   \n",
       "217       yeast4  regular sampling  random population   \n",
       "218       yeast4  regular sampling  random population   \n",
       "219       yeast4  regular sampling  random population   \n",
       "220       yeast4  regular sampling  random population   \n",
       "\n",
       "                                          Optimization  Total Size  \\\n",
       "0        calculate_class0_error_calculate_class1_error         731   \n",
       "1       calculate_overall_error_calculate_num_examples         731   \n",
       "2    calculate_overall_error_calculate_overall_inve...         731   \n",
       "3        calculate_class0_error_calculate_class1_error         731   \n",
       "4       calculate_overall_error_calculate_num_examples         731   \n",
       "..                                                 ...         ...   \n",
       "216  calculate_overall_error_calculate_overall_inve...        1484   \n",
       "217      calculate_class0_error_calculate_class1_error        1484   \n",
       "218                            calculate_overall_error        1484   \n",
       "219     calculate_overall_error_calculate_num_examples        1484   \n",
       "220  calculate_overall_error_calculate_overall_inve...        1484   \n",
       "\n",
       "     Optimized Validation Size  Optimized Test Size  Validation Baseline Acc  \\\n",
       "0                   168.935484           169.645161                 0.949233   \n",
       "1                    27.903226            13.322581                 0.949233   \n",
       "2                    32.225806            13.290323                 0.949233   \n",
       "3                   191.516129           192.741935                 0.949233   \n",
       "4                    23.806452            13.451613                 0.949233   \n",
       "..                         ...                  ...                      ...   \n",
       "216                  46.032258            34.387097                 0.964177   \n",
       "217                 367.806452           367.225806                 0.964177   \n",
       "218                 368.064516           369.709677                 0.964786   \n",
       "219                  49.387097            44.451613                 0.964177   \n",
       "220                  60.419355            52.645161                 0.964177   \n",
       "\n",
       "     Test Baseline Acc  Optimized Validation Acc  Optimized Test Acc  \\\n",
       "0             0.948881                  0.976027            0.946765   \n",
       "1             0.948881                  0.978495            0.937952   \n",
       "2             0.948881                  0.981315            0.936894   \n",
       "3             0.948881                  0.973206            0.947647   \n",
       "4             0.948881                  0.978495            0.936718   \n",
       "..                 ...                       ...                 ...   \n",
       "216           0.967133                  0.987045            0.958351   \n",
       "217           0.967133                  0.981045            0.966785   \n",
       "218           0.966959                  0.980350            0.967133   \n",
       "219           0.967133                  0.984262            0.962438   \n",
       "220           0.967133                  0.985045            0.961742   \n",
       "\n",
       "     Ideal Test Acc  Validation Diff  Test Diff  Ideal Test Diff  \\\n",
       "0          0.959281         0.026794  -0.002115         0.010400   \n",
       "1          0.955050         0.029261  -0.010929         0.006170   \n",
       "2          0.953816         0.032082  -0.011987         0.004936   \n",
       "3          0.959633         0.023973  -0.001234         0.010753   \n",
       "4          0.953464         0.029261  -0.012163         0.004583   \n",
       "..              ...              ...        ...              ...   \n",
       "216        0.965655         0.022868  -0.008782        -0.001478   \n",
       "217        0.971394         0.016868  -0.000348         0.004260   \n",
       "218        0.972176         0.015564   0.000174         0.005217   \n",
       "219        0.965829         0.020085  -0.004695        -0.001304   \n",
       "220        0.967220         0.020868  -0.005391         0.000087   \n",
       "\n",
       "     Validation P-value  Test P-value  Ideal Test P-value  \n",
       "0          1.967156e-11      0.352793            0.001733  \n",
       "1          1.544705e-11      0.017347            0.072651  \n",
       "2          1.401846e-11      0.001174            0.145080  \n",
       "3          3.030386e-11      0.622189            0.000608  \n",
       "4          1.544705e-11      0.003486            0.169858  \n",
       "..                  ...           ...                 ...  \n",
       "216        1.335353e-11      0.000036            0.563790  \n",
       "217        1.401846e-11      0.871382            0.000657  \n",
       "218        1.471579e-11      0.549614            0.000033  \n",
       "219        1.335353e-11      0.004761            0.485872  \n",
       "220        1.335353e-11      0.002588            0.597536  \n",
       "\n",
       "[221 rows x 18 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(report_rows)\n",
    "df.to_excel(\"REPORT.xlsx\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26291c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Configs</th>\n",
       "      <th>Sampling</th>\n",
       "      <th>Population</th>\n",
       "      <th>Optimization</th>\n",
       "      <th>Total Size</th>\n",
       "      <th>Optimized Validation Size</th>\n",
       "      <th>Optimized Test Size</th>\n",
       "      <th>Validation Baseline Acc</th>\n",
       "      <th>Test Baseline Acc</th>\n",
       "      <th>Optimized Validation Acc</th>\n",
       "      <th>Optimized Test Acc</th>\n",
       "      <th>Ideal Test Acc</th>\n",
       "      <th>Validation Diff</th>\n",
       "      <th>Test Diff</th>\n",
       "      <th>Ideal Test Diff</th>\n",
       "      <th>Validation P-value</th>\n",
       "      <th>Test P-value</th>\n",
       "      <th>Ideal Test P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone9-18</td>\n",
       "      <td>['0_abalone9-18 overSample biasPop calculate_c...</td>\n",
       "      <td>over sampling</td>\n",
       "      <td>biased population</td>\n",
       "      <td>calculate_class0_error_calculate_class1_error</td>\n",
       "      <td>731</td>\n",
       "      <td>[np.int64(191), np.int64(168), np.int64(163), ...</td>\n",
       "      <td>[np.int64(176), np.int64(169), np.int64(158), ...</td>\n",
       "      <td>[0.9398907103825137, 0.9508196721311475, 0.950...</td>\n",
       "      <td>[0.9508196721311475, 0.9398907103825137, 0.950...</td>\n",
       "      <td>[0.9781420765027322, 0.9890710382513661, 0.978...</td>\n",
       "      <td>[0.9508196721311475, 0.9234972677595629, 0.956...</td>\n",
       "      <td>[0.9617486338797814, 0.9453551912568307, 0.972...</td>\n",
       "      <td>[0.03825137 0.03825137 0.0273224  0.02185792 0...</td>\n",
       "      <td>[ 0.         -0.01639344  0.00546448 -0.005464...</td>\n",
       "      <td>[ 0.01092896  0.00546448  0.02185792  0.010928...</td>\n",
       "      <td>1.967156e-11</td>\n",
       "      <td>0.352793</td>\n",
       "      <td>0.001733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abalone9-18</td>\n",
       "      <td>['0_abalone9-18 overSample biasPop calculate_o...</td>\n",
       "      <td>over sampling</td>\n",
       "      <td>biased population</td>\n",
       "      <td>calculate_overall_error_calculate_num_examples</td>\n",
       "      <td>731</td>\n",
       "      <td>[np.int64(46), np.int64(76), np.int64(8), np.i...</td>\n",
       "      <td>[np.int64(7), np.int64(8), np.int64(8), np.int...</td>\n",
       "      <td>[0.9398907103825137, 0.9508196721311475, 0.950...</td>\n",
       "      <td>[0.9508196721311475, 0.9398907103825137, 0.950...</td>\n",
       "      <td>[0.9781420765027322, 0.9890710382513661, 0.978...</td>\n",
       "      <td>[0.9180327868852459, 0.9234972677595629, 0.961...</td>\n",
       "      <td>[0.9617486338797814, 0.9398907103825137, 0.967...</td>\n",
       "      <td>[0.03825137 0.03825137 0.0273224  0.02185792 0...</td>\n",
       "      <td>[-0.03278689 -0.01639344  0.01092896 -0.005464...</td>\n",
       "      <td>[ 0.01092896  0.          0.01639344 -0.005464...</td>\n",
       "      <td>1.544705e-11</td>\n",
       "      <td>0.017347</td>\n",
       "      <td>0.072651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abalone9-18</td>\n",
       "      <td>['0_abalone9-18 overSample biasPop calculate_o...</td>\n",
       "      <td>over sampling</td>\n",
       "      <td>biased population</td>\n",
       "      <td>calculate_overall_error_calculate_overall_inve...</td>\n",
       "      <td>731</td>\n",
       "      <td>[np.int64(49), np.int64(45), np.int64(21), np....</td>\n",
       "      <td>[np.int64(11), np.int64(11), np.int64(6), np.i...</td>\n",
       "      <td>[0.9398907103825137, 0.9508196721311475, 0.950...</td>\n",
       "      <td>[0.9508196721311475, 0.9398907103825137, 0.950...</td>\n",
       "      <td>[0.9781420765027322, 0.9890710382513661, 0.978...</td>\n",
       "      <td>[0.912568306010929, 0.9180327868852459, 0.9398...</td>\n",
       "      <td>[0.9508196721311475, 0.9398907103825137, 0.956...</td>\n",
       "      <td>[0.03825137 0.03825137 0.0273224  0.0273224  0...</td>\n",
       "      <td>[-0.03825137 -0.02185792 -0.01092896 -0.016393...</td>\n",
       "      <td>[ 0.          0.          0.00546448  0.      ...</td>\n",
       "      <td>1.401846e-11</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.145080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abalone9-18</td>\n",
       "      <td>['0_abalone9-18 overSample randPop calculate_c...</td>\n",
       "      <td>over sampling</td>\n",
       "      <td>random population</td>\n",
       "      <td>calculate_class0_error_calculate_class1_error</td>\n",
       "      <td>731</td>\n",
       "      <td>[np.int64(192), np.int64(187), np.int64(196), ...</td>\n",
       "      <td>[np.int64(200), np.int64(199), np.int64(201), ...</td>\n",
       "      <td>[0.9398907103825137, 0.9508196721311475, 0.950...</td>\n",
       "      <td>[0.9508196721311475, 0.9398907103825137, 0.950...</td>\n",
       "      <td>[0.9781420765027322, 0.9836065573770492, 0.978...</td>\n",
       "      <td>[0.9508196721311475, 0.9234972677595629, 0.950...</td>\n",
       "      <td>[0.9617486338797814, 0.9453551912568307, 0.972...</td>\n",
       "      <td>[0.03825137 0.03278689 0.0273224  0.01639344 0...</td>\n",
       "      <td>[ 0.         -0.01639344  0.          0.      ...</td>\n",
       "      <td>[ 0.01092896  0.00546448  0.02185792  0.010928...</td>\n",
       "      <td>3.030386e-11</td>\n",
       "      <td>0.622189</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone9-18</td>\n",
       "      <td>['0_abalone9-18 overSample randPop calculate_o...</td>\n",
       "      <td>over sampling</td>\n",
       "      <td>random population</td>\n",
       "      <td>calculate_overall_error_calculate_num_examples</td>\n",
       "      <td>731</td>\n",
       "      <td>[np.int64(46), np.int64(10), np.int64(9), np.i...</td>\n",
       "      <td>[np.int64(12), np.int64(10), np.int64(7), np.i...</td>\n",
       "      <td>[0.9398907103825137, 0.9508196721311475, 0.950...</td>\n",
       "      <td>[0.9508196721311475, 0.9398907103825137, 0.950...</td>\n",
       "      <td>[0.9781420765027322, 0.9836065573770492, 0.983...</td>\n",
       "      <td>[0.9234972677595629, 0.9289617486338798, 0.939...</td>\n",
       "      <td>[0.9562841530054644, 0.9289617486338798, 0.950...</td>\n",
       "      <td>[0.03825137 0.03278689 0.03278689 0.0273224  0...</td>\n",
       "      <td>[-0.0273224  -0.01092896 -0.01092896 -0.027322...</td>\n",
       "      <td>[ 0.00546448 -0.01092896  0.          0.      ...</td>\n",
       "      <td>1.544705e-11</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.169858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>['0_yeast4 regSample biasPop calculate_overall...</td>\n",
       "      <td>regular sampling</td>\n",
       "      <td>biased population</td>\n",
       "      <td>calculate_overall_error_calculate_overall_inve...</td>\n",
       "      <td>1484</td>\n",
       "      <td>[np.int64(53), np.int64(24), np.int64(56), np....</td>\n",
       "      <td>[np.int64(32), np.int64(24), np.int64(49), np....</td>\n",
       "      <td>[0.9649595687331537, 0.967654986522911, 0.9622...</td>\n",
       "      <td>[0.967654986522911, 0.967654986522911, 0.97574...</td>\n",
       "      <td>[0.9919137466307277, 0.9838274932614556, 0.991...</td>\n",
       "      <td>[0.9595687331536388, 0.9703504043126685, 0.973...</td>\n",
       "      <td>[0.9622641509433962, 0.9730458221024259, 0.978...</td>\n",
       "      <td>[0.02695418 0.01617251 0.0296496  0.00808625 0...</td>\n",
       "      <td>[-0.00808625  0.00269542 -0.00269542 -0.018867...</td>\n",
       "      <td>[-0.00539084  0.00539084  0.00269542 -0.002695...</td>\n",
       "      <td>1.335353e-11</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.563790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>['0_yeast4 regSample randPop calculate_class0_...</td>\n",
       "      <td>regular sampling</td>\n",
       "      <td>random population</td>\n",
       "      <td>calculate_class0_error_calculate_class1_error</td>\n",
       "      <td>1484</td>\n",
       "      <td>[np.int64(365), np.int64(386), np.int64(334), ...</td>\n",
       "      <td>[np.int64(376), np.int64(373), np.int64(342), ...</td>\n",
       "      <td>[0.9649595687331537, 0.967654986522911, 0.9622...</td>\n",
       "      <td>[0.967654986522911, 0.967654986522911, 0.97574...</td>\n",
       "      <td>[0.9811320754716981, 0.9784366576819407, 0.983...</td>\n",
       "      <td>[0.967654986522911, 0.9730458221024259, 0.9730...</td>\n",
       "      <td>[0.9730458221024259, 0.9757412398921833, 0.975...</td>\n",
       "      <td>[0.01617251 0.01078167 0.02156334 0.00808625 0...</td>\n",
       "      <td>[ 0.          0.00539084 -0.00269542 -0.010781...</td>\n",
       "      <td>[ 0.00539084  0.00808625  0.         -0.005390...</td>\n",
       "      <td>1.401846e-11</td>\n",
       "      <td>0.871382</td>\n",
       "      <td>0.000657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>['0_yeast4 regSample randPop calculate_overall...</td>\n",
       "      <td>regular sampling</td>\n",
       "      <td>random population</td>\n",
       "      <td>calculate_overall_error</td>\n",
       "      <td>1484</td>\n",
       "      <td>[np.int64(346), np.int64(354), np.int64(357), ...</td>\n",
       "      <td>[np.int64(335), np.int64(369), np.int64(356), ...</td>\n",
       "      <td>[0.9649595687331537, 0.9622641509433962, 0.964...</td>\n",
       "      <td>[0.9622641509433962, 0.9757412398921833, 0.964...</td>\n",
       "      <td>[0.9838274932614556, 0.9757412398921833, 0.981...</td>\n",
       "      <td>[0.9595687331536388, 0.967654986522911, 0.9676...</td>\n",
       "      <td>[0.9649595687331537, 0.9730458221024259, 0.975...</td>\n",
       "      <td>[0.01886792 0.01347709 0.01617251 0.01347709 0...</td>\n",
       "      <td>[-0.00269542 -0.00808625  0.00269542 -0.005390...</td>\n",
       "      <td>[ 0.00269542 -0.00269542  0.01078167  0.008086...</td>\n",
       "      <td>1.471579e-11</td>\n",
       "      <td>0.549614</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>['0_yeast4 regSample randPop calculate_overall...</td>\n",
       "      <td>regular sampling</td>\n",
       "      <td>random population</td>\n",
       "      <td>calculate_overall_error_calculate_num_examples</td>\n",
       "      <td>1484</td>\n",
       "      <td>[np.int64(59), np.int64(24), np.int64(38), np....</td>\n",
       "      <td>[np.int64(59), np.int64(24), np.int64(38), np....</td>\n",
       "      <td>[0.9649595687331537, 0.967654986522911, 0.9622...</td>\n",
       "      <td>[0.967654986522911, 0.967654986522911, 0.97574...</td>\n",
       "      <td>[0.9892183288409704, 0.9784366576819407, 0.986...</td>\n",
       "      <td>[0.9730458221024259, 0.9649595687331537, 0.967...</td>\n",
       "      <td>[0.9730458221024259, 0.967654986522911, 0.9676...</td>\n",
       "      <td>[0.02425876 0.01078167 0.02425876 0.01347709 0...</td>\n",
       "      <td>[ 0.00539084 -0.00269542 -0.00808625 -0.013477...</td>\n",
       "      <td>[ 0.00539084  0.         -0.00808625 -0.008086...</td>\n",
       "      <td>1.335353e-11</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.485872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>['0_yeast4 regSample randPop calculate_overall...</td>\n",
       "      <td>regular sampling</td>\n",
       "      <td>random population</td>\n",
       "      <td>calculate_overall_error_calculate_overall_inve...</td>\n",
       "      <td>1484</td>\n",
       "      <td>[np.int64(68), np.int64(39), np.int64(67), np....</td>\n",
       "      <td>[np.int64(68), np.int64(30), np.int64(51), np....</td>\n",
       "      <td>[0.9649595687331537, 0.967654986522911, 0.9622...</td>\n",
       "      <td>[0.967654986522911, 0.967654986522911, 0.97574...</td>\n",
       "      <td>[0.9892183288409704, 0.9811320754716981, 0.983...</td>\n",
       "      <td>[0.9784366576819407, 0.9730458221024259, 0.962...</td>\n",
       "      <td>[0.9784366576819407, 0.9730458221024259, 0.967...</td>\n",
       "      <td>[0.02425876 0.01347709 0.02156334 0.00808625 0...</td>\n",
       "      <td>[ 0.01078167  0.00539084 -0.01347709 -0.008086...</td>\n",
       "      <td>[ 0.01078167  0.00539084 -0.00808625 -0.005390...</td>\n",
       "      <td>1.335353e-11</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.597536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dataset                                            Configs  \\\n",
       "0    abalone9-18  ['0_abalone9-18 overSample biasPop calculate_c...   \n",
       "1    abalone9-18  ['0_abalone9-18 overSample biasPop calculate_o...   \n",
       "2    abalone9-18  ['0_abalone9-18 overSample biasPop calculate_o...   \n",
       "3    abalone9-18  ['0_abalone9-18 overSample randPop calculate_c...   \n",
       "4    abalone9-18  ['0_abalone9-18 overSample randPop calculate_o...   \n",
       "..           ...                                                ...   \n",
       "216       yeast4  ['0_yeast4 regSample biasPop calculate_overall...   \n",
       "217       yeast4  ['0_yeast4 regSample randPop calculate_class0_...   \n",
       "218       yeast4  ['0_yeast4 regSample randPop calculate_overall...   \n",
       "219       yeast4  ['0_yeast4 regSample randPop calculate_overall...   \n",
       "220       yeast4  ['0_yeast4 regSample randPop calculate_overall...   \n",
       "\n",
       "             Sampling         Population  \\\n",
       "0       over sampling  biased population   \n",
       "1       over sampling  biased population   \n",
       "2       over sampling  biased population   \n",
       "3       over sampling  random population   \n",
       "4       over sampling  random population   \n",
       "..                ...                ...   \n",
       "216  regular sampling  biased population   \n",
       "217  regular sampling  random population   \n",
       "218  regular sampling  random population   \n",
       "219  regular sampling  random population   \n",
       "220  regular sampling  random population   \n",
       "\n",
       "                                          Optimization  Total Size  \\\n",
       "0        calculate_class0_error_calculate_class1_error         731   \n",
       "1       calculate_overall_error_calculate_num_examples         731   \n",
       "2    calculate_overall_error_calculate_overall_inve...         731   \n",
       "3        calculate_class0_error_calculate_class1_error         731   \n",
       "4       calculate_overall_error_calculate_num_examples         731   \n",
       "..                                                 ...         ...   \n",
       "216  calculate_overall_error_calculate_overall_inve...        1484   \n",
       "217      calculate_class0_error_calculate_class1_error        1484   \n",
       "218                            calculate_overall_error        1484   \n",
       "219     calculate_overall_error_calculate_num_examples        1484   \n",
       "220  calculate_overall_error_calculate_overall_inve...        1484   \n",
       "\n",
       "                             Optimized Validation Size  \\\n",
       "0    [np.int64(191), np.int64(168), np.int64(163), ...   \n",
       "1    [np.int64(46), np.int64(76), np.int64(8), np.i...   \n",
       "2    [np.int64(49), np.int64(45), np.int64(21), np....   \n",
       "3    [np.int64(192), np.int64(187), np.int64(196), ...   \n",
       "4    [np.int64(46), np.int64(10), np.int64(9), np.i...   \n",
       "..                                                 ...   \n",
       "216  [np.int64(53), np.int64(24), np.int64(56), np....   \n",
       "217  [np.int64(365), np.int64(386), np.int64(334), ...   \n",
       "218  [np.int64(346), np.int64(354), np.int64(357), ...   \n",
       "219  [np.int64(59), np.int64(24), np.int64(38), np....   \n",
       "220  [np.int64(68), np.int64(39), np.int64(67), np....   \n",
       "\n",
       "                                   Optimized Test Size  \\\n",
       "0    [np.int64(176), np.int64(169), np.int64(158), ...   \n",
       "1    [np.int64(7), np.int64(8), np.int64(8), np.int...   \n",
       "2    [np.int64(11), np.int64(11), np.int64(6), np.i...   \n",
       "3    [np.int64(200), np.int64(199), np.int64(201), ...   \n",
       "4    [np.int64(12), np.int64(10), np.int64(7), np.i...   \n",
       "..                                                 ...   \n",
       "216  [np.int64(32), np.int64(24), np.int64(49), np....   \n",
       "217  [np.int64(376), np.int64(373), np.int64(342), ...   \n",
       "218  [np.int64(335), np.int64(369), np.int64(356), ...   \n",
       "219  [np.int64(59), np.int64(24), np.int64(38), np....   \n",
       "220  [np.int64(68), np.int64(30), np.int64(51), np....   \n",
       "\n",
       "                               Validation Baseline Acc  \\\n",
       "0    [0.9398907103825137, 0.9508196721311475, 0.950...   \n",
       "1    [0.9398907103825137, 0.9508196721311475, 0.950...   \n",
       "2    [0.9398907103825137, 0.9508196721311475, 0.950...   \n",
       "3    [0.9398907103825137, 0.9508196721311475, 0.950...   \n",
       "4    [0.9398907103825137, 0.9508196721311475, 0.950...   \n",
       "..                                                 ...   \n",
       "216  [0.9649595687331537, 0.967654986522911, 0.9622...   \n",
       "217  [0.9649595687331537, 0.967654986522911, 0.9622...   \n",
       "218  [0.9649595687331537, 0.9622641509433962, 0.964...   \n",
       "219  [0.9649595687331537, 0.967654986522911, 0.9622...   \n",
       "220  [0.9649595687331537, 0.967654986522911, 0.9622...   \n",
       "\n",
       "                                     Test Baseline Acc  \\\n",
       "0    [0.9508196721311475, 0.9398907103825137, 0.950...   \n",
       "1    [0.9508196721311475, 0.9398907103825137, 0.950...   \n",
       "2    [0.9508196721311475, 0.9398907103825137, 0.950...   \n",
       "3    [0.9508196721311475, 0.9398907103825137, 0.950...   \n",
       "4    [0.9508196721311475, 0.9398907103825137, 0.950...   \n",
       "..                                                 ...   \n",
       "216  [0.967654986522911, 0.967654986522911, 0.97574...   \n",
       "217  [0.967654986522911, 0.967654986522911, 0.97574...   \n",
       "218  [0.9622641509433962, 0.9757412398921833, 0.964...   \n",
       "219  [0.967654986522911, 0.967654986522911, 0.97574...   \n",
       "220  [0.967654986522911, 0.967654986522911, 0.97574...   \n",
       "\n",
       "                              Optimized Validation Acc  \\\n",
       "0    [0.9781420765027322, 0.9890710382513661, 0.978...   \n",
       "1    [0.9781420765027322, 0.9890710382513661, 0.978...   \n",
       "2    [0.9781420765027322, 0.9890710382513661, 0.978...   \n",
       "3    [0.9781420765027322, 0.9836065573770492, 0.978...   \n",
       "4    [0.9781420765027322, 0.9836065573770492, 0.983...   \n",
       "..                                                 ...   \n",
       "216  [0.9919137466307277, 0.9838274932614556, 0.991...   \n",
       "217  [0.9811320754716981, 0.9784366576819407, 0.983...   \n",
       "218  [0.9838274932614556, 0.9757412398921833, 0.981...   \n",
       "219  [0.9892183288409704, 0.9784366576819407, 0.986...   \n",
       "220  [0.9892183288409704, 0.9811320754716981, 0.983...   \n",
       "\n",
       "                                    Optimized Test Acc  \\\n",
       "0    [0.9508196721311475, 0.9234972677595629, 0.956...   \n",
       "1    [0.9180327868852459, 0.9234972677595629, 0.961...   \n",
       "2    [0.912568306010929, 0.9180327868852459, 0.9398...   \n",
       "3    [0.9508196721311475, 0.9234972677595629, 0.950...   \n",
       "4    [0.9234972677595629, 0.9289617486338798, 0.939...   \n",
       "..                                                 ...   \n",
       "216  [0.9595687331536388, 0.9703504043126685, 0.973...   \n",
       "217  [0.967654986522911, 0.9730458221024259, 0.9730...   \n",
       "218  [0.9595687331536388, 0.967654986522911, 0.9676...   \n",
       "219  [0.9730458221024259, 0.9649595687331537, 0.967...   \n",
       "220  [0.9784366576819407, 0.9730458221024259, 0.962...   \n",
       "\n",
       "                                        Ideal Test Acc  \\\n",
       "0    [0.9617486338797814, 0.9453551912568307, 0.972...   \n",
       "1    [0.9617486338797814, 0.9398907103825137, 0.967...   \n",
       "2    [0.9508196721311475, 0.9398907103825137, 0.956...   \n",
       "3    [0.9617486338797814, 0.9453551912568307, 0.972...   \n",
       "4    [0.9562841530054644, 0.9289617486338798, 0.950...   \n",
       "..                                                 ...   \n",
       "216  [0.9622641509433962, 0.9730458221024259, 0.978...   \n",
       "217  [0.9730458221024259, 0.9757412398921833, 0.975...   \n",
       "218  [0.9649595687331537, 0.9730458221024259, 0.975...   \n",
       "219  [0.9730458221024259, 0.967654986522911, 0.9676...   \n",
       "220  [0.9784366576819407, 0.9730458221024259, 0.967...   \n",
       "\n",
       "                                       Validation Diff  \\\n",
       "0    [0.03825137 0.03825137 0.0273224  0.02185792 0...   \n",
       "1    [0.03825137 0.03825137 0.0273224  0.02185792 0...   \n",
       "2    [0.03825137 0.03825137 0.0273224  0.0273224  0...   \n",
       "3    [0.03825137 0.03278689 0.0273224  0.01639344 0...   \n",
       "4    [0.03825137 0.03278689 0.03278689 0.0273224  0...   \n",
       "..                                                 ...   \n",
       "216  [0.02695418 0.01617251 0.0296496  0.00808625 0...   \n",
       "217  [0.01617251 0.01078167 0.02156334 0.00808625 0...   \n",
       "218  [0.01886792 0.01347709 0.01617251 0.01347709 0...   \n",
       "219  [0.02425876 0.01078167 0.02425876 0.01347709 0...   \n",
       "220  [0.02425876 0.01347709 0.02156334 0.00808625 0...   \n",
       "\n",
       "                                             Test Diff  \\\n",
       "0    [ 0.         -0.01639344  0.00546448 -0.005464...   \n",
       "1    [-0.03278689 -0.01639344  0.01092896 -0.005464...   \n",
       "2    [-0.03825137 -0.02185792 -0.01092896 -0.016393...   \n",
       "3    [ 0.         -0.01639344  0.          0.      ...   \n",
       "4    [-0.0273224  -0.01092896 -0.01092896 -0.027322...   \n",
       "..                                                 ...   \n",
       "216  [-0.00808625  0.00269542 -0.00269542 -0.018867...   \n",
       "217  [ 0.          0.00539084 -0.00269542 -0.010781...   \n",
       "218  [-0.00269542 -0.00808625  0.00269542 -0.005390...   \n",
       "219  [ 0.00539084 -0.00269542 -0.00808625 -0.013477...   \n",
       "220  [ 0.01078167  0.00539084 -0.01347709 -0.008086...   \n",
       "\n",
       "                                       Ideal Test Diff  Validation P-value  \\\n",
       "0    [ 0.01092896  0.00546448  0.02185792  0.010928...        1.967156e-11   \n",
       "1    [ 0.01092896  0.          0.01639344 -0.005464...        1.544705e-11   \n",
       "2    [ 0.          0.          0.00546448  0.      ...        1.401846e-11   \n",
       "3    [ 0.01092896  0.00546448  0.02185792  0.010928...        3.030386e-11   \n",
       "4    [ 0.00546448 -0.01092896  0.          0.      ...        1.544705e-11   \n",
       "..                                                 ...                 ...   \n",
       "216  [-0.00539084  0.00539084  0.00269542 -0.002695...        1.335353e-11   \n",
       "217  [ 0.00539084  0.00808625  0.         -0.005390...        1.401846e-11   \n",
       "218  [ 0.00269542 -0.00269542  0.01078167  0.008086...        1.471579e-11   \n",
       "219  [ 0.00539084  0.         -0.00808625 -0.008086...        1.335353e-11   \n",
       "220  [ 0.01078167  0.00539084 -0.00808625 -0.005390...        1.335353e-11   \n",
       "\n",
       "     Test P-value  Ideal Test P-value  \n",
       "0        0.352793            0.001733  \n",
       "1        0.017347            0.072651  \n",
       "2        0.001174            0.145080  \n",
       "3        0.622189            0.000608  \n",
       "4        0.003486            0.169858  \n",
       "..            ...                 ...  \n",
       "216      0.000036            0.563790  \n",
       "217      0.871382            0.000657  \n",
       "218      0.549614            0.000033  \n",
       "219      0.004761            0.485872  \n",
       "220      0.002588            0.597536  \n",
       "\n",
       "[221 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame.from_records(comparable_rows)\n",
    "# df.to_excel(\"FOR_COMPARE.xlsx\", index=False)\n",
    "df = pd.read_excel(\"FOR_COMPARE.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b86ee2b",
   "metadata": {},
   "source": [
    "# Winners calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0716a886",
   "metadata": {},
   "source": [
    "## Reguar VS Over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "57ab039d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Optimized Validation Acc': {'Over sample wins': 30,\n",
       "  'Over sample losses': 8,\n",
       "  'Tie': 64},\n",
       " 'Optimized Test Acc': {'Over sample wins': 2,\n",
       "  'Over sample losses': 16,\n",
       "  'Tie': 84},\n",
       " 'Ideal Test Acc': {'Over sample wins': 4,\n",
       "  'Over sample losses': 12,\n",
       "  'Tie': 86},\n",
       " 'Optimized Validation Size': {'Over sample wins': 70,\n",
       "  'Over sample losses': 0,\n",
       "  'Tie': 32},\n",
       " 'Optimized Test Size': {'Over sample wins': 63,\n",
       "  'Over sample losses': 0,\n",
       "  'Tie': 39}}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WTL = {\n",
    "\t\"Optimized Validation Acc\": {\"Over sample wins\": 0, \"Over sample losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Test Acc\": {\"Over sample wins\": 0, \"Over sample losses\": 0, \"Tie\": 0},\n",
    "\t\"Ideal Test Acc\": {\"Over sample wins\": 0, \"Over sample losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Validation Size\": {\"Over sample wins\": 0, \"Over sample losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Test Size\": {\"Over sample wins\": 0, \"Over sample losses\": 0, \"Tie\": 0}\n",
    "}\n",
    "\n",
    "values = []\n",
    "for dataset in df['Dataset'].unique():\n",
    "    \n",
    "\tdataset_rows = df.where(df[\"Dataset\"] == dataset).dropna()\n",
    "\tfor optimization in dataset_rows['Optimization'].unique():\n",
    "\t\tfor population in dataset_rows['Population'].unique():\n",
    "\n",
    "\t\t\ttry:\n",
    "\t\t\t\toptimizer_row = df.where(dataset_rows[\"Optimization\"] == optimization).dropna() \n",
    "\t\t\t\tpopulation_row = df.where(optimizer_row[\"Population\"] == population).dropna()\n",
    "\t\t\t\t\n",
    "\t\t\t\tover_sample = df.where(population_row[\"Sampling\"] == \"over sampling\").dropna()\n",
    "\t\t\t\tregular_sample = df.where(population_row[\"Sampling\"] == \"regular sampling\").dropna()\n",
    "\n",
    "\t\t\t\tfor column in WTL:\n",
    "\t\t\t\t\tover_sample_values = np.array(list(over_sample[column])[0])\n",
    "\t\t\t\t\tregular_sample_values = np.array(list(regular_sample[column])[0])\n",
    "\n",
    "\t\t\t\t\tif ranksums(over_sample_values, regular_sample_values).pvalue >= 0.05: WTL[column]['Tie'] += 1\n",
    "\t\t\t\t\telif np.mean(np.subtract(over_sample_values, regular_sample_values)) > 0: \n",
    "\t\t\t\t\t\tvalues.append(dataset)\n",
    "\t\t\t\t\t\tWTL[column][\"Over sample wins\"] += 1\n",
    "\t\t\t\t\telse: WTL[column][\"Over sample losses\"] += 1\t\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tpass\n",
    "\t\n",
    "WTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70787f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(values).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96189866",
   "metadata": {},
   "source": [
    "## Random vs Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "608e111f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Optimized Validation Acc': {'Bias pop wins': 0,\n",
       "  'Bias pop losses': 0,\n",
       "  'Tie': 102},\n",
       " 'Optimized Test Acc': {'Bias pop wins': 0, 'Bias pop losses': 0, 'Tie': 102},\n",
       " 'Ideal Test Acc': {'Bias pop wins': 0, 'Bias pop losses': 0, 'Tie': 102},\n",
       " 'Optimized Validation Size': {'Bias pop wins': 0,\n",
       "  'Bias pop losses': 0,\n",
       "  'Tie': 102},\n",
       " 'Optimized Test Size': {'Bias pop wins': 0, 'Bias pop losses': 0, 'Tie': 102}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WTL = {\n",
    "\t\"Optimized Validation Acc\": {\"Bias pop wins\": 0, \"Bias pop losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Test Acc\": {\"Bias pop wins\": 0, \"Bias pop losses\": 0, \"Tie\": 0},\n",
    "\t\"Ideal Test Acc\": {\"Bias pop wins\": 0, \"Bias pop losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Validation Size\": {\"Bias pop wins\": 0, \"Bias pop losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Test Size\": {\"Bias pop wins\": 0, \"Bias pop losses\": 0, \"Tie\": 0}\n",
    "}\n",
    "\n",
    "for dataset in df['Dataset'].unique():\n",
    "    \n",
    "\tdataset_rows = df.where(df[\"Dataset\"] == dataset).dropna()\n",
    "\tfor optimization in dataset_rows['Optimization'].unique():\n",
    "\t\tfor sampling in dataset_rows['Sampling'].unique():\n",
    "\n",
    "\t\t\ttry:\n",
    "\t\t\t\toptimizer_row = df.where(dataset_rows[\"Optimization\"] == optimization).dropna() \n",
    "\t\t\t\tsampling_row = df.where(optimizer_row[\"Sampling\"] == sampling).dropna()\n",
    "\t\t\t\t\n",
    "\t\t\t\trandom_pop = df.where(sampling_row[\"Population\"] == \"random population\").dropna()\n",
    "\t\t\t\tbias_pop = df.where(sampling_row[\"Population\"] == \"biased population\").dropna()\n",
    "\n",
    "\t\t\t\tfor column in WTL:\n",
    "\t\t\t\t\trandom_pop_values = np.array(list(random_pop[column])[0])\n",
    "\t\t\t\t\tbias_pop_values = np.array(list(bias_pop[column])[0])\n",
    "\n",
    "\t\t\t\t\tif ranksums(bias_pop_values, random_pop_values).pvalue >= 0.05: WTL[column]['Tie'] += 1\n",
    "\t\t\t\t\telif np.mean(np.subtract(bias_pop_values, random_pop_values)) > 0: WTL[column][\"Bias pop wins\"] += 1\n",
    "\t\t\t\t\telse: WTL[column][\"Bias pop losses\"] += 1\t\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tpass\n",
    "\n",
    "WTL\n",
    "# for key in WTL:\n",
    "# \tprint(key, f\"{WTL[key]['Bias pop wins']}/{WTL[key]['Bias pop losses']}/{WTL[key]['Tie']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac49aead",
   "metadata": {},
   "source": [
    "## Baseline vs Class sensitive error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f01da234",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m WTL \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimized Validation Acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer wins\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer losses\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTie\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m},\n\u001b[0;32m      3\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimized Test Acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer wins\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer losses\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTie\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimized Test Size\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer wins\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer losses\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTie\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m}\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m---> 10\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m sampling \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset_rows\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSampling\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m     11\u001b[0m \t\t\u001b[38;5;28;01mfor\u001b[39;00m population \u001b[38;5;129;01min\u001b[39;00m dataset_rows[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPopulation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m     12\u001b[0m \t\t\t\u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_rows' is not defined"
     ]
    }
   ],
   "source": [
    "WTL = {\n",
    "\t\"Optimized Validation Acc\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Test Acc\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Ideal Test Acc\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Validation Size\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Test Size\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0}\n",
    "}\n",
    "\n",
    "for dataset in df['Dataset'].unique():\n",
    "\tfor sampling in dataset_rows['Sampling'].unique():\n",
    "\t\tfor population in dataset_rows['Population'].unique():\n",
    "\t\t\ttry:\n",
    "\t\t\t\trows = df.where(df[\"Dataset\"] == dataset).dropna()\n",
    "\t\t\t\trows = df.where(rows[\"Sampling\"] == sampling).dropna() \n",
    "\t\t\t\trows = df.where(rows[\"Population\"] == population).dropna()\n",
    "\t\t\t\trows = df.where(rows[\"Optimization\"] == \"calculate_class0_error_calculate_class1_error\").dropna()\n",
    "\n",
    "\t\t\t\tvalidation_acc_baseline = np.array(list(rows['Validation Baseline Acc'])[0])\n",
    "\t\t\t\toptimized_validation_acc = np.array(list(rows['Optimized Validation Acc'])[0])\n",
    "\n",
    "\t\t\t\ttest_acc_baseline = np.array(list(rows['Test Baseline Acc'])[0])\n",
    "\t\t\t\toptimized_test_acc = np.array(list(rows['Optimized Test Acc'])[0])\n",
    "\t\t\t\tideal_test_acc = np.array(list(rows['Ideal Test Acc'])[0])\n",
    "\n",
    "\t\t\t\tdataset_size = np.array(list(rows['Total Size'])[0])\n",
    "\t\t\t\tvalidation_size = np.array(list(rows['Optimized Validation Size'])[0])\n",
    "\t\t\t\tideal_test_size = np.array(list(rows['Optimized Test Size'])[0])\n",
    "\n",
    "\t\t\t\tideal_validation_reduction_rates = []\n",
    "\t\t\t\tfor size_of_ideal_validation_instance in validation_size:\n",
    "\t\t\t\t\tideal_validation_reduction_rates.append((dataset_size - size_of_ideal_validation_instance) / dataset_size)\n",
    "\n",
    "\t\t\t\tideal_test_reduction_rates = []\n",
    "\t\t\t\tfor size_of_ideal_test_instance in ideal_test_size:\n",
    "\t\t\t\t\tideal_test_reduction_rates.append((dataset_size - size_of_ideal_test_instance) / dataset_size)\n",
    "\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t# Validation\n",
    "\t\t\t\tif ranksums(optimized_validation_acc, validation_acc_baseline).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Acc\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(np.subtract(optimized_validation_acc, validation_acc_baseline)) > 0: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Acc\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Acc\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Test\n",
    "\t\t\t\tif ranksums(optimized_test_acc, test_acc_baseline).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Acc\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(np.subtract(optimized_test_acc, test_acc_baseline)) > 0: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Acc\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Acc\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Ideal Test\n",
    "\t\t\t\tif ranksums(ideal_test_acc, test_acc_baseline).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Ideal Test Acc\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(np.subtract(ideal_test_acc, test_acc_baseline)) > 0: \n",
    "\t\t\t\t\tWTL[\"Ideal Test Acc\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Ideal Test Acc\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Optimized validation size\n",
    "\t\t\t\tif ranksums(0, ideal_validation_reduction_rates).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Size\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(ideal_validation_reduction_rates) > 0.1: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Size\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Size\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\n",
    "\t\t\t\tprint(dataset)\n",
    "\t\t\t\tprint(dataset_size)\n",
    "\t\t\t\tprint(ideal_test_reduction_rates)\n",
    "\t\t\t\tprint(\"\\n\")\n",
    "\t\t\t\t# Optimized ideal test size\n",
    "\t\t\t\tif ranksums(0, ideal_test_reduction_rates).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Size\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(ideal_test_reduction_rates) > 0.1: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Size\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Size\"][\"Optimizer losses\"] += 1\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(e)\n",
    "\n",
    "WTL\n",
    "# for key in WTL:\n",
    "# \tprint(key, f\"\\n{WTL[key]['Optimizer wins']}/{WTL[key]['Optimizer losses']}/{WTL[key]['Tie']}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610db393",
   "metadata": {},
   "source": [
    "## Baseline vs Error + number of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "70ffea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Optimized Validation Acc': {'Optimizer wins': 67,\n",
       "  'Optimizer losses': 0,\n",
       "  'Tie': 1},\n",
       " 'Optimized Test Acc': {'Optimizer wins': 5,\n",
       "  'Optimizer losses': 31,\n",
       "  'Tie': 32},\n",
       " 'Ideal Test Acc': {'Optimizer wins': 27, 'Optimizer losses': 0, 'Tie': 41},\n",
       " 'Optimized Validation Size': {'Optimizer wins': 0,\n",
       "  'Optimizer losses': 0,\n",
       "  'Tie': 68},\n",
       " 'Optimized Test Size': {'Optimizer wins': 0,\n",
       "  'Optimizer losses': 0,\n",
       "  'Tie': 68}}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WTL = {\n",
    "\t\"Optimized Validation Acc\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Test Acc\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Ideal Test Acc\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Validation Size\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Test Size\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0}\n",
    "}\n",
    "\n",
    "for dataset in df['Dataset'].unique():\n",
    "\tfor sampling in dataset_rows['Sampling'].unique():\n",
    "\t\tfor population in dataset_rows['Population'].unique():\n",
    "\t\t\ttry:\n",
    "\t\t\t\trows = df.where(df[\"Dataset\"] == dataset).dropna()\n",
    "\t\t\t\trows = df.where(rows[\"Sampling\"] == sampling).dropna() \n",
    "\t\t\t\trows = df.where(rows[\"Population\"] == population).dropna()\n",
    "\t\t\t\trows = df.where(rows[\"Optimization\"] == \"calculate_overall_error_calculate_num_examples\").dropna()\n",
    "\n",
    "\t\t\t\tvalidation_acc_baseline = np.array(list(rows['Validation Baseline Acc'])[0])\n",
    "\t\t\t\toptimized_validation_acc = np.array(list(rows['Optimized Validation Acc'])[0])\n",
    "\n",
    "\t\t\t\ttest_acc_baseline = np.array(list(rows['Test Baseline Acc'])[0])\n",
    "\t\t\t\toptimized_test_acc = np.array(list(rows['Optimized Test Acc'])[0])\n",
    "\t\t\t\tideal_test_acc = np.array(list(rows['Ideal Test Acc'])[0])\n",
    "\n",
    "\t\t\t\tdataset_size = np.array(list(rows['Total Size'])[0])\n",
    "\t\t\t\tvalidation_size = np.array(list(rows['Optimized Validation Size'])[0])\n",
    "\t\t\t\tideal_test_size = np.array(list(rows['Optimized Test Size'])[0])\n",
    "\n",
    "\t\t\t\tideal_validation_reduction_rates = []\n",
    "\t\t\t\tfor size_of_ideal_validation_instance in validation_size:\n",
    "\t\t\t\t\tideal_validation_reduction_rates.append((dataset_size - size_of_ideal_validation_instance) / dataset_size)\n",
    "\n",
    "\t\t\t\tideal_test_reduction_rates = []\n",
    "\t\t\t\tfor size_of_ideal_test_instance in ideal_test_size:\n",
    "\t\t\t\t\tideal_test_reduction_rates.append((dataset_size - size_of_ideal_test_instance) / dataset_size)\n",
    "\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t# Validation\n",
    "\t\t\t\tif ranksums(optimized_validation_acc, validation_acc_baseline).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Acc\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(np.subtract(optimized_validation_acc, validation_acc_baseline)) > 0: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Acc\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Acc\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Test\n",
    "\t\t\t\tif ranksums(optimized_test_acc, test_acc_baseline).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Acc\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(np.subtract(optimized_test_acc, test_acc_baseline)) > 0: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Acc\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Acc\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Ideal Test\n",
    "\t\t\t\tif ranksums(ideal_test_acc, test_acc_baseline).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Ideal Test Acc\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(np.subtract(ideal_test_acc, test_acc_baseline)) > 0: \n",
    "\t\t\t\t\tWTL[\"Ideal Test Acc\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Ideal Test Acc\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Optimized validation size\n",
    "\t\t\t\tif ranksums(0, ideal_validation_reduction_rates).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Size\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(ideal_validation_reduction_rates) > 0.1: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Size\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Size\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Optimized ideal test size\n",
    "\t\t\t\tif ranksums(0, ideal_test_reduction_rates).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Size\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(ideal_test_reduction_rates) > 0.1: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Size\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Size\"][\"Optimizer losses\"] += 1\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(e)\n",
    "\n",
    "WTL\n",
    "# for key in WTL:\n",
    "# \tprint(key, f\"\\n{WTL[key]['Optimizer wins']}/{WTL[key]['Optimizer losses']}/{WTL[key]['Tie']}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaac289",
   "metadata": {},
   "source": [
    "## Baseline vs Error+Number of examples+Inverse F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3d18a394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Optimized Validation Acc': {'Optimizer wins': 67,\n",
       "  'Optimizer losses': 0,\n",
       "  'Tie': 1},\n",
       " 'Optimized Test Acc': {'Optimizer wins': 3,\n",
       "  'Optimizer losses': 36,\n",
       "  'Tie': 29},\n",
       " 'Ideal Test Acc': {'Optimizer wins': 25, 'Optimizer losses': 3, 'Tie': 40},\n",
       " 'Optimized Validation Size': {'Optimizer wins': 0,\n",
       "  'Optimizer losses': 0,\n",
       "  'Tie': 68},\n",
       " 'Optimized Test Size': {'Optimizer wins': 0,\n",
       "  'Optimizer losses': 0,\n",
       "  'Tie': 68}}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WTL = {\n",
    "\t\"Optimized Validation Acc\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Test Acc\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Ideal Test Acc\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Validation Size\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Test Size\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0}\n",
    "}\n",
    "\n",
    "for dataset in df['Dataset'].unique():\n",
    "\tfor sampling in dataset_rows['Sampling'].unique():\n",
    "\t\tfor population in dataset_rows['Population'].unique():\n",
    "\t\t\ttry:\n",
    "\t\t\t\trows = df.where(df[\"Dataset\"] == dataset).dropna()\n",
    "\t\t\t\trows = df.where(rows[\"Sampling\"] == sampling).dropna() \n",
    "\t\t\t\trows = df.where(rows[\"Population\"] == population).dropna()\n",
    "\t\t\t\trows = df.where(rows[\"Optimization\"] == \"calculate_overall_error_calculate_overall_inverse_f1_calculate_num_examples\").dropna()\n",
    "\n",
    "\t\t\t\tvalidation_acc_baseline = np.array(list(rows['Validation Baseline Acc'])[0])\n",
    "\t\t\t\toptimized_validation_acc = np.array(list(rows['Optimized Validation Acc'])[0])\n",
    "\n",
    "\t\t\t\ttest_acc_baseline = np.array(list(rows['Test Baseline Acc'])[0])\n",
    "\t\t\t\toptimized_test_acc = np.array(list(rows['Optimized Test Acc'])[0])\n",
    "\t\t\t\tideal_test_acc = np.array(list(rows['Ideal Test Acc'])[0])\n",
    "\n",
    "\t\t\t\tdataset_size = np.array(list(rows['Total Size'])[0])\n",
    "\t\t\t\tvalidation_size = np.array(list(rows['Optimized Validation Size'])[0])\n",
    "\t\t\t\tideal_test_size = np.array(list(rows['Optimized Test Size'])[0])\n",
    "\n",
    "\t\t\t\tideal_validation_reduction_rates = []\n",
    "\t\t\t\tfor size_of_ideal_validation_instance in validation_size:\n",
    "\t\t\t\t\tideal_validation_reduction_rates.append((dataset_size - size_of_ideal_validation_instance) / dataset_size)\n",
    "\n",
    "\t\t\t\tideal_test_reduction_rates = []\n",
    "\t\t\t\tfor size_of_ideal_test_instance in ideal_test_size:\n",
    "\t\t\t\t\tideal_test_reduction_rates.append((dataset_size - size_of_ideal_test_instance) / dataset_size)\n",
    "\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t# Validation\n",
    "\t\t\t\tif ranksums(optimized_validation_acc, validation_acc_baseline).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Acc\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(np.subtract(optimized_validation_acc, validation_acc_baseline)) > 0: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Acc\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Acc\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Test\n",
    "\t\t\t\tif ranksums(optimized_test_acc, test_acc_baseline).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Acc\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(np.subtract(optimized_test_acc, test_acc_baseline)) > 0: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Acc\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Acc\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Ideal Test\n",
    "\t\t\t\tif ranksums(ideal_test_acc, test_acc_baseline).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Ideal Test Acc\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(np.subtract(ideal_test_acc, test_acc_baseline)) > 0: \n",
    "\t\t\t\t\tWTL[\"Ideal Test Acc\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Ideal Test Acc\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Optimized validation size\n",
    "\t\t\t\tif ranksums(0, ideal_validation_reduction_rates).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Size\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(ideal_validation_reduction_rates) > 0.1: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Size\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Size\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Optimized ideal test size\n",
    "\t\t\t\tif ranksums(0, ideal_test_reduction_rates).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Size\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(ideal_test_reduction_rates) > 0.1: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Size\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Size\"][\"Optimizer losses\"] += 1\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(e)\n",
    "\n",
    "WTL\n",
    "# for key in WTL:\n",
    "# \tprint(key, f\"\\n{WTL[key]['Optimizer wins']}/{WTL[key]['Optimizer losses']}/{WTL[key]['Tie']}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a84129",
   "metadata": {},
   "source": [
    "## Baseline vs Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2840499b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Optimized Validation Acc': {'Optimizer wins': 12,\n",
       "  'Optimizer losses': 2,\n",
       "  'Tie': 3},\n",
       " 'Optimized Test Acc': {'Optimizer wins': 1, 'Optimizer losses': 1, 'Tie': 15},\n",
       " 'Ideal Test Acc': {'Optimizer wins': 8, 'Optimizer losses': 2, 'Tie': 7},\n",
       " 'Optimized Validation Size': {'Optimizer wins': 0,\n",
       "  'Optimizer losses': 0,\n",
       "  'Tie': 17},\n",
       " 'Optimized Test Size': {'Optimizer wins': 0,\n",
       "  'Optimizer losses': 0,\n",
       "  'Tie': 17}}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WTL = {\n",
    "\t\"Optimized Validation Acc\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Test Acc\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Ideal Test Acc\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Validation Size\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0},\n",
    "\t\"Optimized Test Size\": {\"Optimizer wins\": 0, \"Optimizer losses\": 0, \"Tie\": 0}\n",
    "}\n",
    "\n",
    "for dataset in df['Dataset'].unique():\n",
    "\tfor sampling in dataset_rows['Sampling'].unique():\n",
    "\t\tfor population in dataset_rows['Population'].unique():\n",
    "\t\t\ttry:\n",
    "\t\t\t\trows = df.where(df[\"Dataset\"] == dataset).dropna()\n",
    "\t\t\t\trows = df.where(rows[\"Sampling\"] == sampling).dropna() \n",
    "\t\t\t\trows = df.where(rows[\"Population\"] == population).dropna()\n",
    "\t\t\t\trows = df.where(rows[\"Optimization\"] == \"calculate_overall_error\").dropna()\n",
    "\n",
    "\t\t\t\tvalidation_acc_baseline = np.array(list(rows['Validation Baseline Acc'])[0])\n",
    "\t\t\t\toptimized_validation_acc = np.array(list(rows['Optimized Validation Acc'])[0])\n",
    "\n",
    "\t\t\t\ttest_acc_baseline = np.array(list(rows['Test Baseline Acc'])[0])\n",
    "\t\t\t\toptimized_test_acc = np.array(list(rows['Optimized Test Acc'])[0])\n",
    "\t\t\t\tideal_test_acc = np.array(list(rows['Ideal Test Acc'])[0])\n",
    "\n",
    "\t\t\t\tdataset_size = np.array(list(rows['Total Size'])[0])\n",
    "\t\t\t\tvalidation_size = np.array(list(rows['Optimized Validation Size'])[0])\n",
    "\t\t\t\tideal_test_size = np.array(list(rows['Optimized Test Size'])[0])\n",
    "\n",
    "\t\t\t\tideal_validation_reduction_rates = []\n",
    "\t\t\t\tfor size_of_ideal_validation_instance in validation_size:\n",
    "\t\t\t\t\tideal_validation_reduction_rates.append((dataset_size - size_of_ideal_validation_instance) / dataset_size)\n",
    "\n",
    "\t\t\t\tideal_test_reduction_rates = []\n",
    "\t\t\t\tfor size_of_ideal_test_instance in ideal_test_size:\n",
    "\t\t\t\t\tideal_test_reduction_rates.append((dataset_size - size_of_ideal_test_instance) / dataset_size)\n",
    "\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t# Validation\n",
    "\t\t\t\tif ranksums(optimized_validation_acc, validation_acc_baseline).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Acc\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(np.subtract(optimized_validation_acc, validation_acc_baseline)) > 0: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Acc\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Acc\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Test\n",
    "\t\t\t\tif ranksums(optimized_test_acc, test_acc_baseline).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Acc\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(np.subtract(optimized_test_acc, test_acc_baseline)) > 0: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Acc\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Acc\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Ideal Test\n",
    "\t\t\t\tif ranksums(ideal_test_acc, test_acc_baseline).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Ideal Test Acc\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(np.subtract(ideal_test_acc, test_acc_baseline)) > 0: \n",
    "\t\t\t\t\tWTL[\"Ideal Test Acc\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Ideal Test Acc\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Optimized validation size\n",
    "\t\t\t\tif ranksums(0, ideal_validation_reduction_rates).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Size\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(ideal_validation_reduction_rates) > 0.1: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Size\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Validation Size\"][\"Optimizer losses\"] += 1\t\n",
    "\n",
    "\t\t\t\t# Optimized ideal test size\n",
    "\t\t\t\tif ranksums(0, ideal_test_reduction_rates).pvalue >= 0.05: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Size\"]['Tie'] += 1\n",
    "\t\t\t\telif np.mean(ideal_test_reduction_rates) > 0.1: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Size\"][\"Optimizer wins\"] += 1\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tWTL[\"Optimized Test Size\"][\"Optimizer losses\"] += 1\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\t# print(e)\n",
    "\t\t\t\tpass\n",
    "\n",
    "WTL\n",
    "# for key in WTL:\n",
    "\t# print(key, f\"\\n{WTL[key]['Optimizer wins']}/{WTL[key]['Optimizer losses']}/{WTL[key]['Tie']}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030edaea",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba02270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "result_dict = loaded_files[\"10_abalone19 overSample biasPop calculate_class0_error_calculate_class1_error.pickle\"]\n",
    "result = result_dict['result']\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "print(result.F.shape)\n",
    "plt.scatter(result.F[:, 0], result.F[:, 1], s=30, facecolors='none', edgecolors='blue')\n",
    "plt.title(\"Pareto Front Space\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3_13_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
