{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f915929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, balanced_accuracy_score\n",
    "\n",
    "from pymoo.operators.mutation.bitflip import BitflipMutation, Mutation\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "from pymoo.operators.sampling.rnd import BinaryRandomSampling, Sampling\n",
    "from pymoo.operators.crossover.hux import HUX\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.indicators.hv import Hypervolume\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "with open('data.pickle', 'rb') as fh:\n",
    "\tdata_mapper = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbbef9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericOptimizer(Problem):\n",
    "\tpopulation_size = 100\n",
    "\tn_neighbours = 5\n",
    "\tsequential = False\n",
    "\tdef __init__(self, X_train, y_train, X_val, y_val, objectives, exec_mode):\n",
    "\t\tself.mutation_history = {}\n",
    "\t\tself.generation_number = 0\n",
    "\n",
    "\t\tself.exec_mode = exec_mode\n",
    "\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\n",
    "\t\tself.X_val = X_val\n",
    "\t\tself.y_val = y_val\n",
    "\n",
    "\t\tself.training_data = X_train\n",
    "\t\tself.n_instances = X_train.shape[0]\n",
    "\t\t\n",
    "\t\tself.objectives = objectives\n",
    "\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tn_var=self.n_instances,\n",
    "\t\t\tn_obj=len(objectives),               \n",
    "\t\t\tn_constr=0,            \n",
    "\t\t\txl=0,                  \n",
    "\t\t\txu=1,                  \n",
    "\t\t\ttype_var=np.bool_,     \n",
    "\t\t)\n",
    "\n",
    "\tdef _evaluate(self, x, out, *args, **kwargs):\n",
    "\t\t\n",
    "\t\tif self.exec_mode == \"sequential\":\n",
    "\t\t\tmetrics = []\n",
    "\t\t\tfor objective in self.objectives:\n",
    "\t\t\t\tmetrics.append(self.eval_objective((objective, x)))\n",
    "\t\telse:\n",
    "\t\t\tmetrics = Parallel(n_jobs=-1)(delayed(self.eval_objective)((objective, x)) for objective in self.objectives)\n",
    "\t\t\n",
    "\t\tself.generation_number += 1\n",
    "\n",
    "\t\tout[\"F\"] = np.column_stack(metrics)\n",
    "\n",
    "\tdef eval_objective(self, pack):\n",
    "\t\tobjective, x = pack\n",
    "\t\t\t\n",
    "\t\tif \"calculate_num_examples\" in repr(objective):\n",
    "\t\t\treturn GenericOptimizer.calculate_num_examples(x)\n",
    "\n",
    "\t\telif \"calculate_IR\" in repr(objective):\n",
    "\t\t\tvals = []\n",
    "\t\t\tfor instance in x:\n",
    "\t\t\t\tvals.append(GenericOptimizer.calculate_IR(self.y_train[instance]))\n",
    "\t\t\treturn vals\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tvals = []\n",
    "\t\t\tfor instance in x:\n",
    "\t\t\t\tvals.append(objective(\n",
    "\t\t\t\t\tself.X_train[instance],\n",
    "\t\t\t\t\tself.y_train[instance],\n",
    "\t\t\t\t\tself.X_val,\n",
    "\t\t\t\t\tself.y_val,\n",
    "\t\t\t\t\tGenericOptimizer.n_neighbours\n",
    "\t\t\t\t))\n",
    "\t\t\treturn vals\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_IR(cls, y):\n",
    "\t\tdf = pd.DataFrame(y).value_counts()\n",
    "\t\treturn (df[1]/df[0]) if df.min() == 0 else (df[0]/df[1])\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef filter_by_class(cls, x, y, label):\n",
    "\t\tindices = np.where(y==label)\n",
    "\t\treturn x[indices], y[indices]\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tbalanced_acc = balanced_accuracy_score(y_val, y_pred)\n",
    "\t\t\treturn 1-balanced_acc\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_classBalanced_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tacc = accuracy_score(y_val, y_pred)\n",
    "\t\t\treturn 1-acc\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_mean_class_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\terrors = []\n",
    "\t\tfor label in np.unique(y_val):\n",
    "\t\t\tlabel_x_val, label_y_val = cls.filter_by_class(x_val, y_val, label)\n",
    "\t\t\terrors.append(cls.calculate_overall_error(\n",
    "\t\t\t\tx_train,\n",
    "\t\t\t\ty_train,\n",
    "\t\t\t\tlabel_x_val,\n",
    "\t\t\t\tlabel_y_val,\n",
    "\t\t\t\tn\n",
    "\t\t\t))\n",
    "\t\treturn np.mean(errors)\n",
    "\t\t\t\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_val, class0_y_val = cls.filter_by_class(x_val, y_val, 0)\n",
    "\t\terr = cls.calculate_overall_error(\n",
    "\t\t\tx_train,\n",
    "\t\t\ty_train,\n",
    "\t\t\tclass0_x_val,\n",
    "\t\t\tclass0_y_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn err\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_error(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass1_x_val, class1_y_val = cls.filter_by_class(x_val, y_val, 1)\n",
    "\t\terr = cls.calculate_overall_error(\n",
    "\t\t\tx_train,\n",
    "\t\t\ty_train,\n",
    "\t\t\tclass1_x_val,\n",
    "\t\t\tclass1_y_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn err\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_overall_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\t\t\t\n",
    "\t\tnum_included_instances = x_train.shape[0]\n",
    "\t\tcounts = pd.DataFrame(y_train).value_counts()\n",
    "\t\tif num_included_instances >= n:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\t\t\toptimization_knn.fit(x_train, y_train)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(x_val)\n",
    "\t\t\tf1 = f1_score(y_val, y_pred, average='binary')\n",
    "\t\t\treturn 1-f1\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class0_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass0_x_val, class0_y_val = cls.filter_by_class(x_val, y_val, 0)\n",
    "\t\tinv_f1 = cls.calculate_overall_inverse_f1(\n",
    "\t\t\tx_train,\n",
    "\t\t\ty_train,\n",
    "\t\t\tclass0_x_val,\n",
    "\t\t\tclass0_y_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_f1\n",
    "\n",
    "\t@classmethod\n",
    "\tdef calculate_class1_inverse_f1(cls, x_train, y_train, x_val, y_val, n):\n",
    "\t\tclass1_x_val, class1_y_val = cls.filter_by_class(x_val, y_val, 1)\n",
    "\t\tinv_f1 = cls.calculate_overall_inverse_f1(\n",
    "\t\t\tx_train,\n",
    "\t\t\ty_train,\n",
    "\t\t\tclass1_x_val,\n",
    "\t\t\tclass1_y_val,\n",
    "\t\t\tn\n",
    "\t\t)\n",
    "\t\treturn inv_f1\n",
    "\t\n",
    "\t@classmethod\n",
    "\tdef calculate_num_examples(cls, instances):\n",
    "\t\treturn np.sum(instances, axis=1)\n",
    "\n",
    "class DiverseCustomSampling(Sampling):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef _do(self, problem, n_samples, **kwargs):\n",
    "\n",
    "\t\ttarget_inclusions = np.random.randint(\n",
    "\t\t\tproblem.n_var // 3,\n",
    "\t\t\tproblem.n_var,\n",
    "\t\t\tn_samples\n",
    "\t\t)\n",
    "\t\tinit_pops = []\n",
    "\t\tfor target in target_inclusions:\n",
    "\t\t\tarray = np.array([1]*target + [0]*(problem.n_var - target))\n",
    "\t\t\tnp.random.shuffle(array)\n",
    "\t\t\tinit_pops.append(array)\n",
    "\t\tinit_pops = np.array(init_pops, dtype=np.bool)\n",
    "\t\treturn init_pops\n",
    "\n",
    "class BiasedBinarySampling(Sampling):\n",
    "\tdef __init__(self, labels, major_prob, minor_prob):\n",
    "\t\t\n",
    "\t\tself.labels = labels\n",
    "\t\tcounts = pd.DataFrame(labels).value_counts()\n",
    "\t\tif counts[0] > counts[1]:\n",
    "\t\t\tself.c0_thresh = major_prob\n",
    "\t\t\tself.c1_thresh = minor_prob\n",
    "\t\telse:\n",
    "\t\t\tself.c0_thresh = minor_prob\n",
    "\t\t\tself.c1_thresh = major_prob\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef _do(self, problem, n_samples, **kwargs):\n",
    "\n",
    "\t\trands = np.random.random((n_samples, problem.n_var))\n",
    "\t\tinit_pops = np.zeros((n_samples, problem.n_var), dtype=bool)\n",
    "\t\tfor idx, label in enumerate(self.labels):\n",
    "\t\t\tif label == 0:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c0_thresh).astype(bool)\n",
    "\t\t\tif label == 1:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c1_thresh).astype(bool)\n",
    "\n",
    "\n",
    "\t\treturn init_pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c887c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(package):\n",
    "\tdata_key, run_type = package\n",
    "\tsave_name = f\"results/{data_key} {run_type}.pickle\"\n",
    "\n",
    "\tif os.path.exists(save_name):\n",
    "\t\treturn None, data_key\n",
    "\t\n",
    "\ttry:\n",
    "\t\tif 'randomPopulation' in save_name:\n",
    "\t\t\tinitial_population = BinaryRandomSampling()\n",
    "\t\t\n",
    "\t\telif 'diversePopulation' in save_name:\n",
    "\t\t\tinitial_population = DiverseCustomSampling()\n",
    "\t\t\n",
    "\t\telif 'biasePopulation' in save_name:\n",
    "\t\t\tinitial_population = BiasedBinarySampling(data_mapper[data_key]['y_train'], 0.4, 0.7)\n",
    "\n",
    "\t\tproblem = GenericOptimizer(\n",
    "\t\t\tdata_mapper[data_key]['x_train'], \n",
    "\t\t\tdata_mapper[data_key]['y_train'], \n",
    "\t\t\tdata_mapper[data_key]['x_validation'], \n",
    "\t\t\tdata_mapper[data_key]['y_validation'], \n",
    "\t\t\t[GenericOptimizer.calculate_class0_error, GenericOptimizer.calculate_class1_error],\n",
    "\t\t\t\"sequential\"\n",
    "\t\t)\n",
    "\t\talgorithm = NSGA2(\n",
    "\t\t\tpop_size=GenericOptimizer.population_size, \n",
    "\t\t\tsampling=initial_population,\n",
    "\t\t\tcrossover=HUX(), \n",
    "\t\t\tmutation=BitflipMutation(), \n",
    "\t\t\teliminate_duplicates=True,\n",
    "\t\t)\n",
    "\t\tresult = minimize(\n",
    "\t\t\tproblem, \n",
    "\t\t\talgorithm, \n",
    "\t\t\t('n_gen', GenericOptimizer.population_size),\n",
    "\t\t\tsave_history=False\n",
    "\t\t)\n",
    "\t\treturn result, data_key\n",
    "\texcept:\n",
    "\t\treturn None, data_key\n",
    "\t\n",
    "run_type = \"randomPopulation\"\n",
    "for result, data_key in Parallel(n_jobs=-1, return_as='generator')(delayed(execute)((data_key, run_type)) for data_key in data_mapper):\n",
    "\tif result is not None:\n",
    "\t\twith open(os.path.join(\"results\", f'{data_key} {run_type}.pickle'), 'wb') as fh:\n",
    "\t\t\tpickle.dump(result, fh)\n",
    "\t\t\tprint(f'Saved {data_key} {run_type}.pickle')\n",
    "\telse:\n",
    "\t\tprint(f'Passed {data_key} {run_type}.pickle')\n",
    "\n",
    "run_type = \"diversePopulation\"\n",
    "for result, data_key in Parallel(n_jobs=-1, return_as='generator')(delayed(execute)((data_key, run_type)) for data_key in data_mapper):\n",
    "\tif result is not None:\n",
    "\t\twith open(os.path.join(\"results\", f'{data_key} {run_type}.pickle'), 'wb') as fh:\n",
    "\t\t\tpickle.dump(result, fh)\n",
    "\t\t\tprint(f'Saved {data_key} {run_type}.pickle')\n",
    "\telse:\n",
    "\t\tprint(f'Passed {data_key} {run_type}.pickle')\n",
    "\n",
    "run_type = \"biasePopulation\"\n",
    "for result, data_key in Parallel(n_jobs=-1, return_as='generator')(delayed(execute)((data_key, run_type)) for data_key in data_mapper):\n",
    "\tif result is not None:\n",
    "\t\twith open(os.path.join(\"results\", f'{data_key} {run_type}.pickle'), 'wb') as fh:\n",
    "\t\t\tpickle.dump(result, fh)\n",
    "\t\t\tprint(f'Saved {data_key} {run_type}.pickle')\n",
    "\telse:\n",
    "\t\tprint(f'Passed {data_key} {run_type}.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f660b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_population = {}\n",
    "bias_population = {}\n",
    "diverse_population = {}\n",
    "\n",
    "for save_name in os.listdir('results'):\n",
    "\tname = save_name.replace(\".pickle\", \"\")\n",
    "\tsegments = name.split(\" \")\n",
    "\tdatabase_iter = segments[0]\n",
    "\tdatabase_name = '_'.join(database_iter.split(\"_\")[1:])\n",
    "\tsplit_number = int(database_iter.split(\"_\")[0])\n",
    "\tpopulation_type = segments[1]\n",
    "\t\n",
    "\twith open(f'results/{save_name}', 'rb') as fh:\n",
    "\t\texecution_data = pickle.load(fh)\n",
    "\n",
    "\tif population_type == 'randomPopulation':\n",
    "\t\tif database_name not in random_population:\n",
    "\t\t\trandom_population[database_name] = {}\n",
    "\t\trandom_population[database_name][split_number] = execution_data\n",
    "\n",
    "\telif population_type == 'diversePopulation':\n",
    "\t\tif database_name not in diverse_population:\n",
    "\t\t\tdiverse_population[database_name] = {}\n",
    "\t\tdiverse_population[database_name][split_number] = execution_data\n",
    "\t\t\n",
    "\telse: # Bias population\n",
    "\t\tif database_name not in bias_population:\n",
    "\t\t\tbias_population[database_name] = {}\n",
    "\t\tbias_population[database_name][split_number] = execution_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a404c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_error(instance, x_train, y_train, x_compare, y_compare):\n",
    "\n",
    "\tx_filtered, y_filtered = x_train[instance], y_train[instance]\n",
    "\tif x_filtered.shape[0] < GenericOptimizer.n_neighbours: \n",
    "\t\terror = 1\n",
    "\telse:\n",
    "\t\tknn = KNeighborsClassifier(n_neighbors=GenericOptimizer.n_neighbours)\n",
    "\t\tknn.fit(x_filtered, y_filtered)\n",
    "\t\ty_pred = knn.predict(x_compare)\n",
    "\t\terror = 1 - accuracy_score(y_compare, y_pred)\n",
    "\treturn error\n",
    "\n",
    "def calculate_metrics(x_train, y_train, x_validation, y_validation, x_test, y_test, result):\n",
    "\tbaseline_validation_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train, y_train,\n",
    "\t\tx_validation, y_validation,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\tbaseline_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train, y_train,\n",
    "\t\tx_test, y_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\n",
    "\tresult_pareto_front = result.X\n",
    "\tif len(result_pareto_front.shape) == 1:\n",
    "\t\tresult_pareto_front = np.array([result_pareto_front])\n",
    "\n",
    "\tvalidation_F = Parallel(n_jobs=-1)(delayed(parallel_error)(instance, x_train, y_train, x_validation, y_validation) for instance in result_pareto_front)\n",
    "\tideal_validation = result_pareto_front[np.argmin(validation_F)]\n",
    "\tvalidation_inclusions = np.sum(ideal_validation)\n",
    "\toptimized_validation_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_validation],\n",
    "\t\ty_train[ideal_validation],\n",
    "\t\tx_validation,\n",
    "\t\ty_validation,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\toptimized_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_validation],\n",
    "\t\ty_train[ideal_validation],\n",
    "\t\tx_test,\n",
    "\t\ty_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\n",
    "\ttest_F = Parallel(n_jobs=-1)(delayed(parallel_error)(instance, x_train, y_train, x_test, y_test) for instance in result_pareto_front)\n",
    "\tideal_test = result_pareto_front[np.argmin(test_F)]\n",
    "\ttest_inclusions = np.sum(ideal_test)\n",
    "\tideal_optimized_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_test],\n",
    "\t\ty_train[ideal_test],\n",
    "\t\tx_test,\n",
    "\t\ty_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\treturn validation_inclusions, test_inclusions, baseline_validation_err, baseline_test_err, optimized_validation_err, optimized_test_err, ideal_optimized_test_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c93622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error,  0_zoo-3\n",
      "Error,  1_zoo-3\n",
      "Error,  2_zoo-3\n",
      "Error,  3_zoo-3\n",
      "Error,  4_zoo-3\n",
      "Error,  5_zoo-3\n",
      "Error,  6_zoo-3\n",
      "Error,  7_zoo-3\n",
      "Error,  8_zoo-3\n",
      "Error,  9_zoo-3\n",
      "Error,  10_zoo-3\n",
      "Error,  11_zoo-3\n",
      "Error,  12_zoo-3\n",
      "Error,  13_zoo-3\n",
      "Error,  14_zoo-3\n",
      "Error,  15_zoo-3\n",
      "Error,  16_zoo-3\n",
      "Error,  17_zoo-3\n",
      "Error,  18_zoo-3\n",
      "Error,  19_zoo-3\n",
      "Error,  20_zoo-3\n",
      "Error,  21_zoo-3\n",
      "Error,  22_zoo-3\n",
      "Error,  23_zoo-3\n",
      "Error,  24_zoo-3\n",
      "Error,  25_zoo-3\n",
      "Error,  26_zoo-3\n",
      "Error,  27_zoo-3\n",
      "Error,  28_zoo-3\n",
      "Error,  29_zoo-3\n",
      "Error,  30_zoo-3\n"
     ]
    }
   ],
   "source": [
    "baselines = {}\n",
    "for data_key in data_mapper:\n",
    "\t\n",
    "\tx_train, y_train = data_mapper[data_key]['x_train'], data_mapper[data_key]['y_train']\n",
    "\tx_validation, y_validation = data_mapper[data_key]['x_validation'], data_mapper[data_key]['y_validation']\n",
    "\tx_test, y_test = data_mapper[data_key]['x_test'], data_mapper[data_key]['y_test']\n",
    "\n",
    "\ttry:\n",
    "\t\tbaseline_validation_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\t\tx_train, y_train,\n",
    "\t\t\tx_validation, y_validation,\n",
    "\t\t\tGenericOptimizer.n_neighbours\n",
    "\t\t)\n",
    "\t\tbaseline_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\t\tx_train, y_train,\n",
    "\t\t\tx_test, y_test,\n",
    "\t\t\tGenericOptimizer.n_neighbours\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tbaselines[data_key] = (baseline_validation_err, baseline_test_err)\n",
    "\texcept:\n",
    "\t\tprint(\"Error, \", data_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(input_data):\n",
    "\tinstance_dict = {}\n",
    "\tfor dataset in input_data:\n",
    "\t\tfor iter_num in input_data[dataset]:\n",
    "\t\t\tresult = input_data[dataset][iter_num]\n",
    "\n",
    "\t\t\tdata_key = f\"{iter_num}_{dataset}\"\n",
    "\t\t\tx_train, y_train = data_mapper[data_key]['x_train'], data_mapper[data_key]['y_train']\n",
    "\t\t\tx_validation, y_validation = data_mapper[data_key]['x_validation'], data_mapper[data_key]['y_validation']\n",
    "\t\t\tx_test, y_test = data_mapper[data_key]['x_test'], data_mapper[data_key]['y_test']\n",
    "\n",
    "\t\t\tresult_pareto_front = result.X\n",
    "\t\t\tif len(result_pareto_front.shape) == 1:\n",
    "\t\t\t\tresult_pareto_front = np.array([result_pareto_front])\n",
    "\n",
    "\t\t\tvalidation_F = Parallel(n_jobs=-1)(delayed(parallel_error)(instance, x_train, y_train, x_validation, y_validation) for instance in result_pareto_front)\n",
    "\t\t\tideal_validation = result_pareto_front[np.argmin(validation_F)]\n",
    "\t\t\t\n",
    "\t\t\ttest_F = Parallel(n_jobs=-1)(delayed(parallel_error)(instance, x_train, y_train, x_test, y_test) for instance in result_pareto_front)\n",
    "\t\t\tideal_test = result_pareto_front[np.argmin(test_F)]\n",
    "\n",
    "\t\t\tinstance_dict[data_key] = (ideal_validation, ideal_test)\n",
    "\treturn instance_dict\n",
    "\n",
    "randPop_best_instances = calculate(random_population)\n",
    "diversePop_metrics_best_instances = calculate(diverse_population)\n",
    "biasPop_metrics_best_instances = calculate(bias_population)\n",
    "\n",
    "with open(\"ideal_instances.pickle\", 'wb') as fh:\n",
    "    pickle.dump({\n",
    "        \"rand\": randPop_best_instances,\n",
    "        \"diverse\": diversePop_metrics_best_instances,\n",
    "        \"bias\": biasPop_metrics_best_instances\n",
    "    }, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34007fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ideal_instances.pickle\", \"rb\") as fh:\n",
    "\tinstances_dict = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_metrics = {}\n",
    "for data_key in data_mapper:\n",
    "\tx_train, y_train = data_mapper[data_key]['x_train'], data_mapper[data_key]['y_train']\n",
    "\tx_validation, y_validation = data_mapper[data_key]['x_validation'], data_mapper[data_key]['y_validation']\n",
    "\tx_test, y_test = data_mapper[data_key]['x_test'], data_mapper[data_key]['y_test']\n",
    "\n",
    "\tdatabase_name = '_'.join(data_key.split(\"_\")[1:])\n",
    "\tsplit_number = int(data_key.split(\"_\")[0])\n",
    "\n",
    "\tif data_key not in instances_dict['rand']:\n",
    "\t\tcontinue\n",
    "\n",
    "\t###########################################\n",
    "\t#\t\tBaseline metrics\n",
    "\t###########################################\n",
    "\n",
    "\tbaseline_validation_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train, y_train,\n",
    "\t\tx_validation, y_validation,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\tbaseline_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train, y_train,\n",
    "\t\tx_test, y_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\n",
    "\t###########################################\n",
    "\t#\t\tRandom Population\n",
    "\t###########################################\n",
    "\t\n",
    "\tideal_validation, ideal_test = instances_dict['rand'][data_key]\n",
    "\n",
    "\trandom_population_optimized_valiation_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_validation], y_train[ideal_validation],\n",
    "\t\tx_validation, y_validation,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\trandom_population_optimized_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_validation], y_train[ideal_validation],\n",
    "\t\tx_test, y_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\trandom_population_ideal_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_test], y_train[ideal_test],\n",
    "\t\tx_test, y_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\n",
    "\t###########################################\n",
    "\t#\t\tDiverse Population\n",
    "\t###########################################\n",
    "\t\n",
    "\tideal_validation, ideal_test = instances_dict['diverse'][data_key]\n",
    "\n",
    "\tdiverse_population_optimized_valiation_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_validation], y_train[ideal_validation],\n",
    "\t\tx_validation, y_validation,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\tdiverse_population_optimized_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_validation], y_train[ideal_validation],\n",
    "\t\tx_test, y_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\tdiverse_population_ideal_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_test], y_train[ideal_test],\n",
    "\t\tx_test, y_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\n",
    "\t###########################################\n",
    "\t#\t\tBiased Population\n",
    "\t###########################################\n",
    "\t\n",
    "\tideal_validation, ideal_test = instances_dict['bias'][data_key]\n",
    "\n",
    "\tbias_population_optimized_valiation_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_validation], y_train[ideal_validation],\n",
    "\t\tx_validation, y_validation,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\tbias_population_optimized_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_validation], y_train[ideal_validation],\n",
    "\t\tx_test, y_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\tbias_population_ideal_test_err = GenericOptimizer.calculate_overall_error(\n",
    "\t\tx_train[ideal_test], y_train[ideal_test],\n",
    "\t\tx_test, y_test,\n",
    "\t\tGenericOptimizer.n_neighbours\n",
    "\t)\n",
    "\n",
    "\n",
    "\t###########################################\n",
    "\t#\t\tRecord creation\n",
    "\t###########################################\n",
    "\t\n",
    "\tif database_name not in average_metrics:\n",
    "\t\taverage_metrics[database_name] = {\n",
    "\t\t\t\"Baseline validation acc\": [],\n",
    "\t\t\t\"Baseline test acc\": [],\n",
    "\n",
    "\t\t\t\"randPop optimized validation acc\": [],\n",
    "\t\t\t\"randPop optimized test acc\": [],\n",
    "\t\t\t\"randPop optimized ideal test acc\": [],\n",
    "\t\t\t\"randPop diff\": [],\n",
    "\n",
    "\t\t\t\"diversePop optimized validation acc\": [],\n",
    "\t\t\t\"diversePop optimized test acc\": [],\n",
    "\t\t\t\"diversePop optimized ideal test acc\": [],\n",
    "\t\t\t\"diversePop diff\": [],\n",
    "\n",
    "\t\t\t\"biasedPop optimized validation acc\": [],\n",
    "\t\t\t\"biasedPop optimized test acc\": [],\n",
    "\t\t\t\"biasedPop optimized ideal test acc\": [],\n",
    "\t\t\t\"biasedPop diff\": [],\n",
    "\t\t}\n",
    "\n",
    "\taverage_metrics[database_name]['Baseline validation acc'].append(1 - baseline_validation_err)\n",
    "\taverage_metrics[database_name]['Baseline test acc'].append(1 - baseline_test_err)\n",
    "\n",
    "\taverage_metrics[database_name]['randPop optimized validation acc'].append(1 - random_population_optimized_valiation_err)\n",
    "\taverage_metrics[database_name]['randPop optimized test acc'].append(1 - random_population_optimized_test_err)\n",
    "\taverage_metrics[database_name]['randPop optimized ideal test acc'].append(1 - random_population_ideal_test_err)\n",
    "\taverage_metrics[database_name]['randPop diff'].append(baseline_test_err - random_population_ideal_test_err)\n",
    "\n",
    "\taverage_metrics[database_name]['diversePop optimized validation acc'].append(1 - diverse_population_optimized_valiation_err)\n",
    "\taverage_metrics[database_name]['diversePop optimized test acc'].append(1 - diverse_population_optimized_test_err)\n",
    "\taverage_metrics[database_name]['diversePop optimized ideal test acc'].append(1 - diverse_population_ideal_test_err)\n",
    "\taverage_metrics[database_name]['diversePop diff'].append(baseline_test_err - diverse_population_ideal_test_err)\n",
    "\n",
    "\taverage_metrics[database_name]['biasedPop optimized validation acc'].append(1 - bias_population_optimized_valiation_err)\n",
    "\taverage_metrics[database_name]['biasedPop optimized test acc'].append(1 - bias_population_optimized_test_err)\n",
    "\taverage_metrics[database_name]['biasedPop optimized ideal test acc'].append(1 - bias_population_ideal_test_err)\n",
    "\taverage_metrics[database_name]['biasedPop diff'].append(baseline_test_err - bias_population_ideal_test_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_rows = []\n",
    "diverse_rows = []\n",
    "biased_rows = []\n",
    "index = []\n",
    "for database_name in average_metrics:\n",
    "    index.append(database_name)\n",
    "    rand_rows.append({\n",
    "        # \"Baseline validation acc\": np.mean(average_metrics[database_name][\"Baseline validation acc\"]),      \n",
    "        # \"Baseline test acc\": np.mean(average_metrics[database_name][\"Baseline test acc\"]),      \n",
    "        \"randPop ideal improvement\": np.mean(average_metrics[database_name][\"randPop diff\"]),      \n",
    "        \"randPop pval\": round(ranksums(average_metrics[database_name][\"randPop optimized ideal test acc\"], average_metrics[database_name][\"Baseline test acc\"]).pvalue, 5),\n",
    "\t})\n",
    "    diverse_rows.append({\n",
    "        # \"Baseline validation acc\": np.mean(average_metrics[database_name][\"Baseline validation acc\"]),      \n",
    "        # \"Baseline test acc\": np.mean(average_metrics[database_name][\"Baseline test acc\"]), \n",
    "        \"diversePop ideal improvement\": np.mean(average_metrics[database_name][\"diversePop diff\"]),\n",
    "        \"diversePop pval\": round(ranksums(average_metrics[database_name][\"diversePop optimized ideal test acc\"], average_metrics[database_name][\"Baseline test acc\"]).pvalue, 5),\n",
    "\t})\n",
    "    biased_rows.append({\n",
    "\t\t# \"Baseline validation acc\": np.mean(average_metrics[database_name][\"Baseline validation acc\"]),      \n",
    "        # \"Baseline test acc\": np.mean(average_metrics[database_name][\"Baseline test acc\"]), \n",
    "        \"biasedPop ideal improvement\": np.mean(average_metrics[database_name][\"biasedPop diff\"]),\n",
    "        \"biasedPop pval\": round(ranksums(average_metrics[database_name][\"biasedPop optimized ideal test acc\"], average_metrics[database_name][\"Baseline test acc\"]).pvalue, 5)\n",
    "\t})\n",
    "    rand_rows[-1][\"randPop sig?\"] = \"YES\" if rand_rows[-1][\"randPop pval\"] < 0.05 else \"NO\"\n",
    "    diverse_rows[-1][\"diversePop sig?\"] = \"YES\" if diverse_rows[-1][\"diversePop pval\"] < 0.05 else \"NO\"\n",
    "    biased_rows[-1][\"biasedPop sig?\"] = \"YES\" if biased_rows[-1][\"biasedPop pval\"] < 0.05 else \"NO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e965e097",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(rand_rows, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52134050",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(diverse_rows, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98381ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(biased_rows, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dbe42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Biased wins over random': 1,\n",
       " 'Biased loses to random': 0,\n",
       " 'Biased and random tie': 18,\n",
       " 'Diverse wins over random': 0,\n",
       " 'Diverse loses to random': 0,\n",
       " 'Diverse and random tie': 19,\n",
       " 'Diverse wins over biased': 1,\n",
       " 'Diverse loses to biased': 1,\n",
       " 'Diverse and biased tie': 17}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_tie_loss = {\n",
    "    \"Biased wins over random\": 0,\n",
    "\t\"Biased loses to random\": 0,\n",
    "\t\"Biased and random tie\": 0,\n",
    "\n",
    "    \"Diverse wins over random\": 0,\n",
    "\t\"Diverse loses to random\": 0,\n",
    "\t\"Diverse and random tie\": 0,\n",
    "\n",
    "    \"Diverse wins over biased\": 0,\n",
    "\t\"Diverse loses to biased\": 0,\n",
    "\t\"Diverse and biased tie\": 0\n",
    "}\n",
    "\n",
    "for database_name in average_metrics:\n",
    "    \n",
    "\trandpop = average_metrics[database_name][\"randPop optimized ideal test acc\"]\n",
    "\tdiversepop = average_metrics[database_name][\"diversePop optimized ideal test acc\"]\n",
    "\tbiasedpop = average_metrics[database_name][\"biasedPop optimized ideal test acc\"]\n",
    "\n",
    "\tbiased_vs_rand =  ranksums(biasedpop, randpop).pvalue  \n",
    "\tdiverse_vs_rand = ranksums(diversepop, randpop).pvalue\n",
    "\tdiverse_vs_biased = ranksums(diversepop, biasedpop).pvalue\n",
    "\n",
    "\tif diverse_vs_rand < 0.05:\n",
    "\t\tif np.mean(randpop) < np.mean(diversepop):\n",
    "\t\t\twin_tie_loss[\"Diverse wins over random\"] += 1\n",
    "\t\telse:\n",
    "\t\t\twin_tie_loss[\"Diverse loses to random\"] += 1\n",
    "\telse:\n",
    "\t\twin_tie_loss[\"Diverse and random tie\"] += 1\n",
    "\n",
    "\n",
    "\n",
    "\tif biased_vs_rand < 0.05:\n",
    "\t\tif np.mean(randpop) < np.mean(diversepop):\n",
    "\t\t\twin_tie_loss[\"Biased wins over random\"] += 1\n",
    "\t\telse:\n",
    "\t\t\twin_tie_loss[\"Biased loses to random\"] += 1\n",
    "\telse:\n",
    "\t\twin_tie_loss[\"Biased and random tie\"] += 1\n",
    "\n",
    "\n",
    "\n",
    "\tif diverse_vs_biased < 0.05:\n",
    "\t\tif np.mean(randpop) < np.mean(diversepop):\n",
    "\t\t\twin_tie_loss[\"Diverse wins over biased\"] += 1\n",
    "\t\telse:\n",
    "\t\t\twin_tie_loss[\"Diverse loses to biased\"] += 1\n",
    "\telse:\n",
    "\t\twin_tie_loss[\"Diverse and biased tie\"] += 1\n",
    "\n",
    "win_tie_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
